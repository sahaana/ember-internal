{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "brutal-musician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "distributed-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\nfrom embedding_datasets import SQuADDataset, EmberEvalDataset\\nfrom embedding_models import TripletSingleBERTModel\\nfrom embedding_utils import param_header, tokenize_batch  \\nfrom embedding_runner import train_model, eval_model\\n#from model_utils import MatchedDatasetTriplets, param_header_bert, tokenize_batch   \\n#from models import BatchedTripletSingleTowerModel, BatchedTripletSingleBERTModel\\n#from model_runner import train_model, eval_model\\nfrom knn_utils import FaissKNeighbors, knn_SQuAD_recall #, knn_matching_accuracy, find_perfect_recall'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/lfs/1/sahaana/enrichment/ember/utils')\n",
    "\n",
    "from file_utils import load_config, get_sorted_files, get_config_knn_dir, get_alpha_sorted_files\n",
    "from embedding_utils import param_header\n",
    "\"\"\"\n",
    "    \n",
    "from embedding_datasets import SQuADDataset, EmberEvalDataset\n",
    "from embedding_models import TripletSingleBERTModel\n",
    "from embedding_utils import param_header, tokenize_batch  \n",
    "from embedding_runner import train_model, eval_model\n",
    "#from model_utils import MatchedDatasetTriplets, param_header_bert, tokenize_batch   \n",
    "#from models import BatchedTripletSingleTowerModel, BatchedTripletSingleBERTModel\n",
    "#from model_runner import train_model, eval_model\n",
    "from knn_utils import FaissKNeighbors, knn_SQuAD_recall #, knn_matching_accuracy, find_perfect_recall\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "julian-miracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "stopped-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/lfs/1/sahaana/enrichment/ember/embedding\"\n",
    "config_base = \"/lfs/1/sahaana/enrichment/ember/embedding/configs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-light",
   "metadata": {},
   "source": [
    "# Barf Em All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "amateur-rover",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD_sent\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-260004/knn/13-57-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-260004/knn/13-57-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-260004/knn/14-59-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-260004/knn/14-59-22-02-21_embeddings.pkl']\n",
      "\n",
      "SQuAD_sent\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-05-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-05-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-06-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-06-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-07-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-07-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-08-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/05-08-22-02-21_embeddings.pkl']\n",
      "\n",
      "SQuAD_sent\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/16-40-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/16-40-22-02-21_embeddings.pkl']\n",
      "\n",
      "SQuAD_sent\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-uncased-masked-ALL-BM25-double-triplet-260004-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-uncased-masked-ALL-BM25-double-triplet-260004-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-260004/knn/06-01-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-uncased-masked-ALL-BM25-double-triplet-260004-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-260004/knn/06-01-22-02-21_embeddings.pkl']\n",
      "\n",
      "SQuAD_sent\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-260004/knn/17-41-20-02-21_knn_results.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-distilbert-base-uncased-single-triplet-5743-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-distilbert-base-uncased-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/19-28-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-distilbert-base-uncased-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/19-28-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-distilbert-base-uncased-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/16-39-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-distilbert-base-uncased-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/16-39-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-13-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-13-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-54-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-54-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/abt_buy_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-43-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-43-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-33-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-33-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/abt_buy_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-5743-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/18-50-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/18-50-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/16-02-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/16-02-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/abt_buy_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-5743-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/18-48-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/18-48-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/16-01-23-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-5743-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-5743/knn/16-01-23-02-21_knn_results.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-distilbert-base-uncased-single-triplet-6874-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-distilbert-base-uncased-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/19-30-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-distilbert-base-uncased-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/19-30-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-distilbert-base-uncased-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/16-41-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-distilbert-base-uncased-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/16-41-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-14-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-14-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-54-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-54-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/amazon_google_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-44-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-44-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-34-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-34-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/amazon_google_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-6874-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/18-52-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/18-52-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/16-04-23-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/16-04-23-02-21_knn_results.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/amazon_google_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-6874-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/18-50-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/18-50-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/16-03-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-6874-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6874/knn/16-03-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-distilbert-base-uncased-single-triplet-268-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-distilbert-base-uncased-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/19-31-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-distilbert-base-uncased-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/19-31-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-distilbert-base-uncased-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/16-42-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-distilbert-base-uncased-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/16-42-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-15-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-15-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-55-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-55-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/beer_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-45-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-45-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-35-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-35-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/beer_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-uncased-masked-ALL-BM25-double-triplet-268-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-double-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/18-53-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-double-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/18-53-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-double-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/16-05-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-double-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/16-05-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/beer_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-uncased-masked-ALL-BM25-single-triplet-268-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/18-51-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/18-51-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/16-04-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/beer_exp_data-uncased-masked-ALL-BM25-single-triplet-268-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-268/knn/16-04-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/21-16-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/21-16-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/18-07-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/18-07-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-24-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-24-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-04-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-04-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-54-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-54-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-44-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-44-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/18-58-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/18-58-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/16-09-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/16-09-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/20-15-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/20-15-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/17-28-23-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/17-28-23-02-21_knn_results.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/21-23-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/21-23-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/18-13-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/18-13-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-27-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-27-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-07-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-07-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-57-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-57-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-47-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-47-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/19-05-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/19-05-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/16-16-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/16-16-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/20-21-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/20-21-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/17-34-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/17-34-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/21-25-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/21-25-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/18-15-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/18-15-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-27-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-27-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-07-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-07-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-58-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-58-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-47-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-47-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/19-07-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/19-07-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/16-18-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/16-18-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/20-24-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/20-24-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/17-37-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-7417/knn/17-37-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/21-31-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/21-31-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/18-22-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/18-22-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-30-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-30-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-10-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-10-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-01-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-01-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-50-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-50-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/19-14-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/19-14-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/16-25-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/16-25-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/20-30-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/20-30-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/17-43-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-17223/knn/17-43-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/21-34-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/21-34-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/18-25-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/18-25-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-33-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-33-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-12-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-12-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-03-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-03-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-52-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-52-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/19-17-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/19-17-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/16-28-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/16-28-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/20-33-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/20-33-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/17-45-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/17-45-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/21-37-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/21-37-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/18-27-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/18-27-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-34-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-34-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-14-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-14-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-05-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-05-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-54-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-54-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/19-20-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/19-20-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/16-31-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/16-31-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/20-35-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/20-35-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/17-48-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/17-48-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-567-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/21-37-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/21-37-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/18-28-23-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/18-28-23-02-21_knn_results.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-35-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-35-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-14-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-14-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-05-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-05-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-54-23-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-54-23-02-21_knn_results.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-567-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/19-20-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/19-20-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/16-32-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/16-32-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-567-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/20-36-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/20-36-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/17-48-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-567-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-567/knn/17-48-23-02-21_embeddings.pkl']\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-43-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-43-23-02-21_embeddings.pkl']\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-23-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-23-23-02-21_embeddings.pkl']\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-44-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-44-23-02-21_embeddings.pkl']\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-33-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-33-23-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/22-49-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/22-49-23-02-21_embeddings.pkl']\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-22-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-22-23-02-21_embeddings.pkl']\n",
      "\n",
      "imdb_wiki\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-distilbert-base-uncased-single-triplet-38250-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-distilbert-base-uncased-single-triplet-38250-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-38250/knn/15-28-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-distilbert-base-uncased-single-triplet-38250-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-38250/knn/15-28-22-02-21_embeddings.pkl']\n",
      "\n",
      "imdb_wiki\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-50-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-50-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-52-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-52-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-55-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-55-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-57-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/03-57-22-02-21_embeddings.pkl']\n",
      "\n",
      "imdb_wiki\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/16-20-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/16-20-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-04-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-04-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-20-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-20-22-02-21_embeddings.pkl']\n",
      "\n",
      "imdb_wiki\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1/batch_size-4-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-38250/knn/19-15-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1/batch_size-4-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-38250/knn/19-15-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1/batch_size-4-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-38250/knn/20-58-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1/batch_size-4-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-38250/knn/20-58-22-02-21_embeddings.pkl']\n",
      "\n",
      "imdb_wiki\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-38250/knn/16-37-20-02-21_knn_results.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/21-40-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/21-40-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/18-30-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/18-30-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-37-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-37-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-17-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-17-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-08-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-08-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-57-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-57-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/19-23-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/19-23-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/16-34-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/16-34-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/20-38-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/20-38-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/17-51-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-321/knn/17-51-23-02-21_embeddings.pkl']\n",
      "\n",
      "small_imdb_fuzzy\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/14-07-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/14-07-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/15-38-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/15-38-22-02-21_embeddings.pkl']\n",
      "\n",
      "small_imdb_fuzzy\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-10-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-10-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-11-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-11-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-14-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-14-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-15-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/04-15-22-02-21_embeddings.pkl']\n",
      "\n",
      "small_imdb_fuzzy\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/small_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/16-22-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/16-22-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-05-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-05-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-21-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/17-21-22-02-21_embeddings.pkl']\n",
      "\n",
      "small_imdb_fuzzy\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/small_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/06-13-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/06-13-22-02-21_embeddings.pkl']\n",
      "\n",
      "small_imdb_fuzzy\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/small_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/03-56-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/03-56-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/04-16-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/04-16-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/04-26-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/04-26-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/04-36-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/04-36-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/16-11-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/16-11-23-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-12-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-40000/knn/18-12-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/21-43-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/21-43-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/18-33-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/18-33-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-pretrained-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-39-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/21-39-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-18-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-18-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-09-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/22-09-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-58-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-pretrained-MLMBM25-1-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1/knn/18-58-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/19-26-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/19-26-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/16-37-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/16-37-23-02-21_embeddings.pkl']\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1.json\n",
      "['/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/20-41-22-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/20-41-22-02-21_embeddings.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/17-53-23-02-21_knn_results.pkl', '/lfs/1/sahaana/enrichment/ember/embedding/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-6144/knn/17-53-23-02-21_embeddings.pkl']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    if 'json' not in i or \"MARCO\" in i or \"company\" in i or 'deepmatcher' in i or 'OLD' in i: \n",
    "        continue\n",
    "    conf = load_config(i)\n",
    "    config_knn = get_config_knn_dir(i)\n",
    "    print(conf['data'])\n",
    "    print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "    print(i)\n",
    "    print(get_sorted_files(config_knn))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-thousand",
   "metadata": {},
   "source": [
    "# Retrieval workloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-landscape",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "working-plaintiff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD_sent\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.595174   3527  0.595174\n",
      "1    2  0.693048   4107  0.644111\n",
      "2    3  0.733716   4348  0.657667\n",
      "3    4  0.765440   4536  0.665598\n",
      "4    5  0.784846   4651  0.669479\n",
      "5    6  0.801721   4751  0.672292\n",
      "6    7  0.815559   4833  0.674268\n",
      "7    8  0.826190   4896  0.675597\n",
      "8    9  0.833446   4939  0.676403\n",
      "9   10  0.841546   4987  0.677213\n",
      "10  11  0.849477   5034  0.677934\n",
      "11  12  0.856058   5073  0.678483\n",
      "12  13  0.862302   5110  0.678963\n",
      "13  14  0.866858   5137  0.679289\n",
      "14  15  0.871920   5167  0.679626\n",
      "15  16  0.876645   5195  0.679921\n",
      "16  17  0.880189   5216  0.680130\n",
      "17  18  0.884070   5239  0.680346\n",
      "18  19  0.886601   5254  0.680479\n",
      "19  20  0.889639   5272  0.680631\n",
      "20  21  0.892339   5288  0.680759\n",
      "21  22  0.895376   5306  0.680897\n",
      "22  23  0.898076   5322  0.681015\n",
      "23  24  0.900439   5336  0.681113\n",
      "24  25  0.902801   5350  0.681208\n",
      "25  26  0.906007   5369  0.681331\n",
      "26  27  0.908539   5384  0.681425\n",
      "27  28  0.910564   5396  0.681497\n",
      "28  29  0.912757   5409  0.681573\n",
      "29  30  0.914276   5418  0.681623\n",
      "     k       avg  count       MRR\n",
      "0    1  0.605130   3586  0.605130\n",
      "1    2  0.705535   4181  0.655332\n",
      "2    3  0.749916   4444  0.670126\n",
      "3    4  0.779447   4619  0.677509\n",
      "4    5  0.801384   4749  0.681896\n",
      "5    6  0.814715   4828  0.684118\n",
      "6    7  0.826696   4899  0.685830\n",
      "7    8  0.835471   4951  0.686926\n",
      "8    9  0.844583   5005  0.687939\n",
      "9   10  0.852177   5050  0.688698\n",
      "10  11  0.857746   5083  0.689205\n",
      "11  12  0.864158   5121  0.689739\n",
      "12  13  0.870064   5156  0.690193\n",
      "13  14  0.874958   5185  0.690543\n",
      "14  15  0.878164   5204  0.690757\n",
      "15  16  0.880695   5219  0.690915\n",
      "16  17  0.883901   5238  0.691103\n",
      "17  18  0.886264   5252  0.691235\n",
      "18  19  0.888289   5264  0.691341\n",
      "19  20  0.891833   5285  0.691518\n",
      "20  21  0.894026   5298  0.691623\n",
      "21  22  0.895883   5309  0.691707\n",
      "22  23  0.898751   5326  0.691832\n",
      "23  24  0.902464   5348  0.691987\n",
      "24  25  0.903814   5356  0.692041\n",
      "25  26  0.905501   5366  0.692106\n",
      "26  27  0.908876   5386  0.692231\n",
      "27  28  0.910395   5395  0.692285\n",
      "28  29  0.912420   5407  0.692355\n",
      "29  30  0.914782   5421  0.692433\n",
      "\n",
      "SQuAD_sent\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-pretrained-1-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.125886    746  0.125886\n",
      "1    2  0.169085   1002  0.147486\n",
      "2    3  0.197266   1169  0.156879\n",
      "3    4  0.220722   1308  0.162743\n",
      "4    5  0.238610   1414  0.166321\n",
      "5    6  0.256328   1519  0.169274\n",
      "6    7  0.268309   1590  0.170985\n",
      "7    8  0.278603   1651  0.172272\n",
      "8    9  0.291428   1727  0.173697\n",
      "9   10  0.299190   1773  0.174473\n",
      "10  11  0.307796   1824  0.175256\n",
      "11  12  0.316909   1878  0.176015\n",
      "12  13  0.326021   1932  0.176716\n",
      "13  14  0.331421   1964  0.177102\n",
      "14  15  0.337833   2002  0.177529\n",
      "15  16  0.342221   2028  0.177803\n",
      "16  17  0.348633   2066  0.178181\n",
      "17  18  0.354708   2102  0.178518\n",
      "18  19  0.359939   2133  0.178793\n",
      "19  20  0.365002   2163  0.179047\n",
      "20  21  0.371245   2200  0.179344\n",
      "21  22  0.375633   2226  0.179543\n",
      "22  23  0.380526   2255  0.179756\n",
      "23  24  0.384408   2278  0.179918\n",
      "24  25  0.387614   2297  0.180046\n",
      "25  26  0.391158   2318  0.180182\n",
      "26  27  0.394026   2335  0.180289\n",
      "27  28  0.397739   2357  0.180421\n",
      "28  29  0.400270   2372  0.180508\n",
      "29  30  0.402801   2387  0.180593\n",
      "     k       avg  count       MRR\n",
      "0    1  0.125886    746  0.125886\n",
      "1    2  0.169085   1002  0.147486\n",
      "2    3  0.197266   1169  0.156879\n",
      "3    4  0.220722   1308  0.162743\n",
      "4    5  0.238610   1414  0.166321\n",
      "5    6  0.256328   1519  0.169274\n",
      "6    7  0.268309   1590  0.170985\n",
      "7    8  0.278603   1651  0.172272\n",
      "8    9  0.291428   1727  0.173697\n",
      "9   10  0.299190   1773  0.174473\n",
      "10  11  0.307796   1824  0.175256\n",
      "11  12  0.316909   1878  0.176015\n",
      "12  13  0.326021   1932  0.176716\n",
      "13  14  0.331421   1964  0.177102\n",
      "14  15  0.337833   2002  0.177529\n",
      "15  16  0.342221   2028  0.177803\n",
      "16  17  0.348633   2066  0.178181\n",
      "17  18  0.354708   2102  0.178518\n",
      "18  19  0.359939   2133  0.178793\n",
      "19  20  0.365002   2163  0.179047\n",
      "20  21  0.371245   2200  0.179344\n",
      "21  22  0.375633   2226  0.179543\n",
      "22  23  0.380526   2255  0.179756\n",
      "23  24  0.384408   2278  0.179918\n",
      "24  25  0.387614   2297  0.180046\n",
      "25  26  0.391158   2318  0.180182\n",
      "26  27  0.394026   2335  0.180289\n",
      "27  28  0.397739   2357  0.180421\n",
      "28  29  0.400270   2372  0.180508\n",
      "29  30  0.402801   2387  0.180593\n",
      "     k       avg  count       MRR\n",
      "0    1  0.125886    746  0.125886\n",
      "1    2  0.169085   1002  0.147486\n",
      "2    3  0.197266   1169  0.156879\n",
      "3    4  0.220722   1308  0.162743\n",
      "4    5  0.238610   1414  0.166321\n",
      "5    6  0.256328   1519  0.169274\n",
      "6    7  0.268309   1590  0.170985\n",
      "7    8  0.278603   1651  0.172272\n",
      "8    9  0.291428   1727  0.173697\n",
      "9   10  0.299190   1773  0.174473\n",
      "10  11  0.307796   1824  0.175256\n",
      "11  12  0.316909   1878  0.176015\n",
      "12  13  0.326021   1932  0.176716\n",
      "13  14  0.331421   1964  0.177102\n",
      "14  15  0.337833   2002  0.177529\n",
      "15  16  0.342221   2028  0.177803\n",
      "16  17  0.348633   2066  0.178181\n",
      "17  18  0.354708   2102  0.178518\n",
      "18  19  0.359939   2133  0.178793\n",
      "19  20  0.365002   2163  0.179047\n",
      "20  21  0.371245   2200  0.179344\n",
      "21  22  0.375633   2226  0.179543\n",
      "22  23  0.380526   2255  0.179756\n",
      "23  24  0.384408   2278  0.179918\n",
      "24  25  0.387614   2297  0.180046\n",
      "25  26  0.391158   2318  0.180182\n",
      "26  27  0.394026   2335  0.180289\n",
      "27  28  0.397739   2357  0.180421\n",
      "28  29  0.400270   2372  0.180508\n",
      "29  30  0.402801   2387  0.180593\n",
      "     k       avg  count       MRR\n",
      "0    1  0.125886    746  0.125886\n",
      "1    2  0.169085   1002  0.147486\n",
      "2    3  0.197266   1169  0.156879\n",
      "3    4  0.220722   1308  0.162743\n",
      "4    5  0.238610   1414  0.166321\n",
      "5    6  0.256328   1519  0.169274\n",
      "6    7  0.268309   1590  0.170985\n",
      "7    8  0.278603   1651  0.172272\n",
      "8    9  0.291428   1727  0.173697\n",
      "9   10  0.299190   1773  0.174473\n",
      "10  11  0.307796   1824  0.175256\n",
      "11  12  0.316909   1878  0.176015\n",
      "12  13  0.326021   1932  0.176716\n",
      "13  14  0.331421   1964  0.177102\n",
      "14  15  0.337833   2002  0.177529\n",
      "15  16  0.342221   2028  0.177803\n",
      "16  17  0.348633   2066  0.178181\n",
      "17  18  0.354708   2102  0.178518\n",
      "18  19  0.359939   2133  0.178793\n",
      "19  20  0.365002   2163  0.179047\n",
      "20  21  0.371245   2200  0.179344\n",
      "21  22  0.375633   2226  0.179543\n",
      "22  23  0.380526   2255  0.179756\n",
      "23  24  0.384408   2278  0.179918\n",
      "24  25  0.387614   2297  0.180046\n",
      "25  26  0.391158   2318  0.180182\n",
      "26  27  0.394026   2335  0.180289\n",
      "27  28  0.397739   2357  0.180421\n",
      "28  29  0.400270   2372  0.180508\n",
      "29  30  0.402801   2387  0.180593\n",
      "\n",
      "SQuAD_sent\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-pretrained-MLMBM25-1-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.105974    628  0.105974\n",
      "1    2  0.130442    773  0.118208\n",
      "2    3  0.144786    858  0.122989\n",
      "3    4  0.153561    910  0.125183\n",
      "4    5  0.164192    973  0.127309\n",
      "5    6  0.169423   1004  0.128181\n",
      "6    7  0.173810   1030  0.128808\n",
      "7    8  0.178873   1060  0.129440\n",
      "8    9  0.183429   1087  0.129947\n",
      "9   10  0.187310   1110  0.130335\n",
      "10  11  0.190516   1129  0.130626\n",
      "11  12  0.194060   1150  0.130922\n",
      "12  13  0.197435   1170  0.131181\n",
      "13  14  0.200979   1191  0.131434\n",
      "14  15  0.203341   1205  0.131592\n",
      "15  16  0.205366   1217  0.131718\n",
      "16  17  0.207054   1227  0.131818\n",
      "17  18  0.209079   1239  0.131930\n",
      "18  19  0.211441   1253  0.132055\n",
      "19  20  0.213297   1264  0.132147\n",
      "20  21  0.214985   1274  0.132228\n",
      "21  22  0.217179   1287  0.132327\n",
      "22  23  0.219541   1301  0.132430\n",
      "23  24  0.221903   1315  0.132529\n",
      "24  25  0.223422   1324  0.132589\n",
      "25  26  0.224772   1332  0.132641\n",
      "26  27  0.225785   1338  0.132679\n",
      "27  28  0.226628   1343  0.132709\n",
      "28  29  0.228316   1353  0.132767\n",
      "29  30  0.230341   1365  0.132835\n",
      "\n",
      "SQuAD_sent\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-uncased-masked-ALL-BM25-double-triplet-260004-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.308302   1827  0.308302\n",
      "1    2  0.408201   2419  0.358252\n",
      "2    3  0.468950   2779  0.378502\n",
      "3    4  0.512656   3038  0.389428\n",
      "4    5  0.546574   3239  0.396212\n",
      "5    6  0.573574   3399  0.400712\n",
      "6    7  0.596524   3535  0.403990\n",
      "7    8  0.618292   3664  0.406711\n",
      "8    9  0.636517   3772  0.408736\n",
      "9   10  0.650861   3857  0.410170\n",
      "10  11  0.663517   3932  0.411321\n",
      "11  12  0.676510   4009  0.412404\n",
      "12  13  0.687310   4073  0.413235\n",
      "13  14  0.697604   4134  0.413970\n",
      "14  15  0.706210   4185  0.414544\n",
      "15  16  0.713972   4231  0.415029\n",
      "16  17  0.721228   4274  0.415456\n",
      "17  18  0.727472   4311  0.415802\n",
      "18  19  0.735066   4356  0.416202\n",
      "19  20  0.740128   4386  0.416455\n",
      "20  21  0.746203   4422  0.416745\n",
      "21  22  0.753122   4463  0.417059\n",
      "22  23  0.759703   4502  0.417345\n",
      "23  24  0.764428   4530  0.417542\n",
      "24  25  0.768309   4553  0.417697\n",
      "25  26  0.773203   4582  0.417885\n",
      "26  27  0.777084   4605  0.418029\n",
      "27  28  0.780459   4625  0.418150\n",
      "28  29  0.784846   4651  0.418301\n",
      "29  30  0.788221   4671  0.418414\n",
      "\n",
      "SQuAD_sent\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.566655   3358  0.566655\n",
      "1    2  0.672292   3984  0.619474\n",
      "2    3  0.721566   4276  0.635898\n",
      "3    4  0.750591   4448  0.643154\n",
      "4    5  0.774384   4589  0.647913\n",
      "5    6  0.789571   4679  0.650444\n",
      "6    7  0.803915   4764  0.652493\n",
      "7    8  0.815559   4833  0.653949\n",
      "8    9  0.824333   4885  0.654924\n",
      "9   10  0.832940   4936  0.655785\n",
      "10  11  0.839690   4976  0.656398\n",
      "11  12  0.846608   5017  0.656975\n",
      "12  13  0.853358   5057  0.657494\n",
      "13  14  0.859939   5096  0.657964\n",
      "14  15  0.864664   5124  0.658279\n",
      "15  16  0.867870   5143  0.658479\n",
      "16  17  0.871245   5163  0.658678\n",
      "17  18  0.875127   5186  0.658894\n",
      "18  19  0.878839   5208  0.659089\n",
      "19  20  0.881876   5226  0.659241\n",
      "20  21  0.884914   5244  0.659385\n",
      "21  22  0.887783   5261  0.659516\n",
      "22  23  0.889639   5272  0.659597\n",
      "23  24  0.892845   5291  0.659730\n",
      "24  25  0.894870   5303  0.659811\n",
      "25  26  0.897401   5318  0.659908\n",
      "26  27  0.899258   5329  0.659977\n",
      "27  28  0.902464   5348  0.660092\n",
      "28  29  0.905332   5365  0.660191\n",
      "29  30  0.907695   5379  0.660269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    if 'SQuAD' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "        conf = load_config(i)\n",
    "        config_knn = get_config_knn_dir(i)\n",
    "        print(conf['data'])\n",
    "        print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "        print(i)\n",
    "        files = get_sorted_files(config_knn)\n",
    "        for j in files:\n",
    "            if 'knn_results' in j:\n",
    "                results = pd.read_pickle(j)\n",
    "                print(results[['k', 'avg', 'count', 'MRR']])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-modern",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## imdb_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "tested-aerospace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_wiki\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-distilbert-base-uncased-single-triplet-38250-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.945624   9043  0.945624\n",
      "1    2  0.960996   9190  0.953310\n",
      "2    3  0.967270   9250  0.955401\n",
      "3    4  0.974171   9316  0.957126\n",
      "4    5  0.977204   9345  0.957733\n",
      "5    6  0.979504   9367  0.958116\n",
      "6    7  0.982537   9396  0.958550\n",
      "7    8  0.984105   9411  0.958746\n",
      "8    9  0.985779   9427  0.958932\n",
      "9   10  0.987033   9439  0.959057\n",
      "10  11  0.987870   9447  0.959133\n",
      "11  12  0.988288   9451  0.959168\n",
      "12  13  0.988916   9457  0.959216\n",
      "13  14  0.989648   9464  0.959268\n",
      "14  15  0.989961   9467  0.959289\n",
      "15  16  0.990589   9473  0.959329\n",
      "16  17  0.990798   9475  0.959341\n",
      "17  18  0.991112   9478  0.959358\n",
      "18  19  0.991739   9484  0.959391\n",
      "19  20  0.991844   9485  0.959397\n",
      "20  21  0.992157   9488  0.959412\n",
      "21  22  0.992366   9490  0.959421\n",
      "22  23  0.992680   9493  0.959435\n",
      "23  24  0.992994   9496  0.959448\n",
      "24  25  0.993203   9498  0.959456\n",
      "25  26  0.993517   9501  0.959468\n",
      "26  27  0.993726   9503  0.959476\n",
      "27  28  0.993830   9504  0.959480\n",
      "28  29  0.994040   9506  0.959487\n",
      "29  30  0.994144   9507  0.959490\n",
      "\n",
      "imdb_wiki\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-pretrained-1-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.000418      4  0.000418\n",
      "1    2  0.000732      7  0.000575\n",
      "2    3  0.001046     10  0.000680\n",
      "3    4  0.001464     14  0.000784\n",
      "4    5  0.001987     19  0.000889\n",
      "5    6  0.002091     20  0.000906\n",
      "6    7  0.002301     22  0.000936\n",
      "7    8  0.002405     23  0.000949\n",
      "8    9  0.002510     24  0.000961\n",
      "9   10  0.002614     25  0.000971\n",
      "10  11  0.002719     26  0.000981\n",
      "11  12  0.002928     28  0.000998\n",
      "12  13  0.003137     30  0.001014\n",
      "13  14  0.003242     31  0.001022\n",
      "14  15  0.003555     34  0.001043\n",
      "15  16  0.003660     35  0.001049\n",
      "16  17  0.004287     41  0.001086\n",
      "17  18  0.005228     50  0.001138\n",
      "18  19  0.005647     54  0.001160\n",
      "19  20  0.005751     55  0.001166\n",
      "20  21  0.006274     60  0.001191\n",
      "21  22  0.006902     66  0.001219\n",
      "22  23  0.007634     73  0.001251\n",
      "23  24  0.007843     75  0.001260\n",
      "24  25  0.008575     82  0.001289\n",
      "25  26  0.009307     89  0.001317\n",
      "26  27  0.010039     96  0.001344\n",
      "27  28  0.010980    105  0.001378\n",
      "28  29  0.011398    109  0.001392\n",
      "29  30  0.011921    114  0.001410\n",
      "     k       avg  count       MRR\n",
      "0    1  0.000418      4  0.000418\n",
      "1    2  0.000732      7  0.000575\n",
      "2    3  0.001046     10  0.000680\n",
      "3    4  0.001464     14  0.000784\n",
      "4    5  0.001987     19  0.000889\n",
      "5    6  0.002091     20  0.000906\n",
      "6    7  0.002301     22  0.000936\n",
      "7    8  0.002405     23  0.000949\n",
      "8    9  0.002510     24  0.000961\n",
      "9   10  0.002614     25  0.000971\n",
      "10  11  0.002719     26  0.000981\n",
      "11  12  0.002928     28  0.000998\n",
      "12  13  0.003137     30  0.001014\n",
      "13  14  0.003242     31  0.001022\n",
      "14  15  0.003555     34  0.001043\n",
      "15  16  0.003660     35  0.001049\n",
      "16  17  0.004287     41  0.001086\n",
      "17  18  0.005228     50  0.001138\n",
      "18  19  0.005647     54  0.001160\n",
      "19  20  0.005751     55  0.001166\n",
      "20  21  0.006274     60  0.001191\n",
      "21  22  0.006902     66  0.001219\n",
      "22  23  0.007634     73  0.001251\n",
      "23  24  0.007843     75  0.001260\n",
      "24  25  0.008575     82  0.001289\n",
      "25  26  0.009307     89  0.001317\n",
      "26  27  0.010039     96  0.001344\n",
      "27  28  0.010980    105  0.001378\n",
      "28  29  0.011398    109  0.001392\n",
      "29  30  0.011921    114  0.001410\n",
      "     k       avg  count       MRR\n",
      "0    1  0.000418      4  0.000418\n",
      "1    2  0.000732      7  0.000575\n",
      "2    3  0.001046     10  0.000680\n",
      "3    4  0.001464     14  0.000784\n",
      "4    5  0.001987     19  0.000889\n",
      "5    6  0.002091     20  0.000906\n",
      "6    7  0.002301     22  0.000936\n",
      "7    8  0.002405     23  0.000949\n",
      "8    9  0.002510     24  0.000961\n",
      "9   10  0.002614     25  0.000971\n",
      "10  11  0.002719     26  0.000981\n",
      "11  12  0.002928     28  0.000998\n",
      "12  13  0.003137     30  0.001014\n",
      "13  14  0.003242     31  0.001022\n",
      "14  15  0.003555     34  0.001043\n",
      "15  16  0.003660     35  0.001049\n",
      "16  17  0.004287     41  0.001086\n",
      "17  18  0.005228     50  0.001138\n",
      "18  19  0.005647     54  0.001160\n",
      "19  20  0.005751     55  0.001166\n",
      "20  21  0.006274     60  0.001191\n",
      "21  22  0.006902     66  0.001219\n",
      "22  23  0.007634     73  0.001251\n",
      "23  24  0.007843     75  0.001260\n",
      "24  25  0.008575     82  0.001289\n",
      "25  26  0.009307     89  0.001317\n",
      "26  27  0.010039     96  0.001344\n",
      "27  28  0.010980    105  0.001378\n",
      "28  29  0.011398    109  0.001392\n",
      "29  30  0.011921    114  0.001410\n",
      "     k       avg  count       MRR\n",
      "0    1  0.000418      4  0.000418\n",
      "1    2  0.000732      7  0.000575\n",
      "2    3  0.001046     10  0.000680\n",
      "3    4  0.001464     14  0.000784\n",
      "4    5  0.001987     19  0.000889\n",
      "5    6  0.002091     20  0.000906\n",
      "6    7  0.002301     22  0.000936\n",
      "7    8  0.002405     23  0.000949\n",
      "8    9  0.002510     24  0.000961\n",
      "9   10  0.002614     25  0.000971\n",
      "10  11  0.002719     26  0.000981\n",
      "11  12  0.002928     28  0.000998\n",
      "12  13  0.003137     30  0.001014\n",
      "13  14  0.003242     31  0.001022\n",
      "14  15  0.003555     34  0.001043\n",
      "15  16  0.003660     35  0.001049\n",
      "16  17  0.004287     41  0.001086\n",
      "17  18  0.005228     50  0.001138\n",
      "18  19  0.005647     54  0.001160\n",
      "19  20  0.005751     55  0.001166\n",
      "20  21  0.006274     60  0.001191\n",
      "21  22  0.006902     66  0.001219\n",
      "22  23  0.007634     73  0.001251\n",
      "23  24  0.007843     75  0.001260\n",
      "24  25  0.008575     82  0.001289\n",
      "25  26  0.009307     89  0.001317\n",
      "26  27  0.010039     96  0.001344\n",
      "27  28  0.010980    105  0.001378\n",
      "28  29  0.011398    109  0.001392\n",
      "29  30  0.011921    114  0.001410\n",
      "\n",
      "imdb_wiki\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-pretrained-MLMBM25-1-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.011712    112  0.011712\n",
      "1    2  0.016940    162  0.014326\n",
      "2    3  0.020914    200  0.015651\n",
      "3    4  0.024783    237  0.016618\n",
      "4    5  0.028025    268  0.017266\n",
      "5    6  0.031371    300  0.017824\n",
      "6    7  0.033671    322  0.018153\n",
      "7    8  0.036599    350  0.018519\n",
      "8    9  0.039214    375  0.018809\n",
      "9   10  0.041932    401  0.019081\n",
      "10  11  0.044233    423  0.019290\n",
      "11  12  0.047266    452  0.019543\n",
      "12  13  0.048939    468  0.019671\n",
      "13  14  0.051344    491  0.019843\n",
      "14  15  0.053540    512  0.019990\n",
      "15  16  0.055317    529  0.020101\n",
      "16  17  0.057618    551  0.020236\n",
      "17  18  0.058977    564  0.020312\n",
      "18  19  0.060546    579  0.020394\n",
      "19  20  0.062010    593  0.020467\n",
      "20  21  0.064624    618  0.020592\n",
      "21  22  0.065983    631  0.020654\n",
      "22  23  0.067970    650  0.020740\n",
      "23  24  0.069853    668  0.020818\n",
      "24  25  0.071421    683  0.020881\n",
      "25  26  0.073199    700  0.020950\n",
      "26  27  0.074872    716  0.021012\n",
      "27  28  0.076231    729  0.021060\n",
      "28  29  0.077382    740  0.021100\n",
      "29  30  0.078950    755  0.021152\n",
      "     k       avg  count       MRR\n",
      "0    1  0.011712    112  0.011712\n",
      "1    2  0.016940    162  0.014326\n",
      "2    3  0.020914    200  0.015651\n",
      "3    4  0.024783    237  0.016618\n",
      "4    5  0.028025    268  0.017266\n",
      "5    6  0.031371    300  0.017824\n",
      "6    7  0.033671    322  0.018153\n",
      "7    8  0.036599    350  0.018519\n",
      "8    9  0.039214    375  0.018809\n",
      "9   10  0.041932    401  0.019081\n",
      "10  11  0.044233    423  0.019290\n",
      "11  12  0.047266    452  0.019543\n",
      "12  13  0.048939    468  0.019671\n",
      "13  14  0.051344    491  0.019843\n",
      "14  15  0.053540    512  0.019990\n",
      "15  16  0.055317    529  0.020101\n",
      "16  17  0.057618    551  0.020236\n",
      "17  18  0.058977    564  0.020312\n",
      "18  19  0.060546    579  0.020394\n",
      "19  20  0.062010    593  0.020467\n",
      "20  21  0.064624    618  0.020592\n",
      "21  22  0.065983    631  0.020654\n",
      "22  23  0.067970    650  0.020740\n",
      "23  24  0.069853    668  0.020818\n",
      "24  25  0.071421    683  0.020881\n",
      "25  26  0.073199    700  0.020950\n",
      "26  27  0.074872    716  0.021012\n",
      "27  28  0.076231    729  0.021060\n",
      "28  29  0.077382    740  0.021100\n",
      "29  30  0.078950    755  0.021152\n",
      "     k       avg  count       MRR\n",
      "0    1  0.011712    112  0.011712\n",
      "1    2  0.016940    162  0.014326\n",
      "2    3  0.020914    200  0.015651\n",
      "3    4  0.024783    237  0.016618\n",
      "4    5  0.028025    268  0.017266\n",
      "5    6  0.031371    300  0.017824\n",
      "6    7  0.033671    322  0.018153\n",
      "7    8  0.036599    350  0.018519\n",
      "8    9  0.039214    375  0.018809\n",
      "9   10  0.041932    401  0.019081\n",
      "10  11  0.044233    423  0.019290\n",
      "11  12  0.047266    452  0.019543\n",
      "12  13  0.048939    468  0.019671\n",
      "13  14  0.051344    491  0.019843\n",
      "14  15  0.053540    512  0.019990\n",
      "15  16  0.055317    529  0.020101\n",
      "16  17  0.057618    551  0.020236\n",
      "17  18  0.058977    564  0.020312\n",
      "18  19  0.060546    579  0.020394\n",
      "19  20  0.062010    593  0.020467\n",
      "20  21  0.064624    618  0.020592\n",
      "21  22  0.065983    631  0.020654\n",
      "22  23  0.067970    650  0.020740\n",
      "23  24  0.069853    668  0.020818\n",
      "24  25  0.071421    683  0.020881\n",
      "25  26  0.073199    700  0.020950\n",
      "26  27  0.074872    716  0.021012\n",
      "27  28  0.076231    729  0.021060\n",
      "28  29  0.077382    740  0.021100\n",
      "29  30  0.078950    755  0.021152\n",
      "\n",
      "imdb_wiki\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.105929   1013  0.105929\n",
      "1    2  0.167416   1601  0.136673\n",
      "2    3  0.211754   2025  0.151452\n",
      "3    4  0.246889   2361  0.160236\n",
      "4    5  0.282129   2698  0.167284\n",
      "5    6  0.310258   2967  0.171972\n",
      "6    7  0.333786   3192  0.175333\n",
      "7    8  0.357106   3415  0.178248\n",
      "8    9  0.376974   3605  0.180455\n",
      "9   10  0.396528   3792  0.182411\n",
      "10  11  0.412318   3943  0.183846\n",
      "11  12  0.428631   4099  0.185206\n",
      "12  13  0.442644   4233  0.186284\n",
      "13  14  0.456238   4363  0.187255\n",
      "14  15  0.469413   4489  0.188133\n",
      "15  16  0.482171   4611  0.188930\n",
      "16  17  0.493464   4719  0.189595\n",
      "17  18  0.504549   4825  0.190211\n",
      "18  19  0.515319   4928  0.190777\n",
      "19  20  0.527031   5040  0.191363\n",
      "20  21  0.536965   5135  0.191836\n",
      "21  22  0.547736   5238  0.192326\n",
      "22  23  0.556206   5319  0.192694\n",
      "23  24  0.565617   5409  0.193086\n",
      "24  25  0.575133   5500  0.193467\n",
      "25  26  0.581617   5562  0.193716\n",
      "26  27  0.589669   5639  0.194014\n",
      "27  28  0.596570   5705  0.194261\n",
      "28  29  0.603472   5771  0.194499\n",
      "29  30  0.610896   5842  0.194746\n",
      "     k       avg  count       MRR\n",
      "0    1  0.068179    652  0.068179\n",
      "1    2  0.120778   1155  0.094479\n",
      "2    3  0.159678   1527  0.107445\n",
      "3    4  0.195859   1873  0.116491\n",
      "4    5  0.225871   2160  0.122493\n",
      "5    6  0.252640   2416  0.126955\n",
      "6    7  0.276378   2643  0.130346\n",
      "7    8  0.296560   2836  0.132868\n",
      "8    9  0.316010   3022  0.135029\n",
      "9   10  0.336819   3221  0.137110\n",
      "10  11  0.354387   3389  0.138707\n",
      "11  12  0.370386   3542  0.140041\n",
      "12  13  0.385444   3686  0.141199\n",
      "13  14  0.400084   3826  0.142245\n",
      "14  15  0.414201   3961  0.143186\n",
      "15  16  0.426226   4076  0.143937\n",
      "16  17  0.442225   4229  0.144879\n",
      "17  18  0.456238   4363  0.145657\n",
      "18  19  0.465544   4452  0.146147\n",
      "19  20  0.477152   4563  0.146727\n",
      "20  21  0.488654   4673  0.147275\n",
      "21  22  0.498484   4767  0.147722\n",
      "22  23  0.507895   4857  0.148131\n",
      "23  24  0.517934   4953  0.148549\n",
      "24  25  0.526404   5034  0.148888\n",
      "25  26  0.535815   5124  0.149250\n",
      "26  27  0.544285   5205  0.149564\n",
      "27  28  0.551396   5273  0.149818\n",
      "28  29  0.560075   5356  0.150117\n",
      "29  30  0.566349   5416  0.150326\n",
      "\n",
      "imdb_wiki\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k       avg  count       MRR\n",
      "0    1  0.966538   9243  0.966538\n",
      "1    2  0.978772   9360  0.972655\n",
      "2    3  0.981387   9385  0.973526\n",
      "3    4  0.983373   9404  0.974023\n",
      "4    5  0.984628   9416  0.974274\n",
      "5    6  0.986720   9436  0.974623\n",
      "6    7  0.987556   9444  0.974742\n",
      "7    8  0.988288   9451  0.974834\n",
      "8    9  0.989125   9459  0.974927\n",
      "9   10  0.989543   9463  0.974968\n",
      "10  11  0.990170   9469  0.975026\n",
      "11  12  0.990902   9476  0.975087\n",
      "12  13  0.991216   9479  0.975111\n",
      "13  14  0.991634   9483  0.975141\n",
      "14  15  0.991739   9484  0.975147\n",
      "15  16  0.991948   9486  0.975161\n",
      "16  17  0.992366   9490  0.975185\n",
      "17  18  0.992471   9491  0.975191\n",
      "18  19  0.992785   9494  0.975207\n",
      "19  20  0.992889   9495  0.975213\n",
      "20  21  0.993098   9497  0.975223\n",
      "21  22  0.993203   9498  0.975227\n",
      "22  23  0.993308   9499  0.975232\n",
      "23  24  0.993517   9501  0.975241\n",
      "24  25  0.993726   9503  0.975249\n",
      "25  26  0.993726   9503  0.975249\n",
      "26  27  0.993726   9503  0.975249\n",
      "27  28  0.993830   9504  0.975253\n",
      "28  29  0.994040   9506  0.975260\n",
      "29  30  0.994144   9507  0.975263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    if 'imdb_wiki' in i and 'OLD' not in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "        conf = load_config(i)\n",
    "        config_knn = get_config_knn_dir(i)\n",
    "        print(conf['data'])\n",
    "        print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "        print(i)\n",
    "        files = get_sorted_files(config_knn)\n",
    "        for j in files:\n",
    "            if 'knn_results' in j:\n",
    "                results = pd.read_pickle(j)\n",
    "                print(results[['k', 'avg', 'count', 'MRR']])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-level",
   "metadata": {},
   "source": [
    "## imdb_fuzzy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "stretch-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_imdb_fuzzy\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.8957   8957  0.895700\n",
      "1    2  0.9257   9257  0.910700\n",
      "2    3  0.9370   9370  0.914467\n",
      "3    4  0.9435   9435  0.916092\n",
      "4    5  0.9481   9481  0.917012\n",
      "5    6  0.9525   9525  0.917745\n",
      "6    7  0.9556   9556  0.918188\n",
      "7    8  0.9579   9579  0.918475\n",
      "8    9  0.9606   9606  0.918775\n",
      "9   10  0.9627   9627  0.918985\n",
      "10  11  0.9647   9647  0.919167\n",
      "11  12  0.9663   9663  0.919301\n",
      "12  13  0.9685   9685  0.919470\n",
      "13  14  0.9703   9703  0.919598\n",
      "14  15  0.9716   9716  0.919685\n",
      "15  16  0.9724   9724  0.919735\n",
      "16  17  0.9731   9731  0.919776\n",
      "17  18  0.9741   9741  0.919832\n",
      "18  19  0.9750   9750  0.919879\n",
      "19  20  0.9758   9758  0.919919\n",
      "20  21  0.9765   9765  0.919952\n",
      "21  22  0.9774   9774  0.919993\n",
      "22  23  0.9780   9780  0.920019\n",
      "23  24  0.9787   9787  0.920049\n",
      "24  25  0.9791   9791  0.920065\n",
      "25  26  0.9798   9798  0.920091\n",
      "26  27  0.9801   9801  0.920103\n",
      "27  28  0.9803   9803  0.920110\n",
      "28  29  0.9810   9810  0.920134\n",
      "29  30  0.9814   9814  0.920147\n",
      "     k     avg  count       MRR\n",
      "0    1  0.8932   8932  0.893200\n",
      "1    2  0.9191   9191  0.906150\n",
      "2    3  0.9337   9337  0.911017\n",
      "3    4  0.9410   9410  0.912842\n",
      "4    5  0.9464   9464  0.913922\n",
      "5    6  0.9498   9498  0.914488\n",
      "6    7  0.9530   9530  0.914945\n",
      "7    8  0.9550   9550  0.915195\n",
      "8    9  0.9574   9574  0.915462\n",
      "9   10  0.9596   9596  0.915682\n",
      "10  11  0.9612   9612  0.915828\n",
      "11  12  0.9631   9631  0.915986\n",
      "12  13  0.9652   9652  0.916147\n",
      "13  14  0.9672   9672  0.916290\n",
      "14  15  0.9687   9687  0.916390\n",
      "15  16  0.9695   9695  0.916440\n",
      "16  17  0.9705   9705  0.916499\n",
      "17  18  0.9711   9711  0.916532\n",
      "18  19  0.9722   9722  0.916590\n",
      "19  20  0.9735   9735  0.916655\n",
      "20  21  0.9744   9744  0.916698\n",
      "21  22  0.9750   9750  0.916726\n",
      "22  23  0.9760   9760  0.916769\n",
      "23  24  0.9762   9762  0.916777\n",
      "24  25  0.9765   9765  0.916789\n",
      "25  26  0.9776   9776  0.916832\n",
      "26  27  0.9778   9778  0.916839\n",
      "27  28  0.9782   9782  0.916853\n",
      "28  29  0.9788   9788  0.916874\n",
      "29  30  0.9793   9793  0.916891\n",
      "\n",
      "small_imdb_fuzzy\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-pretrained-1-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.2069   2069  0.206900\n",
      "1    2  0.2599   2599  0.233400\n",
      "2    3  0.2916   2916  0.243967\n",
      "3    4  0.3148   3148  0.249767\n",
      "4    5  0.3329   3329  0.253387\n",
      "5    6  0.3473   3473  0.255787\n",
      "6    7  0.3630   3630  0.258030\n",
      "7    8  0.3747   3747  0.259492\n",
      "8    9  0.3869   3869  0.260848\n",
      "9   10  0.3985   3985  0.262008\n",
      "10  11  0.4066   4066  0.262744\n",
      "11  12  0.4158   4158  0.263511\n",
      "12  13  0.4264   4264  0.264326\n",
      "13  14  0.4334   4334  0.264826\n",
      "14  15  0.4396   4396  0.265239\n",
      "15  16  0.4468   4468  0.265689\n",
      "16  17  0.4552   4552  0.266183\n",
      "17  18  0.4598   4598  0.266439\n",
      "18  19  0.4658   4658  0.266755\n",
      "19  20  0.4723   4723  0.267080\n",
      "20  21  0.4792   4792  0.267408\n",
      "21  22  0.4831   4831  0.267586\n",
      "22  23  0.4881   4881  0.267803\n",
      "23  24  0.4921   4921  0.267970\n",
      "24  25  0.4963   4963  0.268138\n",
      "25  26  0.5013   5013  0.268330\n",
      "26  27  0.5056   5056  0.268489\n",
      "27  28  0.5101   5101  0.268650\n",
      "28  29  0.5134   5134  0.268764\n",
      "29  30  0.5176   5176  0.268904\n",
      "     k     avg  count       MRR\n",
      "0    1  0.2069   2069  0.206900\n",
      "1    2  0.2599   2599  0.233400\n",
      "2    3  0.2916   2916  0.243967\n",
      "3    4  0.3148   3148  0.249767\n",
      "4    5  0.3329   3329  0.253387\n",
      "5    6  0.3473   3473  0.255787\n",
      "6    7  0.3630   3630  0.258030\n",
      "7    8  0.3747   3747  0.259492\n",
      "8    9  0.3869   3869  0.260848\n",
      "9   10  0.3985   3985  0.262008\n",
      "10  11  0.4066   4066  0.262744\n",
      "11  12  0.4158   4158  0.263511\n",
      "12  13  0.4264   4264  0.264326\n",
      "13  14  0.4334   4334  0.264826\n",
      "14  15  0.4396   4396  0.265239\n",
      "15  16  0.4468   4468  0.265689\n",
      "16  17  0.4552   4552  0.266183\n",
      "17  18  0.4598   4598  0.266439\n",
      "18  19  0.4658   4658  0.266755\n",
      "19  20  0.4723   4723  0.267080\n",
      "20  21  0.4792   4792  0.267408\n",
      "21  22  0.4831   4831  0.267586\n",
      "22  23  0.4881   4881  0.267803\n",
      "23  24  0.4921   4921  0.267970\n",
      "24  25  0.4963   4963  0.268138\n",
      "25  26  0.5013   5013  0.268330\n",
      "26  27  0.5056   5056  0.268489\n",
      "27  28  0.5101   5101  0.268650\n",
      "28  29  0.5134   5134  0.268764\n",
      "29  30  0.5176   5176  0.268904\n",
      "     k     avg  count       MRR\n",
      "0    1  0.2069   2069  0.206900\n",
      "1    2  0.2599   2599  0.233400\n",
      "2    3  0.2916   2916  0.243967\n",
      "3    4  0.3148   3148  0.249767\n",
      "4    5  0.3329   3329  0.253387\n",
      "5    6  0.3473   3473  0.255787\n",
      "6    7  0.3630   3630  0.258030\n",
      "7    8  0.3747   3747  0.259492\n",
      "8    9  0.3869   3869  0.260848\n",
      "9   10  0.3985   3985  0.262008\n",
      "10  11  0.4066   4066  0.262744\n",
      "11  12  0.4158   4158  0.263511\n",
      "12  13  0.4264   4264  0.264326\n",
      "13  14  0.4334   4334  0.264826\n",
      "14  15  0.4396   4396  0.265239\n",
      "15  16  0.4468   4468  0.265689\n",
      "16  17  0.4552   4552  0.266183\n",
      "17  18  0.4598   4598  0.266439\n",
      "18  19  0.4658   4658  0.266755\n",
      "19  20  0.4723   4723  0.267080\n",
      "20  21  0.4792   4792  0.267408\n",
      "21  22  0.4831   4831  0.267586\n",
      "22  23  0.4881   4881  0.267803\n",
      "23  24  0.4921   4921  0.267970\n",
      "24  25  0.4963   4963  0.268138\n",
      "25  26  0.5013   5013  0.268330\n",
      "26  27  0.5056   5056  0.268489\n",
      "27  28  0.5101   5101  0.268650\n",
      "28  29  0.5134   5134  0.268764\n",
      "29  30  0.5176   5176  0.268904\n",
      "     k     avg  count       MRR\n",
      "0    1  0.2069   2069  0.206900\n",
      "1    2  0.2599   2599  0.233400\n",
      "2    3  0.2916   2916  0.243967\n",
      "3    4  0.3148   3148  0.249767\n",
      "4    5  0.3329   3329  0.253387\n",
      "5    6  0.3473   3473  0.255787\n",
      "6    7  0.3630   3630  0.258030\n",
      "7    8  0.3747   3747  0.259492\n",
      "8    9  0.3869   3869  0.260848\n",
      "9   10  0.3985   3985  0.262008\n",
      "10  11  0.4066   4066  0.262744\n",
      "11  12  0.4158   4158  0.263511\n",
      "12  13  0.4264   4264  0.264326\n",
      "13  14  0.4334   4334  0.264826\n",
      "14  15  0.4396   4396  0.265239\n",
      "15  16  0.4468   4468  0.265689\n",
      "16  17  0.4552   4552  0.266183\n",
      "17  18  0.4598   4598  0.266439\n",
      "18  19  0.4658   4658  0.266755\n",
      "19  20  0.4723   4723  0.267080\n",
      "20  21  0.4792   4792  0.267408\n",
      "21  22  0.4831   4831  0.267586\n",
      "22  23  0.4881   4881  0.267803\n",
      "23  24  0.4921   4921  0.267970\n",
      "24  25  0.4963   4963  0.268138\n",
      "25  26  0.5013   5013  0.268330\n",
      "26  27  0.5056   5056  0.268489\n",
      "27  28  0.5101   5101  0.268650\n",
      "28  29  0.5134   5134  0.268764\n",
      "29  30  0.5176   5176  0.268904\n",
      "\n",
      "small_imdb_fuzzy\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/small_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-pretrained-MLMBM25-1-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.1632   1632  0.163200\n",
      "1    2  0.1969   1969  0.180050\n",
      "2    3  0.2188   2188  0.187350\n",
      "3    4  0.2370   2370  0.191900\n",
      "4    5  0.2502   2502  0.194540\n",
      "5    6  0.2607   2607  0.196290\n",
      "6    7  0.2710   2710  0.197761\n",
      "7    8  0.2789   2789  0.198749\n",
      "8    9  0.2854   2854  0.199471\n",
      "9   10  0.2932   2932  0.200251\n",
      "10  11  0.2995   2995  0.200824\n",
      "11  12  0.3064   3064  0.201399\n",
      "12  13  0.3124   3124  0.201860\n",
      "13  14  0.3189   3189  0.202325\n",
      "14  15  0.3238   3238  0.202651\n",
      "15  16  0.3289   3289  0.202970\n",
      "16  17  0.3332   3332  0.203223\n",
      "17  18  0.3387   3387  0.203529\n",
      "18  19  0.3431   3431  0.203760\n",
      "19  20  0.3468   3468  0.203945\n",
      "20  21  0.3503   3503  0.204112\n",
      "21  22  0.3533   3533  0.204248\n",
      "22  23  0.3572   3572  0.204418\n",
      "23  24  0.3610   3610  0.204576\n",
      "24  25  0.3659   3659  0.204772\n",
      "25  26  0.3697   3697  0.204918\n",
      "26  27  0.3734   3734  0.205055\n",
      "27  28  0.3764   3764  0.205162\n",
      "28  29  0.3792   3792  0.205259\n",
      "29  30  0.3821   3821  0.205356\n",
      "     k     avg  count       MRR\n",
      "0    1  0.1632   1632  0.163200\n",
      "1    2  0.1969   1969  0.180050\n",
      "2    3  0.2188   2188  0.187350\n",
      "3    4  0.2370   2370  0.191900\n",
      "4    5  0.2502   2502  0.194540\n",
      "5    6  0.2607   2607  0.196290\n",
      "6    7  0.2710   2710  0.197761\n",
      "7    8  0.2789   2789  0.198749\n",
      "8    9  0.2854   2854  0.199471\n",
      "9   10  0.2932   2932  0.200251\n",
      "10  11  0.2995   2995  0.200824\n",
      "11  12  0.3064   3064  0.201399\n",
      "12  13  0.3124   3124  0.201860\n",
      "13  14  0.3189   3189  0.202325\n",
      "14  15  0.3238   3238  0.202651\n",
      "15  16  0.3289   3289  0.202970\n",
      "16  17  0.3332   3332  0.203223\n",
      "17  18  0.3387   3387  0.203529\n",
      "18  19  0.3431   3431  0.203760\n",
      "19  20  0.3468   3468  0.203945\n",
      "20  21  0.3503   3503  0.204112\n",
      "21  22  0.3533   3533  0.204248\n",
      "22  23  0.3572   3572  0.204418\n",
      "23  24  0.3610   3610  0.204576\n",
      "24  25  0.3659   3659  0.204772\n",
      "25  26  0.3697   3697  0.204918\n",
      "26  27  0.3734   3734  0.205055\n",
      "27  28  0.3764   3764  0.205162\n",
      "28  29  0.3792   3792  0.205259\n",
      "29  30  0.3821   3821  0.205356\n",
      "     k     avg  count       MRR\n",
      "0    1  0.1632   1632  0.163200\n",
      "1    2  0.1969   1969  0.180050\n",
      "2    3  0.2188   2188  0.187350\n",
      "3    4  0.2370   2370  0.191900\n",
      "4    5  0.2502   2502  0.194540\n",
      "5    6  0.2607   2607  0.196290\n",
      "6    7  0.2710   2710  0.197761\n",
      "7    8  0.2789   2789  0.198749\n",
      "8    9  0.2854   2854  0.199471\n",
      "9   10  0.2932   2932  0.200251\n",
      "10  11  0.2995   2995  0.200824\n",
      "11  12  0.3064   3064  0.201399\n",
      "12  13  0.3124   3124  0.201860\n",
      "13  14  0.3189   3189  0.202325\n",
      "14  15  0.3238   3238  0.202651\n",
      "15  16  0.3289   3289  0.202970\n",
      "16  17  0.3332   3332  0.203223\n",
      "17  18  0.3387   3387  0.203529\n",
      "18  19  0.3431   3431  0.203760\n",
      "19  20  0.3468   3468  0.203945\n",
      "20  21  0.3503   3503  0.204112\n",
      "21  22  0.3533   3533  0.204248\n",
      "22  23  0.3572   3572  0.204418\n",
      "23  24  0.3610   3610  0.204576\n",
      "24  25  0.3659   3659  0.204772\n",
      "25  26  0.3697   3697  0.204918\n",
      "26  27  0.3734   3734  0.205055\n",
      "27  28  0.3764   3764  0.205162\n",
      "28  29  0.3792   3792  0.205259\n",
      "29  30  0.3821   3821  0.205356\n",
      "\n",
      "small_imdb_fuzzy\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/small_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.5113   5113  0.511300\n",
      "1    2  0.6493   6493  0.580300\n",
      "2    3  0.7207   7207  0.604100\n",
      "3    4  0.7641   7641  0.614950\n",
      "4    5  0.7986   7986  0.621850\n",
      "5    6  0.8244   8244  0.626150\n",
      "6    7  0.8448   8448  0.629064\n",
      "7    8  0.8603   8603  0.631002\n",
      "8    9  0.8723   8723  0.632335\n",
      "9   10  0.8842   8842  0.633525\n",
      "10  11  0.8952   8952  0.634525\n",
      "11  12  0.9032   9032  0.635192\n",
      "12  13  0.9092   9092  0.635653\n",
      "13  14  0.9158   9158  0.636125\n",
      "14  15  0.9229   9229  0.636598\n",
      "15  16  0.9283   9283  0.636936\n",
      "16  17  0.9328   9328  0.637200\n",
      "17  18  0.9372   9372  0.637445\n",
      "18  19  0.9404   9404  0.637613\n",
      "19  20  0.9436   9436  0.637773\n",
      "20  21  0.9461   9461  0.637892\n",
      "21  22  0.9490   9490  0.638024\n",
      "22  23  0.9520   9520  0.638154\n",
      "23  24  0.9545   9545  0.638259\n",
      "24  25  0.9556   9556  0.638303\n",
      "25  26  0.9569   9569  0.638353\n",
      "26  27  0.9586   9586  0.638416\n",
      "27  28  0.9601   9601  0.638469\n",
      "28  29  0.9625   9625  0.638552\n",
      "29  30  0.9642   9642  0.638609\n",
      "\n",
      "small_imdb_fuzzy\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/small_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//small_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.9540   9540  0.954000\n",
      "1    2  0.9690   9690  0.961500\n",
      "2    3  0.9755   9755  0.963667\n",
      "3    4  0.9794   9794  0.964642\n",
      "4    5  0.9808   9808  0.964922\n",
      "5    6  0.9832   9832  0.965322\n",
      "6    7  0.9847   9847  0.965536\n",
      "7    8  0.9855   9855  0.965636\n",
      "8    9  0.9859   9859  0.965680\n",
      "9   10  0.9866   9866  0.965750\n",
      "10  11  0.9874   9874  0.965823\n",
      "11  12  0.9883   9883  0.965898\n",
      "12  13  0.9889   9889  0.965944\n",
      "13  14  0.9898   9898  0.966009\n",
      "14  15  0.9903   9903  0.966042\n",
      "15  16  0.9914   9914  0.966111\n",
      "16  17  0.9924   9924  0.966169\n",
      "17  18  0.9932   9932  0.966214\n",
      "18  19  0.9934   9934  0.966224\n",
      "19  20  0.9938   9938  0.966244\n",
      "20  21  0.9940   9940  0.966254\n",
      "21  22  0.9945   9945  0.966277\n",
      "22  23  0.9948   9948  0.966290\n",
      "23  24  0.9948   9948  0.966290\n",
      "24  25  0.9951   9951  0.966302\n",
      "25  26  0.9954   9954  0.966313\n",
      "26  27  0.9957   9957  0.966324\n",
      "27  28  0.9959   9959  0.966332\n",
      "28  29  0.9959   9959  0.966332\n",
      "29  30  0.9961   9961  0.966338\n",
      "     k     avg  count       MRR\n",
      "0    1  0.9433   9433  0.943300\n",
      "1    2  0.9636   9636  0.953450\n",
      "2    3  0.9716   9716  0.956117\n",
      "3    4  0.9761   9761  0.957242\n",
      "4    5  0.9800   9800  0.958022\n",
      "5    6  0.9820   9820  0.958355\n",
      "6    7  0.9839   9839  0.958626\n",
      "7    8  0.9854   9854  0.958814\n",
      "8    9  0.9866   9866  0.958947\n",
      "9   10  0.9877   9877  0.959057\n",
      "10  11  0.9885   9885  0.959130\n",
      "11  12  0.9892   9892  0.959188\n",
      "12  13  0.9902   9902  0.959265\n",
      "13  14  0.9905   9905  0.959287\n",
      "14  15  0.9915   9915  0.959353\n",
      "15  16  0.9921   9921  0.959391\n",
      "16  17  0.9925   9925  0.959414\n",
      "17  18  0.9934   9934  0.959464\n",
      "18  19  0.9934   9934  0.959464\n",
      "19  20  0.9941   9941  0.959499\n",
      "20  21  0.9945   9945  0.959518\n",
      "21  22  0.9950   9950  0.959541\n",
      "22  23  0.9951   9951  0.959545\n",
      "23  24  0.9953   9953  0.959554\n",
      "24  25  0.9955   9955  0.959562\n",
      "25  26  0.9958   9958  0.959573\n",
      "26  27  0.9962   9962  0.959588\n",
      "27  28  0.9964   9964  0.959595\n",
      "28  29  0.9965   9965  0.959599\n",
      "29  30  0.9967   9967  0.959605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k     avg  count       MRR\n",
      "0    1  0.9592   9592  0.959200\n",
      "1    2  0.9726   9726  0.965900\n",
      "2    3  0.9794   9794  0.968167\n",
      "3    4  0.9824   9824  0.968917\n",
      "4    5  0.9848   9848  0.969397\n",
      "5    6  0.9874   9874  0.969830\n",
      "6    7  0.9885   9885  0.969987\n",
      "7    8  0.9895   9895  0.970112\n",
      "8    9  0.9909   9909  0.970268\n",
      "9   10  0.9916   9916  0.970338\n",
      "10  11  0.9921   9921  0.970383\n",
      "11  12  0.9933   9933  0.970483\n",
      "12  13  0.9943   9943  0.970560\n",
      "13  14  0.9945   9945  0.970574\n",
      "14  15  0.9949   9949  0.970601\n",
      "15  16  0.9952   9952  0.970620\n",
      "16  17  0.9958   9958  0.970655\n",
      "17  18  0.9960   9960  0.970666\n",
      "18  19  0.9963   9963  0.970682\n",
      "19  20  0.9965   9965  0.970692\n",
      "20  21  0.9969   9969  0.970711\n",
      "21  22  0.9970   9970  0.970716\n",
      "22  23  0.9972   9972  0.970724\n",
      "23  24  0.9972   9972  0.970724\n",
      "24  25  0.9972   9972  0.970724\n",
      "25  26  0.9976   9976  0.970740\n",
      "26  27  0.9976   9976  0.970740\n",
      "27  28  0.9976   9976  0.970740\n",
      "28  29  0.9976   9976  0.970740\n",
      "29  30  0.9978   9978  0.970746\n",
      "     k     avg  count       MRR\n",
      "0    1  0.9524   9524  0.952400\n",
      "1    2  0.9700   9700  0.961200\n",
      "2    3  0.9771   9771  0.963567\n",
      "3    4  0.9809   9809  0.964517\n",
      "4    5  0.9824   9824  0.964817\n",
      "5    6  0.9845   9845  0.965167\n",
      "6    7  0.9862   9862  0.965410\n",
      "7    8  0.9878   9878  0.965610\n",
      "8    9  0.9895   9895  0.965798\n",
      "9   10  0.9902   9902  0.965868\n",
      "10  11  0.9914   9914  0.965978\n",
      "11  12  0.9918   9918  0.966011\n",
      "12  13  0.9925   9925  0.966065\n",
      "13  14  0.9931   9931  0.966108\n",
      "14  15  0.9931   9931  0.966108\n",
      "15  16  0.9934   9934  0.966126\n",
      "16  17  0.9940   9940  0.966162\n",
      "17  18  0.9947   9947  0.966200\n",
      "18  19  0.9948   9948  0.966206\n",
      "19  20  0.9949   9949  0.966211\n",
      "20  21  0.9952   9952  0.966225\n",
      "21  22  0.9957   9957  0.966248\n",
      "22  23  0.9961   9961  0.966265\n",
      "23  24  0.9961   9961  0.966265\n",
      "24  25  0.9961   9961  0.966265\n",
      "25  26  0.9963   9963  0.966273\n",
      "26  27  0.9965   9965  0.966280\n",
      "27  28  0.9966   9966  0.966284\n",
      "28  29  0.9967   9967  0.966287\n",
      "29  30  0.9967   9967  0.966287\n",
      "     k     avg  count       MRR\n",
      "0    1  0.9541   9541  0.954100\n",
      "1    2  0.9702   9702  0.962150\n",
      "2    3  0.9767   9767  0.964317\n",
      "3    4  0.9814   9814  0.965492\n",
      "4    5  0.9839   9839  0.965992\n",
      "5    6  0.9866   9866  0.966442\n",
      "6    7  0.9878   9878  0.966613\n",
      "7    8  0.9892   9892  0.966788\n",
      "8    9  0.9909   9909  0.966977\n",
      "9   10  0.9916   9916  0.967047\n",
      "10  11  0.9919   9919  0.967074\n",
      "11  12  0.9927   9927  0.967141\n",
      "12  13  0.9929   9929  0.967156\n",
      "13  14  0.9933   9933  0.967185\n",
      "14  15  0.9936   9936  0.967205\n",
      "15  16  0.9940   9940  0.967230\n",
      "16  17  0.9944   9944  0.967253\n",
      "17  18  0.9944   9944  0.967253\n",
      "18  19  0.9949   9949  0.967280\n",
      "19  20  0.9951   9951  0.967290\n",
      "20  21  0.9955   9955  0.967309\n",
      "21  22  0.9956   9956  0.967313\n",
      "22  23  0.9959   9959  0.967326\n",
      "23  24  0.9959   9959  0.967326\n",
      "24  25  0.9962   9962  0.967338\n",
      "25  26  0.9963   9963  0.967342\n",
      "26  27  0.9964   9964  0.967346\n",
      "27  28  0.9967   9967  0.967357\n",
      "28  29  0.9968   9968  0.967360\n",
      "29  30  0.9969   9969  0.967363\n",
      "     k     avg  count       MRR\n",
      "0    1  0.9503   9503  0.950300\n",
      "1    2  0.9681   9681  0.959200\n",
      "2    3  0.9761   9761  0.961867\n",
      "3    4  0.9802   9802  0.962892\n",
      "4    5  0.9835   9835  0.963552\n",
      "5    6  0.9852   9852  0.963835\n",
      "6    7  0.9864   9864  0.964006\n",
      "7    8  0.9878   9878  0.964181\n",
      "8    9  0.9889   9889  0.964304\n",
      "9   10  0.9902   9902  0.964434\n",
      "10  11  0.9910   9910  0.964506\n",
      "11  12  0.9917   9917  0.964565\n",
      "12  13  0.9922   9922  0.964603\n",
      "13  14  0.9927   9927  0.964639\n",
      "14  15  0.9935   9935  0.964692\n",
      "15  16  0.9938   9938  0.964711\n",
      "16  17  0.9940   9940  0.964723\n",
      "17  18  0.9944   9944  0.964745\n",
      "18  19  0.9945   9945  0.964750\n",
      "19  20  0.9950   9950  0.964775\n",
      "20  21  0.9952   9952  0.964785\n",
      "21  22  0.9959   9959  0.964817\n",
      "22  23  0.9962   9962  0.964830\n",
      "23  24  0.9964   9964  0.964838\n",
      "24  25  0.9964   9964  0.964838\n",
      "25  26  0.9965   9965  0.964842\n",
      "26  27  0.9967   9967  0.964849\n",
      "27  28  0.9969   9969  0.964856\n",
      "28  29  0.9970   9970  0.964860\n",
      "29  30  0.9971   9971  0.964863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    if 'small_imdb_fuzzy' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "        conf = load_config(i)\n",
    "        config_knn = get_config_knn_dir(i)\n",
    "        print(conf['data'])\n",
    "        print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "        print(i)\n",
    "        files = get_sorted_files(config_knn)\n",
    "        for j in files:\n",
    "            if 'knn_results' in j:\n",
    "                results = pd.read_pickle(j)\n",
    "                print(results[['k', 'avg', 'count', 'MRR']])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-montreal",
   "metadata": {},
   "source": [
    "## imdb_fuzzy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "agricultural-jersey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard_imdb_fuzzy\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.6536   6536  0.653600\n",
      "1    2  0.7175   7175  0.685550\n",
      "2    3  0.7534   7534  0.697517\n",
      "3    4  0.7742   7742  0.702717\n",
      "4    5  0.7909   7909  0.706057\n",
      "5    6  0.8038   8038  0.708207\n",
      "6    7  0.8140   8140  0.709664\n",
      "7    8  0.8219   8219  0.710651\n",
      "8    9  0.8297   8297  0.711518\n",
      "9   10  0.8363   8363  0.712178\n",
      "10  11  0.8418   8418  0.712678\n",
      "11  12  0.8463   8463  0.713053\n",
      "12  13  0.8522   8522  0.713507\n",
      "13  14  0.8576   8576  0.713893\n",
      "14  15  0.8620   8620  0.714186\n",
      "15  16  0.8654   8654  0.714398\n",
      "16  17  0.8691   8691  0.714616\n",
      "17  18  0.8729   8729  0.714827\n",
      "18  19  0.8764   8764  0.715011\n",
      "19  20  0.8799   8799  0.715186\n",
      "20  21  0.8822   8822  0.715296\n",
      "21  22  0.8846   8846  0.715405\n",
      "22  23  0.8862   8862  0.715475\n",
      "23  24  0.8882   8882  0.715558\n",
      "24  25  0.8911   8911  0.715674\n",
      "25  26  0.8929   8929  0.715743\n",
      "26  27  0.8949   8949  0.715817\n",
      "27  28  0.8966   8966  0.715878\n",
      "28  29  0.8987   8987  0.715950\n",
      "29  30  0.8998   8998  0.715987\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-pretrained-1-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.0663    663  0.066300\n",
      "1    2  0.0891    891  0.077700\n",
      "2    3  0.1039   1039  0.082633\n",
      "3    4  0.1153   1153  0.085483\n",
      "4    5  0.1253   1253  0.087483\n",
      "5    6  0.1327   1327  0.088717\n",
      "6    7  0.1419   1419  0.090031\n",
      "7    8  0.1493   1493  0.090956\n",
      "8    9  0.1549   1549  0.091578\n",
      "9   10  0.1622   1622  0.092308\n",
      "10  11  0.1676   1676  0.092799\n",
      "11  12  0.1730   1730  0.093249\n",
      "12  13  0.1778   1778  0.093618\n",
      "13  14  0.1823   1823  0.093940\n",
      "14  15  0.1855   1855  0.094153\n",
      "15  16  0.1901   1901  0.094441\n",
      "16  17  0.1935   1935  0.094641\n",
      "17  18  0.1971   1971  0.094841\n",
      "18  19  0.2018   2018  0.095088\n",
      "19  20  0.2051   2051  0.095253\n",
      "20  21  0.2095   2095  0.095462\n",
      "21  22  0.2134   2134  0.095640\n",
      "22  23  0.2173   2173  0.095809\n",
      "23  24  0.2206   2206  0.095947\n",
      "24  25  0.2237   2237  0.096071\n",
      "25  26  0.2267   2267  0.096186\n",
      "26  27  0.2309   2309  0.096342\n",
      "27  28  0.2334   2334  0.096431\n",
      "28  29  0.2366   2366  0.096541\n",
      "29  30  0.2394   2394  0.096635\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-pretrained-MLMBM25-1-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.1516   1516  0.151600\n",
      "1    2  0.1972   1972  0.174400\n",
      "2    3  0.2291   2291  0.185033\n",
      "3    4  0.2514   2514  0.190608\n",
      "4    5  0.2713   2713  0.194588\n",
      "5    6  0.2874   2874  0.197272\n",
      "6    7  0.3003   3003  0.199115\n",
      "7    8  0.3132   3132  0.200727\n",
      "8    9  0.3237   3237  0.201894\n",
      "9   10  0.3326   3326  0.202784\n",
      "10  11  0.3438   3438  0.203802\n",
      "11  12  0.3526   3526  0.204535\n",
      "12  13  0.3616   3616  0.205228\n",
      "13  14  0.3684   3684  0.205713\n",
      "14  15  0.3749   3749  0.206147\n",
      "15  16  0.3816   3816  0.206565\n",
      "16  17  0.3893   3893  0.207018\n",
      "17  18  0.3940   3940  0.207279\n",
      "18  19  0.3998   3998  0.207585\n",
      "19  20  0.4054   4054  0.207865\n",
      "20  21  0.4109   4109  0.208127\n",
      "21  22  0.4160   4160  0.208358\n",
      "22  23  0.4207   4207  0.208563\n",
      "23  24  0.4261   4261  0.208788\n",
      "24  25  0.4301   4301  0.208948\n",
      "25  26  0.4345   4345  0.209117\n",
      "26  27  0.4386   4386  0.209269\n",
      "27  28  0.4413   4413  0.209365\n",
      "28  29  0.4458   4458  0.209520\n",
      "29  30  0.4494   4494  0.209640\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.3734   3734  0.373400\n",
      "1    2  0.5026   5026  0.438000\n",
      "2    3  0.5793   5793  0.463567\n",
      "3    4  0.6351   6351  0.477517\n",
      "4    5  0.6756   6756  0.485617\n",
      "5    6  0.7080   7080  0.491017\n",
      "6    7  0.7332   7332  0.494617\n",
      "7    8  0.7527   7527  0.497054\n",
      "8    9  0.7720   7720  0.499199\n",
      "9   10  0.7864   7864  0.500639\n",
      "10  11  0.8030   8030  0.502148\n",
      "11  12  0.8148   8148  0.503131\n",
      "12  13  0.8257   8257  0.503969\n",
      "13  14  0.8366   8366  0.504748\n",
      "14  15  0.8451   8451  0.505315\n",
      "15  16  0.8541   8541  0.505877\n",
      "16  17  0.8624   8624  0.506365\n",
      "17  18  0.8696   8696  0.506765\n",
      "18  19  0.8773   8773  0.507171\n",
      "19  20  0.8838   8838  0.507496\n",
      "20  21  0.8888   8888  0.507734\n",
      "21  22  0.8941   8941  0.507975\n",
      "22  23  0.8984   8984  0.508162\n",
      "23  24  0.9038   9038  0.508387\n",
      "24  25  0.9081   9081  0.508559\n",
      "25  26  0.9127   9127  0.508736\n",
      "26  27  0.9166   9166  0.508880\n",
      "27  28  0.9198   9198  0.508994\n",
      "28  29  0.9233   9233  0.509115\n",
      "29  30  0.9263   9263  0.509215\n",
      "     k     avg  count       MRR\n",
      "0    1  0.3160   3160  0.316000\n",
      "1    2  0.4595   4595  0.387750\n",
      "2    3  0.5391   5391  0.414283\n",
      "3    4  0.5992   5992  0.429308\n",
      "4    5  0.6451   6451  0.438488\n",
      "5    6  0.6856   6856  0.445238\n",
      "6    7  0.7172   7172  0.449753\n",
      "7    8  0.7431   7431  0.452990\n",
      "8    9  0.7666   7666  0.455601\n",
      "9   10  0.7840   7840  0.457341\n",
      "10  11  0.8004   8004  0.458832\n",
      "11  12  0.8147   8147  0.460024\n",
      "12  13  0.8281   8281  0.461055\n",
      "13  14  0.8396   8396  0.461876\n",
      "14  15  0.8498   8498  0.462556\n",
      "15  16  0.8581   8581  0.463075\n",
      "16  17  0.8652   8652  0.463492\n",
      "17  18  0.8732   8732  0.463937\n",
      "18  19  0.8816   8816  0.464379\n",
      "19  20  0.8877   8877  0.464684\n",
      "20  21  0.8941   8941  0.464989\n",
      "21  22  0.8983   8983  0.465180\n",
      "22  23  0.9041   9041  0.465432\n",
      "23  24  0.9078   9078  0.465586\n",
      "24  25  0.9117   9117  0.465742\n",
      "25  26  0.9158   9158  0.465900\n",
      "26  27  0.9191   9191  0.466022\n",
      "27  28  0.9225   9225  0.466143\n",
      "28  29  0.9260   9260  0.466264\n",
      "29  30  0.9296   9296  0.466384\n",
      "\n",
      "hard_imdb_fuzzy\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/hard_imdb_fuzzy-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//hard_imdb_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "     k     avg  count       MRR\n",
      "0    1  0.9156   9156  0.915600\n",
      "1    2  0.9482   9482  0.931900\n",
      "2    3  0.9619   9619  0.936467\n",
      "3    4  0.9706   9706  0.938642\n",
      "4    5  0.9759   9759  0.939702\n",
      "5    6  0.9791   9791  0.940235\n",
      "6    7  0.9814   9814  0.940564\n",
      "7    8  0.9834   9834  0.940814\n",
      "8    9  0.9847   9847  0.940958\n",
      "9   10  0.9863   9863  0.941118\n",
      "10  11  0.9870   9870  0.941182\n",
      "11  12  0.9876   9876  0.941232\n",
      "12  13  0.9885   9885  0.941301\n",
      "13  14  0.9893   9893  0.941358\n",
      "14  15  0.9898   9898  0.941391\n",
      "15  16  0.9906   9906  0.941441\n",
      "16  17  0.9908   9908  0.941453\n",
      "17  18  0.9915   9915  0.941492\n",
      "18  19  0.9919   9919  0.941513\n",
      "19  20  0.9925   9925  0.941543\n",
      "20  21  0.9929   9929  0.941562\n",
      "21  22  0.9936   9936  0.941594\n",
      "22  23  0.9939   9939  0.941607\n",
      "23  24  0.9939   9939  0.941607\n",
      "24  25  0.9940   9940  0.941611\n",
      "25  26  0.9944   9944  0.941626\n",
      "26  27  0.9945   9945  0.941630\n",
      "27  28  0.9948   9948  0.941641\n",
      "28  29  0.9949   9949  0.941644\n",
      "29  30  0.9951   9951  0.941651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    if 'hard_imdb_fuzzy' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "        conf = load_config(i)\n",
    "        config_knn = get_config_knn_dir(i)\n",
    "        print(conf['data'])\n",
    "        print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "        print(i)\n",
    "        files = get_sorted_files(config_knn)\n",
    "        for j in files:\n",
    "            if 'knn_results' in j:\n",
    "                results = pd.read_pickle(j)\n",
    "                print(results[['k', 'avg', 'count', 'MRR']])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-applicant",
   "metadata": {},
   "source": [
    "# DeepMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-chest",
   "metadata": {},
   "source": [
    "## single-triplet ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "extreme-fossil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/abt_buy_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-5743-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.893939  0.859223  0.876238\n",
      "1    2  0.623377  0.932039  0.747082\n",
      "2    3  0.544944  0.941748  0.690391\n",
      "3    4  0.481481  0.946602  0.638298\n",
      "4    5  0.431416  0.946602  0.592705\n",
      "5    6  0.401235  0.946602  0.563584\n",
      "6    7  0.381044  0.956311  0.544952\n",
      "7    8  0.366853  0.956311  0.530283\n",
      "8    9  0.353047  0.956311  0.515707\n",
      "9   10  0.340242  0.956311  0.501911\n",
      "10  11  0.334459  0.961165  0.496241\n",
      "11  12  0.324104  0.966019  0.485366\n",
      "12  13  0.316957  0.970874  0.477897\n",
      "13  14  0.309707  0.975728  0.470175\n",
      "14  15  0.303303  0.980583  0.463303\n",
      "15  16  0.295754  0.980583  0.454443\n",
      "16  17  0.292929  0.985437  0.451613\n",
      "17  18  0.286319  0.985437  0.443716\n",
      "18  19  0.281553  0.985437  0.437972\n",
      "19  20  0.278308  0.990291  0.434505\n",
      "20  21  0.275304  0.990291  0.430834\n",
      "21  22  0.267717  0.990291  0.421488\n",
      "22  23  0.264591  0.990291  0.417605\n",
      "23  24  0.261874  0.990291  0.414213\n",
      "24  25  0.258228  0.990291  0.409639\n",
      "25  26  0.255319  0.990291  0.405970\n",
      "26  27  0.254047  0.990291  0.404361\n",
      "27  28  0.250923  0.990291  0.400393\n",
      "28  29  0.249694  0.990291  0.398827\n",
      "29  30  0.247273  0.990291  0.395732\n",
      "     k       avg     count       MRR\n",
      "0    1  0.928571  0.820388  0.871134\n",
      "1    2  0.642105  0.888350  0.745418\n",
      "2    3  0.540462  0.907767  0.677536\n",
      "3    4  0.480818  0.912621  0.629816\n",
      "4    5  0.453461  0.922330  0.608000\n",
      "5    6  0.431767  0.936893  0.591118\n",
      "6    7  0.415778  0.946602  0.577778\n",
      "7    8  0.399590  0.946602  0.561960\n",
      "8    9  0.386905  0.946602  0.549296\n",
      "9   10  0.376448  0.946602  0.538674\n",
      "10  11  0.368914  0.956311  0.532432\n",
      "11  12  0.361468  0.956311  0.524634\n",
      "12  13  0.351159  0.956311  0.513690\n",
      "13  14  0.342609  0.956311  0.504481\n",
      "14  15  0.332770  0.956311  0.493734\n",
      "15  16  0.327787  0.956311  0.488228\n",
      "16  17  0.321370  0.956311  0.481074\n",
      "17  18  0.318841  0.961165  0.478839\n",
      "18  19  0.314961  0.970874  0.475624\n",
      "19  20  0.310185  0.975728  0.470726\n",
      "20  21  0.304085  0.975728  0.463668\n",
      "21  22  0.299107  0.975728  0.457859\n",
      "22  23  0.296024  0.975728  0.454237\n",
      "23  24  0.293860  0.975728  0.451685\n",
      "24  25  0.290883  0.975728  0.448161\n",
      "25  26  0.289398  0.980583  0.446903\n",
      "26  27  0.284507  0.980583  0.441048\n",
      "27  28  0.280946  0.980583  0.436757\n",
      "28  29  0.278237  0.980583  0.433476\n",
      "29  30  0.276712  0.980583  0.431624\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/amazon_google_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-6874-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.672000  0.717949  0.694215\n",
      "1    2  0.515385  0.858974  0.644231\n",
      "2    3  0.434959  0.914530  0.589532\n",
      "3    4  0.389565  0.957265  0.553770\n",
      "4    5  0.357030  0.965812  0.521338\n",
      "5    6  0.328488  0.965812  0.490239\n",
      "6    7  0.313536  0.970085  0.473904\n",
      "7    8  0.300000  0.974359  0.458753\n",
      "8    9  0.287141  0.982906  0.444444\n",
      "9   10  0.277778  0.982906  0.433145\n",
      "10  11  0.268378  0.982906  0.421632\n",
      "11  12  0.258718  0.982906  0.409617\n",
      "12  13  0.253304  0.982906  0.402802\n",
      "13  14  0.249187  0.982906  0.397580\n",
      "14  15  0.245989  0.982906  0.393499\n",
      "15  16  0.239583  0.982906  0.385260\n",
      "16  17  0.235174  0.982906  0.379538\n",
      "17  18  0.231621  0.982906  0.374898\n",
      "18  19  0.228036  0.987179  0.370489\n",
      "19  20  0.224371  0.991453  0.365931\n",
      "20  21  0.220323  0.991453  0.360528\n",
      "21  22  0.217636  0.991453  0.356923\n",
      "22  23  0.215413  0.991453  0.353928\n",
      "23  24  0.213039  0.991453  0.350718\n",
      "24  25  0.211101  0.991453  0.348087\n",
      "25  26  0.209386  0.991453  0.345753\n",
      "26  27  0.207513  0.991453  0.343195\n",
      "27  28  0.206222  0.991453  0.341428\n",
      "28  29  0.204405  0.991453  0.338934\n",
      "29  30  0.202091  0.991453  0.335745\n",
      "     k       avg     count       MRR\n",
      "0    1  0.695833  0.713675  0.704641\n",
      "1    2  0.541555  0.863248  0.665568\n",
      "2    3  0.460215  0.914530  0.612303\n",
      "3    4  0.404372  0.948718  0.567050\n",
      "4    5  0.370248  0.957265  0.533969\n",
      "5    6  0.336310  0.965812  0.498896\n",
      "6    7  0.320225  0.974359  0.482030\n",
      "7    8  0.304927  0.978632  0.464975\n",
      "8    9  0.291878  0.982906  0.450098\n",
      "9   10  0.281174  0.982906  0.437262\n",
      "10  11  0.275000  0.987179  0.430168\n",
      "11  12  0.268605  0.987179  0.422303\n",
      "12  13  0.259843  0.987179  0.411398\n",
      "13  14  0.252459  0.987179  0.402089\n",
      "14  15  0.249730  0.987179  0.398619\n",
      "15  16  0.246006  0.987179  0.393862\n",
      "16  17  0.243158  0.987179  0.390203\n",
      "17  18  0.239875  0.987179  0.385965\n",
      "18  19  0.234518  0.987179  0.378999\n",
      "19  20  0.231695  0.987179  0.375305\n",
      "20  21  0.229023  0.991453  0.372093\n",
      "21  22  0.225681  0.991453  0.367670\n",
      "22  23  0.222435  0.991453  0.363352\n",
      "23  24  0.219697  0.991453  0.359690\n",
      "24  25  0.217840  0.991453  0.357198\n",
      "25  26  0.216418  0.991453  0.355283\n",
      "26  27  0.215413  0.991453  0.353928\n",
      "27  28  0.213628  0.991453  0.351515\n",
      "28  29  0.211679  0.991453  0.348872\n",
      "29  30  0.209955  0.991453  0.346527\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/beer_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-uncased-masked-ALL-BM25-single-triplet-268-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.866667  0.928571  0.896552\n",
      "1    2  0.812500  0.928571  0.866667\n",
      "2    3  0.722222  0.928571  0.812500\n",
      "3    4  0.684211  0.928571  0.787879\n",
      "4    5  0.684211  0.928571  0.787879\n",
      "5    6  0.684211  0.928571  0.787879\n",
      "6    7  0.684211  0.928571  0.787879\n",
      "7    8  0.684211  0.928571  0.787879\n",
      "8    9  0.684211  0.928571  0.787879\n",
      "9   10  0.684211  0.928571  0.787879\n",
      "10  11  0.684211  0.928571  0.787879\n",
      "11  12  0.684211  0.928571  0.787879\n",
      "12  13  0.684211  0.928571  0.787879\n",
      "13  14  0.684211  0.928571  0.787879\n",
      "14  15  0.650000  0.928571  0.764706\n",
      "15  16  0.650000  0.928571  0.764706\n",
      "16  17  0.650000  0.928571  0.764706\n",
      "17  18  0.650000  0.928571  0.764706\n",
      "18  19  0.650000  0.928571  0.764706\n",
      "19  20  0.650000  0.928571  0.764706\n",
      "20  21  0.650000  0.928571  0.764706\n",
      "21  22  0.619048  0.928571  0.742857\n",
      "22  23  0.590909  0.928571  0.722222\n",
      "23  24  0.590909  0.928571  0.722222\n",
      "24  25  0.565217  0.928571  0.702703\n",
      "25  26  0.541667  0.928571  0.684211\n",
      "26  27  0.541667  0.928571  0.684211\n",
      "27  28  0.541667  0.928571  0.684211\n",
      "28  29  0.541667  0.928571  0.684211\n",
      "29  30  0.541667  0.928571  0.684211\n",
      "     k       avg     count       MRR\n",
      "0    1  0.923077  0.857143  0.888889\n",
      "1    2  0.750000  0.857143  0.800000\n",
      "2    3  0.750000  0.857143  0.800000\n",
      "3    4  0.750000  0.857143  0.800000\n",
      "4    5  0.705882  0.857143  0.774194\n",
      "5    6  0.705882  0.857143  0.774194\n",
      "6    7  0.722222  0.928571  0.812500\n",
      "7    8  0.722222  0.928571  0.812500\n",
      "8    9  0.684211  0.928571  0.787879\n",
      "9   10  0.684211  0.928571  0.787879\n",
      "10  11  0.684211  0.928571  0.787879\n",
      "11  12  0.684211  0.928571  0.787879\n",
      "12  13  0.684211  0.928571  0.787879\n",
      "13  14  0.684211  0.928571  0.787879\n",
      "14  15  0.684211  0.928571  0.787879\n",
      "15  16  0.684211  0.928571  0.787879\n",
      "16  17  0.684211  0.928571  0.787879\n",
      "17  18  0.684211  0.928571  0.787879\n",
      "18  19  0.684211  0.928571  0.787879\n",
      "19  20  0.650000  0.928571  0.764706\n",
      "20  21  0.650000  0.928571  0.764706\n",
      "21  22  0.650000  0.928571  0.764706\n",
      "22  23  0.650000  0.928571  0.764706\n",
      "23  24  0.650000  0.928571  0.764706\n",
      "24  25  0.650000  0.928571  0.764706\n",
      "25  26  0.650000  0.928571  0.764706\n",
      "26  27  0.650000  0.928571  0.764706\n",
      "27  28  0.650000  0.928571  0.764706\n",
      "28  29  0.650000  0.928571  0.764706\n",
      "29  30  0.619048  0.928571  0.742857\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/company_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//company_exp_data-uncased-masked-ALL-BM25-single-triplet-67596-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.995945  0.653191  0.788950\n",
      "1    2  0.989030  0.703369  0.822091\n",
      "2    3  0.985535  0.724823  0.835309\n",
      "3    4  0.982963  0.736525  0.842084\n",
      "4    5  0.981150  0.747518  0.848546\n",
      "5    6  0.977518  0.755496  0.852285\n",
      "6    7  0.974796  0.761170  0.854839\n",
      "7    8  0.972668  0.763475  0.855468\n",
      "8    9  0.970813  0.766667  0.856747\n",
      "9   10  0.969616  0.769504  0.858047\n",
      "10  11  0.968402  0.771631  0.858891\n",
      "11  12  0.967656  0.774468  0.860351\n",
      "12  13  0.966255  0.776773  0.861215\n",
      "13  14  0.965661  0.777837  0.861632\n",
      "14  15  0.964662  0.779255  0.862103\n",
      "15  16  0.963700  0.781383  0.863018\n",
      "16  17  0.962696  0.782447  0.863263\n",
      "17  18  0.961296  0.783865  0.863561\n",
      "18  19  0.960104  0.785106  0.863831\n",
      "19  20  0.958324  0.786879  0.864181\n",
      "20  21  0.957965  0.787943  0.864676\n",
      "21  22  0.957241  0.789894  0.865553\n",
      "22  23  0.956662  0.790603  0.865741\n",
      "23  24  0.956261  0.790780  0.865683\n",
      "24  25  0.955898  0.791667  0.866065\n",
      "25  26  0.955090  0.791844  0.865839\n",
      "26  27  0.954119  0.792730  0.865969\n",
      "27  28  0.953984  0.793972  0.866654\n",
      "28  29  0.953800  0.794326  0.866789\n",
      "29  30  0.952411  0.794858  0.866531\n",
      "     k       avg     count       MRR\n",
      "0    1  0.995469  0.662234  0.795358\n",
      "1    2  0.986549  0.715248  0.829273\n",
      "2    3  0.979981  0.737766  0.841796\n",
      "3    4  0.975224  0.753723  0.850285\n",
      "4    5  0.970126  0.765780  0.855925\n",
      "5    6  0.966940  0.772695  0.858973\n",
      "6    7  0.962841  0.776418  0.859639\n",
      "7    8  0.958460  0.781383  0.860910\n",
      "8    9  0.955743  0.784929  0.861955\n",
      "9   10  0.952871  0.788652  0.863019\n",
      "10  11  0.951407  0.791489  0.864111\n",
      "11  12  0.949131  0.793972  0.864646\n",
      "12  13  0.945205  0.795213  0.863746\n",
      "13  14  0.942791  0.797695  0.864195\n",
      "14  15  0.940575  0.799823  0.864507\n",
      "15  16  0.939123  0.801418  0.864823\n",
      "16  17  0.936853  0.802305  0.864374\n",
      "17  18  0.934818  0.803546  0.864226\n",
      "18  19  0.933060  0.805674  0.864700\n",
      "19  20  0.930689  0.807092  0.864495\n",
      "20  21  0.929052  0.807979  0.864296\n",
      "21  22  0.928164  0.808688  0.864317\n",
      "22  23  0.926963  0.810106  0.864604\n",
      "23  24  0.926158  0.811702  0.865161\n",
      "24  25  0.924536  0.812411  0.864855\n",
      "25  26  0.922551  0.813121  0.864386\n",
      "26  27  0.921640  0.813298  0.864086\n",
      "27  28  0.919487  0.814007  0.863538\n",
      "28  29  0.918665  0.815071  0.863773\n",
      "29  30  0.917631  0.815780  0.863713\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.973568  0.995495  0.984410\n",
      "1    2  0.811355  0.997748  0.894949\n",
      "2    3  0.776224  1.000000  0.874016\n",
      "3    4  0.732673  1.000000  0.845714\n",
      "4    5  0.699213  1.000000  0.822984\n",
      "5    6  0.678899  1.000000  0.808743\n",
      "6    7  0.662687  1.000000  0.797127\n",
      "7    8  0.645349  1.000000  0.784452\n",
      "8    9  0.631579  1.000000  0.774194\n",
      "9   10  0.623596  1.000000  0.768166\n",
      "10  11  0.611570  1.000000  0.758974\n",
      "11  12  0.605730  1.000000  0.754460\n",
      "12  13  0.594378  1.000000  0.745592\n",
      "13  14  0.584211  1.000000  0.737542\n",
      "14  15  0.575130  1.000000  0.730263\n",
      "15  16  0.569231  1.000000  0.725490\n",
      "16  17  0.562738  1.000000  0.720195\n",
      "17  18  0.557789  1.000000  0.716129\n",
      "18  19  0.552239  1.000000  0.711538\n",
      "19  20  0.547472  1.000000  0.707570\n",
      "20  21  0.542787  1.000000  0.703645\n",
      "21  22  0.539490  1.000000  0.700868\n",
      "22  23  0.532374  1.000000  0.694836\n",
      "23  24  0.527316  1.000000  0.690513\n",
      "24  25  0.523585  1.000000  0.687307\n",
      "25  26  0.518692  1.000000  0.683077\n",
      "26  27  0.513295  1.000000  0.678380\n",
      "27  28  0.510932  1.000000  0.676314\n",
      "28  29  0.508009  1.000000  0.673748\n",
      "29  30  0.503973  1.000000  0.670189\n",
      "     k       avg     count       MRR\n",
      "0    1  0.975664  0.993243  0.984375\n",
      "1    2  0.860194  0.997748  0.923879\n",
      "2    3  0.803993  0.997748  0.890452\n",
      "3    4  0.769097  0.997748  0.868627\n",
      "4    5  0.732231  0.997748  0.844614\n",
      "5    6  0.708800  0.997748  0.828812\n",
      "6    7  0.698738  0.997748  0.821892\n",
      "7    8  0.683642  0.997748  0.811355\n",
      "8    9  0.674277  0.997748  0.804723\n",
      "9   10  0.666165  0.997748  0.798918\n",
      "10  11  0.654357  0.997748  0.790366\n",
      "11  12  0.650073  1.000000  0.787933\n",
      "12  13  0.641618  1.000000  0.781690\n",
      "13  14  0.630682  1.000000  0.773519\n",
      "14  15  0.621849  1.000000  0.766839\n",
      "15  16  0.611570  1.000000  0.758974\n",
      "16  17  0.604905  1.000000  0.753820\n",
      "17  18  0.603261  1.000000  0.752542\n",
      "18  19  0.597577  1.000000  0.748104\n",
      "19  20  0.592000  1.000000  0.743719\n",
      "20  21  0.588079  1.000000  0.740617\n",
      "21  22  0.583443  1.000000  0.736929\n",
      "22  23  0.578125  1.000000  0.732673\n",
      "23  24  0.574386  1.000000  0.729663\n",
      "24  25  0.570694  1.000000  0.726678\n",
      "25  26  0.564885  1.000000  0.721951\n",
      "26  27  0.563452  1.000000  0.720779\n",
      "27  28  0.556391  1.000000  0.714976\n",
      "28  29  0.553616  1.000000  0.712681\n",
      "29  30  0.550868  1.000000  0.710400\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.943396  0.420561  0.581771\n",
      "1    2  0.865099  0.653271  0.744409\n",
      "2    3  0.824526  0.772897  0.797877\n",
      "3    4  0.787773  0.842991  0.814447\n",
      "4    5  0.765940  0.886916  0.822001\n",
      "5    6  0.752098  0.921495  0.828223\n",
      "6    7  0.732847  0.938318  0.822951\n",
      "7    8  0.718529  0.949533  0.818035\n",
      "8    9  0.706694  0.957009  0.813021\n",
      "9   10  0.697564  0.963551  0.809262\n",
      "10  11  0.690160  0.970093  0.806527\n",
      "11  12  0.684418  0.972897  0.803551\n",
      "12  13  0.675291  0.975701  0.798165\n",
      "13  14  0.669443  0.976636  0.794375\n",
      "14  15  0.662034  0.979439  0.790049\n",
      "15  16  0.653367  0.979439  0.783844\n",
      "16  17  0.649784  0.983178  0.782447\n",
      "17  18  0.644825  0.984112  0.779134\n",
      "18  19  0.640340  0.985047  0.776141\n",
      "19  20  0.636473  0.985047  0.773294\n",
      "20  21  0.632335  0.986916  0.770803\n",
      "21  22  0.629917  0.987850  0.769287\n",
      "22  23  0.627300  0.987850  0.767332\n",
      "23  24  0.624189  0.988785  0.765280\n",
      "24  25  0.622719  0.988785  0.764175\n",
      "25  26  0.619801  0.988785  0.761973\n",
      "26  27  0.614402  0.988785  0.757880\n",
      "27  28  0.611432  0.989720  0.755889\n",
      "28  29  0.606182  0.989720  0.751864\n",
      "29  30  0.604452  0.989720  0.750532\n",
      "     k       avg     count       MRR\n",
      "0    1  0.959315  0.418692  0.582954\n",
      "1    2  0.875776  0.658879  0.752000\n",
      "2    3  0.834669  0.778505  0.805609\n",
      "3    4  0.792354  0.852336  0.821252\n",
      "4    5  0.767014  0.895327  0.826218\n",
      "5    6  0.748858  0.919626  0.825503\n",
      "6    7  0.734500  0.941121  0.825072\n",
      "7    8  0.721161  0.952336  0.820781\n",
      "8    9  0.708075  0.958879  0.814609\n",
      "9   10  0.697297  0.964486  0.809412\n",
      "10  11  0.688122  0.969159  0.804812\n",
      "11  12  0.680157  0.973832  0.800922\n",
      "12  13  0.674629  0.976636  0.798015\n",
      "13  14  0.667732  0.976636  0.793169\n",
      "14  15  0.661199  0.979439  0.789454\n",
      "15  16  0.659348  0.982243  0.789039\n",
      "16  17  0.653036  0.985047  0.785395\n",
      "17  18  0.645477  0.986916  0.780488\n",
      "18  19  0.639612  0.986916  0.776185\n",
      "19  20  0.635216  0.987850  0.773226\n",
      "20  21  0.631108  0.989720  0.770742\n",
      "21  22  0.627590  0.990654  0.768394\n",
      "22  23  0.624632  0.990654  0.766173\n",
      "23  24  0.621194  0.991589  0.763859\n",
      "24  25  0.616502  0.991589  0.760301\n",
      "25  26  0.612940  0.991589  0.757587\n",
      "26  27  0.609770  0.991589  0.755160\n",
      "27  28  0.607675  0.991589  0.753551\n",
      "28  29  0.605248  0.991589  0.751683\n",
      "29  30  0.602841  0.991589  0.749823\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-7417-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.960526  0.986486  0.973333\n",
      "1    2  0.766436  0.997748  0.866928\n",
      "2    3  0.696541  0.997748  0.820370\n",
      "3    4  0.649560  0.997748  0.786856\n",
      "4    5  0.613573  0.997748  0.759863\n",
      "5    6  0.589096  0.997748  0.740803\n",
      "6    7  0.573092  0.997748  0.728020\n",
      "7    8  0.558638  0.997748  0.716249\n",
      "8    9  0.544226  0.997748  0.704293\n",
      "9   10  0.530539  0.997748  0.692729\n",
      "10  11  0.519343  0.997748  0.683115\n",
      "11  12  0.506865  0.997748  0.672231\n",
      "12  13  0.497194  0.997748  0.663670\n",
      "13  14  0.487349  0.997748  0.654841\n",
      "14  15  0.479437  0.997748  0.647661\n",
      "15  16  0.473291  0.997748  0.642029\n",
      "16  17  0.468783  0.997748  0.637869\n",
      "17  18  0.464848  0.997748  0.634216\n",
      "18  19  0.458118  0.997748  0.627923\n",
      "19  20  0.452965  0.997748  0.623066\n",
      "20  21  0.449290  0.997748  0.619580\n",
      "21  22  0.447927  0.997748  0.618283\n",
      "22  23  0.443443  0.997748  0.613999\n",
      "23  24  0.439049  0.997748  0.609773\n",
      "24  25  0.436453  0.997748  0.607265\n",
      "25  26  0.432195  0.997748  0.603131\n",
      "26  27  0.428433  0.997748  0.599459\n",
      "27  28  0.424736  0.997748  0.595831\n",
      "28  29  0.421905  0.997748  0.593039\n",
      "29  30  0.419508  0.997748  0.590667\n",
      "     k       avg     count       MRR\n",
      "0    1  0.967177  0.995495  0.981132\n",
      "1    2  0.791071  0.997748  0.882470\n",
      "2    3  0.707668  0.997748  0.828037\n",
      "3    4  0.668175  0.997748  0.800361\n",
      "4    5  0.641100  0.997748  0.780617\n",
      "5    6  0.612725  0.997748  0.759212\n",
      "6    7  0.593039  0.997748  0.743913\n",
      "7    8  0.572351  0.997748  0.727422\n",
      "8    9  0.558638  0.997748  0.716249\n",
      "9   10  0.546914  0.997748  0.706539\n",
      "10  11  0.532452  0.997748  0.694357\n",
      "11  12  0.524260  0.997748  0.687355\n",
      "12  13  0.513326  0.997748  0.677888\n",
      "13  14  0.502268  0.997748  0.668175\n",
      "14  15  0.496081  0.997748  0.662678\n",
      "15  16  0.490044  0.997748  0.657270\n",
      "16  17  0.482046  0.997748  0.650037\n",
      "17  18  0.475322  0.997748  0.643895\n",
      "18  19  0.470776  0.997748  0.639711\n",
      "19  20  0.465336  0.997748  0.634670\n",
      "20  21  0.461458  0.997748  0.631054\n",
      "21  22  0.459067  0.997748  0.628815\n",
      "22  23  0.455761  0.997748  0.625706\n",
      "23  24  0.450203  0.997748  0.620448\n",
      "24  25  0.444333  0.997748  0.614851\n",
      "25  26  0.442116  0.997748  0.612725\n",
      "26  27  0.440358  0.997748  0.611034\n",
      "27  28  0.435167  0.997748  0.606019\n",
      "28  29  0.432617  0.997748  0.603542\n",
      "29  30  0.430515  0.997748  0.601494\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-17223-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.956159  0.428037  0.591349\n",
      "1    2  0.868550  0.660748  0.750531\n",
      "2    3  0.821569  0.783178  0.801914\n",
      "3    4  0.781708  0.846729  0.812921\n",
      "4    5  0.745683  0.887850  0.810580\n",
      "5    6  0.724520  0.916822  0.809406\n",
      "6    7  0.704225  0.934579  0.803213\n",
      "7    8  0.684103  0.941121  0.792290\n",
      "8    9  0.672607  0.952336  0.788395\n",
      "9   10  0.664290  0.957944  0.784539\n",
      "10  11  0.651486  0.962617  0.777065\n",
      "11  12  0.645081  0.968224  0.774290\n",
      "12  13  0.636252  0.971028  0.768775\n",
      "13  14  0.633273  0.974766  0.767759\n",
      "14  15  0.626723  0.977570  0.763782\n",
      "15  16  0.620710  0.980374  0.760145\n",
      "16  17  0.616872  0.984112  0.758372\n",
      "17  18  0.612565  0.984112  0.755109\n",
      "18  19  0.608671  0.984112  0.752143\n",
      "19  20  0.605052  0.985047  0.749644\n",
      "20  21  0.600570  0.985047  0.746195\n",
      "21  22  0.596719  0.985981  0.743481\n",
      "22  23  0.593697  0.985981  0.741131\n",
      "23  24  0.590274  0.986916  0.738720\n",
      "24  25  0.586993  0.986916  0.736145\n",
      "25  26  0.584718  0.986916  0.734353\n",
      "26  27  0.582460  0.986916  0.732570\n",
      "27  28  0.581178  0.986916  0.731555\n",
      "28  29  0.579583  0.986916  0.730290\n",
      "29  30  0.577049  0.986916  0.728276\n",
      "     k       avg     count       MRR\n",
      "0    1  0.949474  0.421495  0.583819\n",
      "1    2  0.861650  0.663551  0.749736\n",
      "2    3  0.817204  0.781308  0.798853\n",
      "3    4  0.780551  0.847664  0.812724\n",
      "4    5  0.751577  0.890654  0.815227\n",
      "5    6  0.721083  0.920561  0.808703\n",
      "6    7  0.703521  0.933645  0.802410\n",
      "7    8  0.684997  0.942991  0.793551\n",
      "8    9  0.673712  0.953271  0.789474\n",
      "9   10  0.662153  0.959813  0.783670\n",
      "10  11  0.649906  0.966355  0.777151\n",
      "11  12  0.643344  0.971028  0.773929\n",
      "12  13  0.635976  0.974766  0.769742\n",
      "13  14  0.627851  0.977570  0.764620\n",
      "14  15  0.621814  0.980374  0.760972\n",
      "15  16  0.620873  0.984112  0.761388\n",
      "16  17  0.612435  0.985047  0.755285\n",
      "17  18  0.607719  0.985981  0.751960\n",
      "18  19  0.604000  0.987850  0.749645\n",
      "19  20  0.599206  0.987850  0.745942\n",
      "20  21  0.595721  0.988785  0.743500\n",
      "21  22  0.590731  0.988785  0.739602\n",
      "22  23  0.586800  0.988785  0.736512\n",
      "23  24  0.583885  0.988785  0.734212\n",
      "24  25  0.581229  0.989720  0.732365\n",
      "25  26  0.579005  0.989720  0.730597\n",
      "26  27  0.577112  0.989720  0.729088\n",
      "27  28  0.575231  0.989720  0.727585\n",
      "28  29  0.571737  0.990654  0.725034\n",
      "29  30  0.568365  0.990654  0.722317\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.909091  0.370370  0.526316\n",
      "1    2  0.733333  0.407407  0.523810\n",
      "2    3  0.722222  0.481481  0.577778\n",
      "3    4  0.736842  0.518519  0.608696\n",
      "4    5  0.714286  0.555556  0.625000\n",
      "5    6  0.714286  0.555556  0.625000\n",
      "6    7  0.739130  0.629630  0.680000\n",
      "7    8  0.720000  0.666667  0.692308\n",
      "8    9  0.720000  0.666667  0.692308\n",
      "9   10  0.666667  0.666667  0.666667\n",
      "10  11  0.642857  0.666667  0.654545\n",
      "11  12  0.620690  0.666667  0.642857\n",
      "12  13  0.600000  0.666667  0.631579\n",
      "13  14  0.575758  0.703704  0.633333\n",
      "14  15  0.558824  0.703704  0.622951\n",
      "15  16  0.555556  0.740741  0.634921\n",
      "16  17  0.555556  0.740741  0.634921\n",
      "17  18  0.540541  0.740741  0.625000\n",
      "18  19  0.526316  0.740741  0.615385\n",
      "19  20  0.526316  0.740741  0.615385\n",
      "20  21  0.512195  0.777778  0.617647\n",
      "21  22  0.512195  0.777778  0.617647\n",
      "22  23  0.512195  0.777778  0.617647\n",
      "23  24  0.500000  0.777778  0.608696\n",
      "24  25  0.500000  0.777778  0.608696\n",
      "25  26  0.511628  0.814815  0.628571\n",
      "26  27  0.500000  0.814815  0.619718\n",
      "27  28  0.478261  0.814815  0.602740\n",
      "28  29  0.468085  0.814815  0.594595\n",
      "29  30  0.468085  0.814815  0.594595\n",
      "     k       avg     count       MRR\n",
      "0    1  0.750000  0.222222  0.342857\n",
      "1    2  0.833333  0.370370  0.512821\n",
      "2    3  0.733333  0.407407  0.523810\n",
      "3    4  0.722222  0.481481  0.577778\n",
      "4    5  0.650000  0.481481  0.553191\n",
      "5    6  0.652174  0.555556  0.600000\n",
      "6    7  0.652174  0.555556  0.600000\n",
      "7    8  0.652174  0.555556  0.600000\n",
      "8    9  0.652174  0.555556  0.600000\n",
      "9   10  0.625000  0.555556  0.588235\n",
      "10  11  0.615385  0.592593  0.603774\n",
      "11  12  0.615385  0.592593  0.603774\n",
      "12  13  0.592593  0.592593  0.592593\n",
      "13  14  0.571429  0.592593  0.581818\n",
      "14  15  0.551724  0.592593  0.571429\n",
      "15  16  0.531250  0.629630  0.576271\n",
      "16  17  0.531250  0.629630  0.576271\n",
      "17  18  0.558824  0.703704  0.622951\n",
      "18  19  0.542857  0.703704  0.612903\n",
      "19  20  0.555556  0.740741  0.634921\n",
      "20  21  0.512821  0.740741  0.606061\n",
      "21  22  0.487805  0.740741  0.588235\n",
      "22  23  0.477273  0.777778  0.591549\n",
      "23  24  0.488889  0.814815  0.611111\n",
      "24  25  0.500000  0.851852  0.630137\n",
      "25  26  0.489362  0.851852  0.621622\n",
      "26  27  0.500000  0.888889  0.640000\n",
      "27  28  0.500000  0.888889  0.640000\n",
      "28  29  0.489796  0.888889  0.631579\n",
      "29  30  0.480000  0.888889  0.623377\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.662222  0.772021  0.712919\n",
      "1    2  0.532915  0.880829  0.664063\n",
      "2    3  0.436869  0.896373  0.587436\n",
      "3    4  0.391499  0.906736  0.546875\n",
      "4    5  0.353535  0.906736  0.508721\n",
      "5    6  0.333333  0.906736  0.487465\n",
      "6    7  0.313620  0.906736  0.466045\n",
      "7    8  0.303082  0.917098  0.455598\n",
      "8    9  0.294408  0.927461  0.446941\n",
      "9   10  0.286169  0.932642  0.437956\n",
      "10  11  0.279503  0.932642  0.430108\n",
      "11  12  0.273828  0.937824  0.423888\n",
      "12  13  0.268546  0.937824  0.417532\n",
      "13  14  0.261183  0.937824  0.408578\n",
      "14  15  0.255977  0.943005  0.402655\n",
      "15  16  0.249315  0.943005  0.394366\n",
      "16  17  0.244295  0.943005  0.388060\n",
      "17  18  0.242384  0.948187  0.386076\n",
      "18  19  0.240209  0.953368  0.383733\n",
      "19  20  0.236504  0.953368  0.378991\n",
      "20  21  0.234395  0.953368  0.376278\n",
      "21  22  0.231738  0.953368  0.372847\n",
      "22  23  0.229244  0.958549  0.370000\n",
      "23  24  0.227273  0.958549  0.367428\n",
      "24  25  0.226002  0.963731  0.366142\n",
      "25  26  0.225182  0.963731  0.365064\n",
      "26  27  0.223827  0.963731  0.363281\n",
      "27  28  0.221957  0.963731  0.360815\n",
      "28  29  0.220379  0.963731  0.358727\n",
      "29  30  0.218824  0.963731  0.356663\n",
      "     k       avg     count       MRR\n",
      "0    1  0.617021  0.751295  0.677570\n",
      "1    2  0.480000  0.870466  0.618785\n",
      "2    3  0.408879  0.906736  0.563607\n",
      "3    4  0.377119  0.922280  0.535338\n",
      "4    5  0.342857  0.932642  0.501393\n",
      "5    6  0.324955  0.937824  0.482667\n",
      "6    7  0.309645  0.948187  0.466837\n",
      "7    8  0.291601  0.953368  0.446602\n",
      "8    9  0.280728  0.958549  0.434272\n",
      "9   10  0.270864  0.958549  0.422374\n",
      "10  11  0.266094  0.963731  0.417040\n",
      "11  12  0.258333  0.963731  0.407448\n",
      "12  13  0.253061  0.963731  0.400862\n",
      "13  14  0.245059  0.963731  0.390756\n",
      "14  15  0.238462  0.963731  0.382323\n",
      "15  16  0.234257  0.963731  0.376900\n",
      "16  17  0.230483  0.963731  0.372000\n",
      "17  18  0.225182  0.963731  0.365064\n",
      "18  19  0.221692  0.963731  0.360465\n",
      "19  20  0.218970  0.968912  0.357211\n",
      "20  21  0.215438  0.968912  0.352498\n",
      "21  22  0.212742  0.968912  0.348881\n",
      "22  23  0.211061  0.968912  0.346617\n",
      "23  24  0.208705  0.968912  0.343434\n",
      "24  25  0.205947  0.968912  0.339691\n",
      "25  26  0.203926  0.968912  0.336937\n",
      "26  27  0.202368  0.974093  0.335116\n",
      "27  28  0.200855  0.974093  0.333038\n",
      "28  29  0.198522  0.974093  0.329825\n",
      "29  30  0.197286  0.979275  0.328410\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-567-1.json\n",
      "     k       avg  count       MRR\n",
      "0    1  0.758621    1.0  0.862745\n",
      "1    2  0.628571    1.0  0.771930\n",
      "2    3  0.564103    1.0  0.721311\n",
      "3    4  0.500000    1.0  0.666667\n",
      "4    5  0.423077    1.0  0.594595\n",
      "5    6  0.379310    1.0  0.550000\n",
      "6    7  0.354839    1.0  0.523810\n",
      "7    8  0.333333    1.0  0.500000\n",
      "8    9  0.305556    1.0  0.468085\n",
      "9   10  0.297297    1.0  0.458333\n",
      "10  11  0.275000    1.0  0.431373\n",
      "11  12  0.258824    1.0  0.411215\n",
      "12  13  0.255814    1.0  0.407407\n",
      "13  14  0.244444    1.0  0.392857\n",
      "14  15  0.241758    1.0  0.389381\n",
      "15  16  0.236559    1.0  0.382609\n",
      "16  17  0.231579    1.0  0.376068\n",
      "17  18  0.229167    1.0  0.372881\n",
      "18  19  0.229167    1.0  0.372881\n",
      "19  20  0.229167    1.0  0.372881\n",
      "20  21  0.222222    1.0  0.363636\n",
      "21  22  0.217822    1.0  0.357724\n",
      "22  23  0.213592    1.0  0.352000\n",
      "23  24  0.205607    1.0  0.341085\n",
      "24  25  0.203704    1.0  0.338462\n",
      "25  26  0.200000    1.0  0.333333\n",
      "26  27  0.198198    1.0  0.330827\n",
      "27  28  0.196429    1.0  0.328358\n",
      "28  29  0.194690    1.0  0.325926\n",
      "29  30  0.192982    1.0  0.323529\n",
      "     k       avg     count       MRR\n",
      "0    1  0.875000  0.954545  0.913043\n",
      "1    2  0.700000  0.954545  0.807692\n",
      "2    3  0.567568  0.954545  0.711864\n",
      "3    4  0.446809  0.954545  0.608696\n",
      "4    5  0.403846  0.954545  0.567568\n",
      "5    6  0.362069  0.954545  0.525000\n",
      "6    7  0.328125  0.954545  0.488372\n",
      "7    8  0.308824  0.954545  0.466667\n",
      "8    9  0.300000  0.954545  0.456522\n",
      "9   10  0.297297  1.000000  0.458333\n",
      "10  11  0.278481  1.000000  0.435644\n",
      "11  12  0.265060  1.000000  0.419048\n",
      "12  13  0.261905  1.000000  0.415094\n",
      "13  14  0.255814  1.000000  0.407407\n",
      "14  15  0.244444  1.000000  0.392857\n",
      "15  16  0.239130  1.000000  0.385965\n",
      "16  17  0.239130  1.000000  0.385965\n",
      "17  18  0.229167  1.000000  0.372881\n",
      "18  19  0.220000  1.000000  0.360656\n",
      "19  20  0.209524  1.000000  0.346457\n",
      "20  21  0.205607  1.000000  0.341085\n",
      "21  22  0.198198  1.000000  0.330827\n",
      "22  23  0.194690  1.000000  0.325926\n",
      "23  24  0.188034  1.000000  0.316547\n",
      "24  25  0.188034  1.000000  0.316547\n",
      "25  26  0.186441  1.000000  0.314286\n",
      "26  27  0.184874  1.000000  0.312057\n",
      "27  28  0.181818  1.000000  0.307692\n",
      "28  29  0.180328  1.000000  0.305556\n",
      "29  30  0.178862  1.000000  0.303448\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-321-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.888889  0.592593  0.711111\n",
      "1    2  0.818182  0.666667  0.734694\n",
      "2    3  0.769231  0.740741  0.754717\n",
      "3    4  0.785714  0.814815  0.800000\n",
      "4    5  0.709677  0.814815  0.758621\n",
      "5    6  0.647059  0.814815  0.721311\n",
      "6    7  0.647059  0.814815  0.721311\n",
      "7    8  0.594595  0.814815  0.687500\n",
      "8    9  0.578947  0.814815  0.676923\n",
      "9   10  0.589744  0.851852  0.696970\n",
      "10  11  0.585366  0.888889  0.705882\n",
      "11  12  0.571429  0.888889  0.695652\n",
      "12  13  0.558140  0.888889  0.685714\n",
      "13  14  0.568182  0.925926  0.704225\n",
      "14  15  0.543478  0.925926  0.684932\n",
      "15  16  0.531915  0.925926  0.675676\n",
      "16  17  0.500000  0.925926  0.649351\n",
      "17  18  0.471698  0.925926  0.625000\n",
      "18  19  0.454545  0.925926  0.609756\n",
      "19  20  0.448276  0.962963  0.611765\n",
      "20  21  0.448276  0.962963  0.611765\n",
      "21  22  0.457627  1.000000  0.627907\n",
      "22  23  0.450000  1.000000  0.620690\n",
      "23  24  0.450000  1.000000  0.620690\n",
      "24  25  0.435484  1.000000  0.606742\n",
      "25  26  0.428571  1.000000  0.600000\n",
      "26  27  0.428571  1.000000  0.600000\n",
      "27  28  0.428571  1.000000  0.600000\n",
      "28  29  0.415385  1.000000  0.586957\n",
      "29  30  0.397059  1.000000  0.568421\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.481481  0.650000\n",
      "1    2  0.900000  0.666667  0.765957\n",
      "2    3  0.818182  0.666667  0.734694\n",
      "3    4  0.791667  0.703704  0.745098\n",
      "4    5  0.677419  0.777778  0.724138\n",
      "5    6  0.666667  0.814815  0.733333\n",
      "6    7  0.666667  0.814815  0.733333\n",
      "7    8  0.621622  0.851852  0.718750\n",
      "8    9  0.585366  0.888889  0.705882\n",
      "9   10  0.571429  0.888889  0.695652\n",
      "10  11  0.558140  0.888889  0.685714\n",
      "11  12  0.521739  0.888889  0.657534\n",
      "12  13  0.489796  0.888889  0.631579\n",
      "13  14  0.489796  0.888889  0.631579\n",
      "14  15  0.489796  0.888889  0.631579\n",
      "15  16  0.489796  0.888889  0.631579\n",
      "16  17  0.471698  0.925926  0.625000\n",
      "17  18  0.454545  0.925926  0.609756\n",
      "18  19  0.454545  0.925926  0.609756\n",
      "19  20  0.446429  0.925926  0.602410\n",
      "20  21  0.438596  0.925926  0.595238\n",
      "21  22  0.416667  0.925926  0.574713\n",
      "22  23  0.409836  0.925926  0.568182\n",
      "23  24  0.409836  0.925926  0.568182\n",
      "24  25  0.409836  0.925926  0.568182\n",
      "25  26  0.403226  0.925926  0.561798\n",
      "26  27  0.396825  0.925926  0.555556\n",
      "27  28  0.406250  0.962963  0.571429\n",
      "28  29  0.406250  0.962963  0.571429\n",
      "29  30  0.406250  0.962963  0.571429\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-6144-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.717703  0.777202  0.746269\n",
      "1    2  0.528125  0.875648  0.658869\n",
      "2    3  0.452880  0.896373  0.601739\n",
      "3    4  0.404651  0.901554  0.558587\n",
      "4    5  0.369979  0.906736  0.525526\n",
      "5    6  0.347913  0.906736  0.502874\n",
      "6    7  0.332700  0.906736  0.486787\n",
      "7    8  0.317117  0.911917  0.470588\n",
      "8    9  0.306759  0.917098  0.459740\n",
      "9   10  0.296482  0.917098  0.448101\n",
      "10  11  0.289689  0.917098  0.440299\n",
      "11  12  0.282748  0.917098  0.432234\n",
      "12  13  0.279251  0.927461  0.429257\n",
      "13  14  0.271084  0.932642  0.420070\n",
      "14  15  0.265096  0.932642  0.412844\n",
      "15  16  0.260116  0.932642  0.406780\n",
      "16  17  0.256410  0.932642  0.402235\n",
      "17  18  0.253879  0.932642  0.399113\n",
      "18  19  0.251739  0.937824  0.396930\n",
      "19  20  0.247606  0.937824  0.391775\n",
      "20  21  0.244926  0.937824  0.388412\n",
      "21  22  0.243641  0.943005  0.387234\n",
      "22  23  0.240423  0.943005  0.383158\n",
      "23  24  0.239216  0.948187  0.382046\n",
      "24  25  0.237662  0.948187  0.380062\n",
      "25  26  0.237047  0.948187  0.379275\n",
      "26  27  0.236434  0.948187  0.378490\n",
      "27  28  0.234315  0.948187  0.375770\n",
      "28  29  0.233121  0.948187  0.374233\n",
      "29  30  0.231646  0.948187  0.372330\n",
      "     k       avg     count       MRR\n",
      "0    1  0.681223  0.808290  0.739336\n",
      "1    2  0.514970  0.891192  0.652751\n",
      "2    3  0.433168  0.906736  0.586265\n",
      "3    4  0.385965  0.911917  0.542373\n",
      "4    5  0.355289  0.922280  0.512968\n",
      "5    6  0.332714  0.927461  0.489740\n",
      "6    7  0.316254  0.927461  0.471673\n",
      "7    8  0.301347  0.927461  0.454892\n",
      "8    9  0.292683  0.932642  0.445545\n",
      "9   10  0.282575  0.932642  0.433735\n",
      "10  11  0.273973  0.932642  0.423529\n",
      "11  12  0.265096  0.932642  0.412844\n",
      "12  13  0.259366  0.932642  0.405862\n",
      "13  14  0.251748  0.932642  0.396476\n",
      "14  15  0.245902  0.932642  0.389189\n",
      "15  16  0.241935  0.932642  0.384205\n",
      "16  17  0.239735  0.937824  0.381857\n",
      "17  18  0.235371  0.937824  0.376299\n",
      "18  19  0.232648  0.937824  0.372812\n",
      "19  20  0.230964  0.943005  0.371050\n",
      "20  21  0.229219  0.943005  0.368794\n",
      "21  22  0.227612  0.948187  0.367101\n",
      "22  23  0.226044  0.953368  0.365442\n",
      "23  24  0.224117  0.953368  0.362919\n",
      "24  25  0.221687  0.953368  0.359726\n",
      "25  26  0.218787  0.953368  0.355899\n",
      "26  27  0.217494  0.953368  0.354187\n",
      "27  28  0.215205  0.953368  0.351145\n",
      "28  29  0.214203  0.953368  0.349810\n",
      "29  30  0.212963  0.953368  0.348155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    #if 'deepmatcher' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "    if 'json' in i and 'deepmatcher' not in i:\n",
    "        conf = load_config(i)\n",
    "        if conf['data'] == 'deepmatcher' and conf['arch'] == 'single-triplet' and 'distilbert' not in conf['bert_path']:\n",
    "            config_knn = get_config_knn_dir(i)\n",
    "            print(conf['data'])\n",
    "            print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "            print(i)\n",
    "            files = get_sorted_files(config_knn)\n",
    "            for j in files:\n",
    "                if 'knn_results' in j:\n",
    "                    results = pd.read_pickle(j)\n",
    "                    print(results[['k', 'avg', 'count', 'MRR']])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-madness",
   "metadata": {},
   "source": [
    "## single-triplet BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "retained-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-distilbert-base-uncased-single-triplet-5743-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.867403  0.762136  0.811370\n",
      "1    2  0.628571  0.854369  0.724280\n",
      "2    3  0.547904  0.888350  0.677778\n",
      "3    4  0.506775  0.907767  0.650435\n",
      "4    5  0.461165  0.922330  0.614887\n",
      "5    6  0.438073  0.927184  0.595016\n",
      "6    7  0.424176  0.936893  0.583964\n",
      "7    8  0.409283  0.941748  0.570588\n",
      "8    9  0.396341  0.946602  0.558739\n",
      "9   10  0.383104  0.946602  0.545455\n",
      "10  11  0.370301  0.956311  0.533875\n",
      "11  12  0.363139  0.966019  0.527851\n",
      "12  13  0.359066  0.970874  0.524246\n",
      "13  14  0.350263  0.970874  0.514801\n",
      "14  15  0.342466  0.970874  0.506329\n",
      "15  16  0.337838  0.970874  0.501253\n",
      "16  17  0.332226  0.970874  0.495050\n",
      "17  18  0.326264  0.970874  0.488400\n",
      "18  19  0.323102  0.970874  0.484848\n",
      "19  20  0.320000  0.970874  0.481348\n",
      "20  21  0.317460  0.970874  0.478469\n",
      "21  22  0.312500  0.970874  0.472813\n",
      "22  23  0.307692  0.970874  0.467290\n",
      "23  24  0.304085  0.975728  0.463668\n",
      "24  25  0.300898  0.975728  0.459954\n",
      "25  26  0.299107  0.975728  0.457859\n",
      "26  27  0.295588  0.975728  0.453725\n",
      "27  28  0.294461  0.980583  0.452915\n",
      "28  29  0.289813  0.980583  0.447398\n",
      "29  30  0.285311  0.980583  0.442013\n",
      "     k       avg     count       MRR\n",
      "0    1  0.907975  0.718447  0.802168\n",
      "1    2  0.668000  0.810680  0.732456\n",
      "2    3  0.588435  0.839806  0.692000\n",
      "3    4  0.550000  0.854369  0.669202\n",
      "4    5  0.520588  0.859223  0.648352\n",
      "5    6  0.490358  0.864078  0.625659\n",
      "6    7  0.473545  0.868932  0.613014\n",
      "7    8  0.458015  0.873786  0.601002\n",
      "8    9  0.444717  0.878641  0.590538\n",
      "9   10  0.434368  0.883495  0.582400\n",
      "10  11  0.429234  0.898058  0.580848\n",
      "11  12  0.415730  0.898058  0.568356\n",
      "12  13  0.404814  0.898058  0.558069\n",
      "13  14  0.395299  0.898058  0.548961\n",
      "14  15  0.389474  0.898058  0.543319\n",
      "15  16  0.386694  0.902913  0.541485\n",
      "16  17  0.378819  0.902913  0.533716\n",
      "17  18  0.374749  0.907767  0.530496\n",
      "18  19  0.369352  0.912621  0.525874\n",
      "19  20  0.366990  0.917476  0.524272\n",
      "20  21  0.361905  0.922330  0.519836\n",
      "21  22  0.360377  0.927184  0.519022\n",
      "22  23  0.353704  0.927184  0.512064\n",
      "23  24  0.351750  0.927184  0.510013\n",
      "24  25  0.352190  0.936893  0.511936\n",
      "25  26  0.347748  0.936893  0.507227\n",
      "26  27  0.343416  0.936893  0.502604\n",
      "27  28  0.340989  0.936893  0.500000\n",
      "28  29  0.336237  0.936893  0.494872\n",
      "29  30  0.335640  0.941748  0.494898\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-distilbert-base-uncased-single-triplet-6874-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.680672  0.692308  0.686441\n",
      "1    2  0.549724  0.850427  0.667785\n",
      "2    3  0.484163  0.914530  0.633136\n",
      "3    4  0.442191  0.931624  0.599725\n",
      "4    5  0.404059  0.935897  0.564433\n",
      "5    6  0.382609  0.940171  0.543881\n",
      "6    7  0.371287  0.961538  0.535714\n",
      "7    8  0.356467  0.965812  0.520737\n",
      "8    9  0.343939  0.970085  0.507830\n",
      "9   10  0.337278  0.974359  0.501099\n",
      "10  11  0.330435  0.974359  0.493506\n",
      "11  12  0.324786  0.974359  0.487179\n",
      "12  13  0.315789  0.974359  0.476987\n",
      "13  14  0.309362  0.974359  0.469619\n",
      "14  15  0.304000  0.974359  0.463415\n",
      "15  16  0.300000  0.974359  0.458753\n",
      "16  17  0.295720  0.974359  0.453731\n",
      "17  18  0.293436  0.974359  0.451039\n",
      "18  19  0.287154  0.974359  0.443580\n",
      "19  20  0.283935  0.974359  0.439730\n",
      "20  21  0.282178  0.974359  0.437620\n",
      "21  22  0.278928  0.978632  0.434123\n",
      "22  23  0.276236  0.978632  0.430856\n",
      "23  24  0.273270  0.978632  0.427239\n",
      "24  25  0.271006  0.978632  0.424467\n",
      "25  26  0.268464  0.978632  0.421343\n",
      "26  27  0.265661  0.978632  0.417883\n",
      "27  28  0.264434  0.978632  0.416364\n",
      "28  29  0.261714  0.978632  0.412985\n",
      "29  30  0.260227  0.978632  0.411131\n",
      "     k       avg     count       MRR\n",
      "0    1  0.684874  0.696581  0.690678\n",
      "1    2  0.544236  0.867521  0.668863\n",
      "2    3  0.475556  0.914530  0.625731\n",
      "3    4  0.426326  0.927350  0.584118\n",
      "4    5  0.398917  0.944444  0.560914\n",
      "5    6  0.374368  0.948718  0.536880\n",
      "6    7  0.351097  0.957265  0.513761\n",
      "7    8  0.338346  0.961538  0.500556\n",
      "8    9  0.330904  0.970085  0.493478\n",
      "9   10  0.327611  0.978632  0.490890\n",
      "10  11  0.321629  0.978632  0.484144\n",
      "11  12  0.317175  0.978632  0.479079\n",
      "12  13  0.310298  0.978632  0.471193\n",
      "13  14  0.304521  0.978632  0.464503\n",
      "14  15  0.299090  0.982906  0.458624\n",
      "15  16  0.297542  0.982906  0.456802\n",
      "16  17  0.294494  0.982906  0.453202\n",
      "17  18  0.290038  0.982906  0.447907\n",
      "18  19  0.287141  0.982906  0.444444\n",
      "19  20  0.283951  0.982906  0.440613\n",
      "20  21  0.281174  0.982906  0.437262\n",
      "21  22  0.279465  0.982906  0.435194\n",
      "22  23  0.277443  0.982906  0.432738\n",
      "23  24  0.273484  0.982906  0.427907\n",
      "24  25  0.270588  0.982906  0.424354\n",
      "25  26  0.269006  0.982906  0.422406\n",
      "26  27  0.266512  0.982906  0.419325\n",
      "27  28  0.264368  0.982906  0.416667\n",
      "28  29  0.263459  0.982906  0.415537\n",
      "29  30  0.262258  0.982906  0.414041\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-distilbert-base-uncased-single-triplet-268-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.900000  0.642857  0.750000\n",
      "1    2  0.909091  0.714286  0.800000\n",
      "2    3  0.833333  0.714286  0.769231\n",
      "3    4  0.833333  0.714286  0.769231\n",
      "4    5  0.769231  0.714286  0.740741\n",
      "5    6  0.769231  0.714286  0.740741\n",
      "6    7  0.769231  0.714286  0.740741\n",
      "7    8  0.769231  0.714286  0.740741\n",
      "8    9  0.769231  0.714286  0.740741\n",
      "9   10  0.769231  0.714286  0.740741\n",
      "10  11  0.785714  0.785714  0.785714\n",
      "11  12  0.785714  0.785714  0.785714\n",
      "12  13  0.785714  0.785714  0.785714\n",
      "13  14  0.785714  0.785714  0.785714\n",
      "14  15  0.800000  0.857143  0.827586\n",
      "15  16  0.800000  0.857143  0.827586\n",
      "16  17  0.750000  0.857143  0.800000\n",
      "17  18  0.750000  0.857143  0.800000\n",
      "18  19  0.750000  0.857143  0.800000\n",
      "19  20  0.750000  0.857143  0.800000\n",
      "20  21  0.705882  0.857143  0.774194\n",
      "21  22  0.705882  0.857143  0.774194\n",
      "22  23  0.705882  0.857143  0.774194\n",
      "23  24  0.705882  0.857143  0.774194\n",
      "24  25  0.705882  0.857143  0.774194\n",
      "25  26  0.705882  0.857143  0.774194\n",
      "26  27  0.705882  0.857143  0.774194\n",
      "27  28  0.705882  0.857143  0.774194\n",
      "28  29  0.705882  0.857143  0.774194\n",
      "29  30  0.722222  0.928571  0.812500\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.214286  0.352941\n",
      "1    2  1.000000  0.214286  0.352941\n",
      "2    3  1.000000  0.214286  0.352941\n",
      "3    4  1.000000  0.214286  0.352941\n",
      "4    5  1.000000  0.214286  0.352941\n",
      "5    6  1.000000  0.214286  0.352941\n",
      "6    7  0.750000  0.214286  0.333333\n",
      "7    8  0.750000  0.214286  0.333333\n",
      "8    9  0.750000  0.214286  0.333333\n",
      "9   10  0.800000  0.285714  0.421053\n",
      "10  11  0.800000  0.285714  0.421053\n",
      "11  12  0.800000  0.285714  0.421053\n",
      "12  13  0.800000  0.285714  0.421053\n",
      "13  14  0.800000  0.285714  0.421053\n",
      "14  15  0.800000  0.285714  0.421053\n",
      "15  16  0.800000  0.285714  0.421053\n",
      "16  17  0.666667  0.285714  0.400000\n",
      "17  18  0.666667  0.285714  0.400000\n",
      "18  19  0.666667  0.285714  0.400000\n",
      "19  20  0.571429  0.285714  0.380952\n",
      "20  21  0.571429  0.285714  0.380952\n",
      "21  22  0.571429  0.285714  0.380952\n",
      "22  23  0.571429  0.285714  0.380952\n",
      "23  24  0.571429  0.285714  0.380952\n",
      "24  25  0.571429  0.285714  0.380952\n",
      "25  26  0.571429  0.285714  0.380952\n",
      "26  27  0.625000  0.357143  0.454545\n",
      "27  28  0.625000  0.357143  0.454545\n",
      "28  29  0.666667  0.428571  0.521739\n",
      "29  30  0.600000  0.428571  0.500000\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//company_exp_data-distilbert-base-uncased-single-triplet-67596-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.994599  0.620390  0.764141\n",
      "1    2  0.990114  0.674823  0.802615\n",
      "2    3  0.986974  0.698582  0.818106\n",
      "3    4  0.982793  0.708865  0.823651\n",
      "4    5  0.979966  0.719858  0.830011\n",
      "5    6  0.977132  0.727305  0.833909\n",
      "6    7  0.974329  0.733511  0.836941\n",
      "7    8  0.972721  0.739716  0.840367\n",
      "8    9  0.969557  0.745390  0.842823\n",
      "9   10  0.966102  0.747872  0.843094\n",
      "10  11  0.964537  0.752305  0.845303\n",
      "11  12  0.962871  0.754078  0.845779\n",
      "12  13  0.960612  0.756738  0.846573\n",
      "13  14  0.958604  0.759574  0.847562\n",
      "14  15  0.956599  0.762057  0.848317\n",
      "15  16  0.954556  0.763475  0.848389\n",
      "16  17  0.953883  0.766489  0.849980\n",
      "17  18  0.953407  0.769149  0.851423\n",
      "18  19  0.952235  0.770567  0.851823\n",
      "19  20  0.951507  0.772340  0.852613\n",
      "20  21  0.950120  0.773404  0.852703\n",
      "21  22  0.949348  0.774291  0.852930\n",
      "22  23  0.946788  0.776064  0.852967\n",
      "23  24  0.946448  0.777128  0.853471\n",
      "24  25  0.945870  0.777660  0.853556\n",
      "25  26  0.945329  0.778723  0.853976\n",
      "26  27  0.944600  0.779965  0.854424\n",
      "27  28  0.944075  0.781206  0.854953\n",
      "28  29  0.942924  0.782092  0.855011\n",
      "29  30  0.941766  0.782801  0.854957\n",
      "     k       avg     count       MRR\n",
      "0    1  0.995002  0.564716  0.720507\n",
      "1    2  0.989828  0.621099  0.763264\n",
      "2    3  0.985779  0.651418  0.784456\n",
      "3    4  0.983051  0.668440  0.795778\n",
      "4    5  0.980597  0.681028  0.803809\n",
      "5    6  0.978638  0.690426  0.809648\n",
      "6    7  0.975913  0.696809  0.813075\n",
      "7    8  0.973510  0.703723  0.816919\n",
      "8    9  0.971338  0.709043  0.819719\n",
      "9   10  0.970106  0.713475  0.822231\n",
      "10  11  0.967780  0.718972  0.825025\n",
      "11  12  0.966682  0.725355  0.828809\n",
      "12  13  0.964756  0.728014  0.829830\n",
      "13  14  0.962894  0.731560  0.831436\n",
      "14  15  0.961208  0.733688  0.832177\n",
      "15  16  0.960176  0.735284  0.832815\n",
      "16  17  0.958920  0.736702  0.833250\n",
      "17  18  0.957110  0.739894  0.834600\n",
      "18  19  0.955657  0.741312  0.834948\n",
      "19  20  0.953997  0.742730  0.835211\n",
      "20  21  0.952543  0.743794  0.835325\n",
      "21  22  0.951938  0.744504  0.835539\n",
      "22  23  0.950531  0.746099  0.835999\n",
      "23  24  0.949515  0.746986  0.836162\n",
      "24  25  0.947687  0.748404  0.836338\n",
      "25  26  0.947121  0.749468  0.836781\n",
      "26  27  0.946121  0.750355  0.836943\n",
      "27  28  0.944977  0.752128  0.837595\n",
      "28  29  0.944395  0.752837  0.837806\n",
      "29  30  0.944284  0.754255  0.838640\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.981982  0.981982  0.981982\n",
      "1    2  0.912500  0.986486  0.948052\n",
      "2    3  0.881288  0.986486  0.930925\n",
      "3    4  0.863905  0.986486  0.921136\n",
      "4    5  0.839080  0.986486  0.906832\n",
      "5    6  0.827977  0.986486  0.900308\n",
      "6    7  0.811111  0.986486  0.890244\n",
      "7    8  0.806985  0.988739  0.888664\n",
      "8    9  0.798182  0.988739  0.883300\n",
      "9   10  0.785714  0.990991  0.876494\n",
      "10  11  0.779152  0.993243  0.873267\n",
      "11  12  0.773684  0.993243  0.869822\n",
      "12  13  0.770979  0.993243  0.868110\n",
      "13  14  0.762976  0.993243  0.863014\n",
      "14  15  0.755137  0.993243  0.857977\n",
      "15  16  0.747885  0.995495  0.854106\n",
      "16  17  0.742857  0.995495  0.850818\n",
      "17  18  0.741611  0.995495  0.850000\n",
      "18  19  0.739130  0.995495  0.848369\n",
      "19  20  0.735441  0.995495  0.845933\n",
      "20  21  0.731788  0.995495  0.843511\n",
      "21  22  0.724590  0.995495  0.838710\n",
      "22  23  0.721044  0.995495  0.836329\n",
      "23  24  0.716370  0.995495  0.833176\n",
      "24  25  0.710611  0.995495  0.829268\n",
      "25  26  0.704944  0.995495  0.825397\n",
      "26  27  0.693878  0.995495  0.817761\n",
      "27  28  0.690625  0.995495  0.815498\n",
      "28  29  0.684211  0.995495  0.811009\n",
      "29  30  0.682099  0.995495  0.809524\n",
      "     k       avg     count       MRR\n",
      "0    1  0.962472  0.981982  0.972129\n",
      "1    2  0.844231  0.988739  0.910788\n",
      "2    3  0.810662  0.993243  0.892713\n",
      "3    4  0.773684  0.993243  0.869822\n",
      "4    5  0.753846  0.993243  0.857143\n",
      "5    6  0.726524  0.993243  0.839201\n",
      "6    7  0.712439  0.993243  0.829727\n",
      "7    8  0.704473  0.993243  0.824299\n",
      "8    9  0.696682  0.993243  0.818942\n",
      "9   10  0.690141  0.993243  0.814404\n",
      "10  11  0.684783  0.993243  0.810662\n",
      "11  12  0.678955  0.995495  0.807306\n",
      "12  13  0.667674  0.995495  0.799277\n",
      "13  14  0.665663  0.995495  0.797834\n",
      "14  15  0.660209  0.997748  0.794619\n",
      "15  16  0.654357  0.997748  0.790366\n",
      "16  17  0.650514  0.997748  0.787556\n",
      "17  18  0.640173  0.997748  0.779930\n",
      "18  19  0.631954  0.997748  0.773799\n",
      "19  20  0.627479  0.997748  0.770435\n",
      "20  21  0.623066  0.997748  0.767100\n",
      "21  22  0.616992  0.997748  0.762478\n",
      "22  23  0.611878  0.997748  0.758562\n",
      "23  24  0.607682  0.997748  0.755328\n",
      "24  25  0.605191  0.997748  0.753401\n",
      "25  26  0.600271  0.997748  0.749577\n",
      "26  27  0.597035  0.997748  0.747049\n",
      "27  28  0.594631  0.997748  0.745164\n",
      "28  29  0.591455  0.997748  0.742666\n",
      "29  30  0.589096  0.997748  0.740803\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.949260  0.419626  0.581983\n",
      "1    2  0.896644  0.624299  0.736088\n",
      "2    3  0.868852  0.742991  0.801008\n",
      "3    4  0.853175  0.803738  0.827719\n",
      "4    5  0.836735  0.842991  0.839851\n",
      "5    6  0.826821  0.870093  0.847905\n",
      "6    7  0.818026  0.890654  0.852796\n",
      "7    8  0.809167  0.907477  0.855507\n",
      "8    9  0.802621  0.915888  0.855522\n",
      "9   10  0.800485  0.926168  0.858752\n",
      "10  11  0.793461  0.929907  0.856282\n",
      "11  12  0.787234  0.933645  0.854211\n",
      "12  13  0.784543  0.939252  0.854955\n",
      "13  14  0.780620  0.941121  0.853390\n",
      "14  15  0.776326  0.943925  0.851961\n",
      "15  16  0.770517  0.947664  0.849958\n",
      "16  17  0.769114  0.949533  0.849854\n",
      "17  18  0.766214  0.949533  0.848080\n",
      "18  19  0.763691  0.951402  0.847274\n",
      "19  20  0.761372  0.954206  0.846951\n",
      "20  21  0.760238  0.954206  0.846249\n",
      "21  22  0.755736  0.954206  0.843453\n",
      "22  23  0.754619  0.954206  0.842757\n",
      "23  24  0.753506  0.954206  0.842062\n",
      "24  25  0.751471  0.955140  0.841152\n",
      "25  26  0.749451  0.956075  0.840246\n",
      "26  27  0.747991  0.957009  0.839688\n",
      "27  28  0.744186  0.957009  0.837285\n",
      "28  29  0.742754  0.957944  0.836735\n",
      "29  30  0.740260  0.958879  0.835505\n",
      "     k       avg     count       MRR\n",
      "0    1  0.948025  0.426168  0.588008\n",
      "1    2  0.904953  0.631776  0.744084\n",
      "2    3  0.879505  0.729907  0.797753\n",
      "3    4  0.862348  0.796262  0.827988\n",
      "4    5  0.855364  0.834579  0.844844\n",
      "5    6  0.849541  0.865421  0.857407\n",
      "6    7  0.838078  0.880374  0.858706\n",
      "7    8  0.829289  0.894393  0.860612\n",
      "8    9  0.820731  0.902804  0.859813\n",
      "9   10  0.813701  0.910280  0.859285\n",
      "10  11  0.805785  0.911215  0.855263\n",
      "11  12  0.800000  0.915888  0.854031\n",
      "12  13  0.792909  0.919626  0.851579\n",
      "13  14  0.788676  0.924299  0.851119\n",
      "14  15  0.785150  0.928972  0.851027\n",
      "15  16  0.780833  0.928972  0.848485\n",
      "16  17  0.779079  0.932710  0.849000\n",
      "17  18  0.775621  0.933645  0.847328\n",
      "18  19  0.771429  0.933645  0.844820\n",
      "19  20  0.768405  0.936449  0.844145\n",
      "20  21  0.766641  0.936449  0.843080\n",
      "21  22  0.760425  0.937383  0.839682\n",
      "22  23  0.758125  0.937383  0.838278\n",
      "23  24  0.754320  0.938318  0.836318\n",
      "24  25  0.752624  0.938318  0.835275\n",
      "25  26  0.749813  0.938318  0.833541\n",
      "26  27  0.747955  0.940187  0.833126\n",
      "27  28  0.748143  0.941121  0.833609\n",
      "28  29  0.746667  0.942056  0.833058\n",
      "29  30  0.745199  0.942991  0.832508\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-7417-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.986425  0.981982  0.984199\n",
      "1    2  0.922269  0.988739  0.954348\n",
      "2    3  0.892495  0.990991  0.939168\n",
      "3    4  0.864706  0.993243  0.924528\n",
      "4    5  0.849711  0.993243  0.915888\n",
      "5    6  0.841603  0.993243  0.911157\n",
      "6    7  0.830508  0.993243  0.904615\n",
      "7    8  0.812155  0.993243  0.893617\n",
      "8    9  0.803279  0.993243  0.888218\n",
      "9   10  0.793165  0.993243  0.882000\n",
      "10  11  0.786096  0.993243  0.877612\n",
      "11  12  0.781915  0.993243  0.875000\n",
      "12  13  0.775044  0.993243  0.870681\n",
      "13  14  0.764298  0.993243  0.863859\n",
      "14  15  0.753846  0.993243  0.857143\n",
      "15  16  0.751278  0.993243  0.855480\n",
      "16  17  0.742424  0.993243  0.849711\n",
      "17  18  0.738693  0.993243  0.847262\n",
      "18  19  0.733777  0.993243  0.844019\n",
      "19  20  0.726524  0.993243  0.839201\n",
      "20  21  0.722951  0.993243  0.836812\n",
      "21  22  0.719413  0.993243  0.834437\n",
      "22  23  0.718241  0.993243  0.833648\n",
      "23  24  0.714749  0.993243  0.831291\n",
      "24  25  0.710145  0.993243  0.828169\n",
      "25  26  0.707865  0.993243  0.826617\n",
      "26  27  0.701113  0.993243  0.821994\n",
      "27  28  0.700000  0.993243  0.821229\n",
      "28  29  0.697785  0.993243  0.819703\n",
      "29  30  0.692308  0.993243  0.815911\n",
      "     k       avg     count       MRR\n",
      "0    1  0.981735  0.968468  0.975057\n",
      "1    2  0.906054  0.977477  0.940412\n",
      "2    3  0.872000  0.981982  0.923729\n",
      "3    4  0.842004  0.984234  0.907580\n",
      "4    5  0.822976  0.984234  0.896410\n",
      "5    6  0.812268  0.984234  0.890020\n",
      "6    7  0.798903  0.984234  0.881937\n",
      "7    8  0.791667  0.984234  0.877510\n",
      "8    9  0.783154  0.984234  0.872255\n",
      "9   10  0.776991  0.988739  0.870168\n",
      "10  11  0.768827  0.988739  0.865025\n",
      "11  12  0.763478  0.988739  0.861629\n",
      "12  13  0.759516  0.988739  0.859100\n",
      "13  14  0.747871  0.988739  0.851600\n",
      "14  15  0.742809  0.988739  0.848309\n",
      "15  16  0.734114  0.988739  0.842610\n",
      "16  17  0.730449  0.988739  0.840191\n",
      "17  18  0.729236  0.988739  0.839388\n",
      "18  19  0.726821  0.988739  0.837786\n",
      "19  20  0.722039  0.988739  0.834601\n",
      "20  21  0.713821  0.988739  0.829084\n",
      "21  22  0.708065  0.988739  0.825188\n",
      "22  23  0.705788  0.988739  0.823640\n",
      "23  24  0.702400  0.988739  0.821328\n",
      "24  25  0.697933  0.988739  0.818267\n",
      "25  26  0.692429  0.988739  0.814471\n",
      "26  27  0.687011  0.988739  0.810711\n",
      "27  28  0.679567  0.988739  0.805505\n",
      "28  29  0.677469  0.988739  0.804029\n",
      "29  30  0.675385  0.988739  0.802559\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-17223-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.968468  0.401869  0.568032\n",
      "1    2  0.934097  0.609346  0.737557\n",
      "2    3  0.906780  0.700000  0.790084\n",
      "3    4  0.886564  0.752336  0.813953\n",
      "4    5  0.874227  0.792523  0.831373\n",
      "5    6  0.868056  0.817757  0.842156\n",
      "6    7  0.863067  0.836449  0.849549\n",
      "7    8  0.858223  0.848598  0.853383\n",
      "8    9  0.854360  0.860748  0.857542\n",
      "9   10  0.848101  0.876636  0.862132\n",
      "10  11  0.844920  0.885981  0.864964\n",
      "11  12  0.843778  0.893458  0.867907\n",
      "12  13  0.838428  0.897196  0.866817\n",
      "13  14  0.837250  0.899065  0.867057\n",
      "14  15  0.830043  0.903738  0.865324\n",
      "15  16  0.826939  0.906542  0.864913\n",
      "16  17  0.824576  0.909346  0.864889\n",
      "17  18  0.822635  0.910280  0.864241\n",
      "18  19  0.821699  0.913084  0.864985\n",
      "19  20  0.818410  0.914019  0.863576\n",
      "20  21  0.814476  0.914953  0.861796\n",
      "21  22  0.810587  0.915888  0.860026\n",
      "22  23  0.808739  0.916822  0.859396\n",
      "23  24  0.807407  0.916822  0.858643\n",
      "24  25  0.807407  0.916822  0.858643\n",
      "25  26  0.805078  0.918692  0.858141\n",
      "26  27  0.803105  0.918692  0.857018\n",
      "27  28  0.802449  0.918692  0.856645\n",
      "28  29  0.801141  0.918692  0.855899\n",
      "29  30  0.799187  0.918692  0.854783\n",
      "     k       avg     count       MRR\n",
      "0    1  0.969697  0.418692  0.584856\n",
      "1    2  0.924222  0.638318  0.755113\n",
      "2    3  0.897753  0.746729  0.815306\n",
      "3    4  0.870445  0.803738  0.835763\n",
      "4    5  0.859060  0.837383  0.848083\n",
      "5    6  0.847286  0.860748  0.853964\n",
      "6    7  0.841918  0.885981  0.863388\n",
      "7    8  0.836364  0.902804  0.868315\n",
      "8    9  0.827792  0.907477  0.865805\n",
      "9   10  0.827150  0.916822  0.869681\n",
      "10  11  0.822648  0.923364  0.870101\n",
      "11  12  0.817506  0.925234  0.868040\n",
      "12  13  0.810303  0.926168  0.864370\n",
      "13  14  0.807974  0.928037  0.863854\n",
      "14  15  0.805982  0.931776  0.864326\n",
      "15  16  0.799679  0.932710  0.861087\n",
      "16  17  0.795075  0.935514  0.859596\n",
      "17  18  0.791962  0.939252  0.859342\n",
      "18  19  0.789804  0.941121  0.858849\n",
      "19  20  0.786271  0.942056  0.857143\n",
      "20  21  0.781395  0.942056  0.854237\n",
      "21  22  0.777350  0.942991  0.852196\n",
      "22  23  0.776923  0.943925  0.852321\n",
      "23  24  0.774540  0.943925  0.850885\n",
      "24  25  0.772345  0.944860  0.849937\n",
      "25  26  0.770579  0.944860  0.848866\n",
      "26  27  0.766667  0.945794  0.846862\n",
      "27  28  0.763376  0.946729  0.845223\n",
      "28  29  0.761082  0.946729  0.843815\n",
      "29  30  0.758801  0.946729  0.842412\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.148148  0.258065\n",
      "1    2  1.000000  0.222222  0.363636\n",
      "2    3  0.875000  0.259259  0.400000\n",
      "3    4  0.888889  0.296296  0.444444\n",
      "4    5  0.800000  0.296296  0.432432\n",
      "5    6  0.800000  0.296296  0.432432\n",
      "6    7  0.800000  0.296296  0.432432\n",
      "7    8  0.800000  0.296296  0.432432\n",
      "8    9  0.800000  0.296296  0.432432\n",
      "9   10  0.727273  0.296296  0.421053\n",
      "10  11  0.615385  0.296296  0.400000\n",
      "11  12  0.615385  0.296296  0.400000\n",
      "12  13  0.571429  0.296296  0.390244\n",
      "13  14  0.533333  0.296296  0.380952\n",
      "14  15  0.533333  0.296296  0.380952\n",
      "15  16  0.533333  0.296296  0.380952\n",
      "16  17  0.533333  0.296296  0.380952\n",
      "17  18  0.533333  0.296296  0.380952\n",
      "18  19  0.500000  0.296296  0.372093\n",
      "19  20  0.500000  0.333333  0.400000\n",
      "20  21  0.500000  0.333333  0.400000\n",
      "21  22  0.500000  0.333333  0.400000\n",
      "22  23  0.500000  0.333333  0.400000\n",
      "23  24  0.500000  0.333333  0.400000\n",
      "24  25  0.473684  0.333333  0.391304\n",
      "25  26  0.473684  0.333333  0.391304\n",
      "26  27  0.473684  0.333333  0.391304\n",
      "27  28  0.500000  0.370370  0.425532\n",
      "28  29  0.476190  0.370370  0.416667\n",
      "29  30  0.476190  0.370370  0.416667\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.074074  0.137931\n",
      "1    2  1.000000  0.185185  0.312500\n",
      "2    3  1.000000  0.185185  0.312500\n",
      "3    4  1.000000  0.222222  0.363636\n",
      "4    5  1.000000  0.222222  0.363636\n",
      "5    6  0.777778  0.259259  0.388889\n",
      "6    7  0.777778  0.259259  0.388889\n",
      "7    8  0.777778  0.259259  0.388889\n",
      "8    9  0.636364  0.259259  0.368421\n",
      "9   10  0.636364  0.259259  0.368421\n",
      "10  11  0.583333  0.259259  0.358974\n",
      "11  12  0.533333  0.296296  0.380952\n",
      "12  13  0.533333  0.296296  0.380952\n",
      "13  14  0.533333  0.296296  0.380952\n",
      "14  15  0.533333  0.296296  0.380952\n",
      "15  16  0.533333  0.296296  0.380952\n",
      "16  17  0.533333  0.296296  0.380952\n",
      "17  18  0.562500  0.333333  0.418605\n",
      "18  19  0.562500  0.333333  0.418605\n",
      "19  20  0.473684  0.333333  0.391304\n",
      "20  21  0.473684  0.333333  0.391304\n",
      "21  22  0.473684  0.333333  0.391304\n",
      "22  23  0.428571  0.333333  0.375000\n",
      "23  24  0.409091  0.333333  0.367347\n",
      "24  25  0.434783  0.370370  0.400000\n",
      "25  26  0.434783  0.370370  0.400000\n",
      "26  27  0.416667  0.370370  0.392157\n",
      "27  28  0.416667  0.370370  0.392157\n",
      "28  29  0.416667  0.370370  0.392157\n",
      "29  30  0.416667  0.370370  0.392157\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.653061  0.663212  0.658098\n",
      "1    2  0.496835  0.813472  0.616896\n",
      "2    3  0.423077  0.854922  0.566038\n",
      "3    4  0.379863  0.860104  0.526984\n",
      "4    5  0.344330  0.865285  0.492625\n",
      "5    6  0.327485  0.870466  0.475921\n",
      "6    7  0.314815  0.880829  0.463847\n",
      "7    8  0.299824  0.880829  0.447368\n",
      "8    9  0.287879  0.886010  0.434562\n",
      "9   10  0.276699  0.886010  0.421702\n",
      "10  11  0.270866  0.891192  0.415459\n",
      "11  12  0.264122  0.896373  0.408019\n",
      "12  13  0.261194  0.906736  0.405562\n",
      "13  14  0.255443  0.911917  0.399093\n",
      "14  15  0.250712  0.911917  0.393296\n",
      "15  16  0.247539  0.911917  0.389381\n",
      "16  17  0.242134  0.917098  0.383117\n",
      "17  18  0.239189  0.917098  0.379421\n",
      "18  19  0.235372  0.917098  0.374603\n",
      "19  20  0.232283  0.917098  0.370681\n",
      "20  21  0.229572  0.917098  0.367220\n",
      "21  22  0.226633  0.917098  0.363450\n",
      "22  23  0.224905  0.917098  0.361224\n",
      "23  24  0.222922  0.917098  0.358663\n",
      "24  25  0.220423  0.917098  0.355422\n",
      "25  26  0.218249  0.917098  0.352590\n",
      "26  27  0.216381  0.917098  0.350148\n",
      "27  28  0.214027  0.917098  0.347059\n",
      "28  29  0.211976  0.917098  0.344358\n",
      "29  30  0.210464  0.917098  0.342360\n",
      "     k       avg     count       MRR\n",
      "0    1  0.676768  0.694301  0.685422\n",
      "1    2  0.507886  0.834197  0.631373\n",
      "2    3  0.442708  0.880829  0.589255\n",
      "3    4  0.404706  0.891192  0.556634\n",
      "4    5  0.372845  0.896373  0.526636\n",
      "5    6  0.350101  0.901554  0.504348\n",
      "6    7  0.329588  0.911917  0.484182\n",
      "7    8  0.314848  0.911917  0.468085\n",
      "8    9  0.302926  0.911917  0.454780\n",
      "9   10  0.293046  0.917098  0.444166\n",
      "10  11  0.286400  0.927461  0.437653\n",
      "11  12  0.283228  0.927461  0.433939\n",
      "12  13  0.276662  0.927461  0.426190\n",
      "13  14  0.270393  0.927461  0.418713\n",
      "14  15  0.265973  0.927461  0.413395\n",
      "15  16  0.263543  0.932642  0.410959\n",
      "16  17  0.259740  0.932642  0.406321\n",
      "17  18  0.252101  0.932642  0.396913\n",
      "18  19  0.249311  0.937824  0.393906\n",
      "19  20  0.246612  0.943005  0.390977\n",
      "20  21  0.241700  0.943005  0.384778\n",
      "21  22  0.239474  0.943005  0.381952\n",
      "22  23  0.236671  0.943005  0.378378\n",
      "23  24  0.233633  0.943005  0.374486\n",
      "24  25  0.231552  0.943005  0.371808\n",
      "25  26  0.228931  0.943005  0.368421\n",
      "26  27  0.226650  0.943005  0.365462\n",
      "27  28  0.225527  0.943005  0.364000\n",
      "28  29  0.224414  0.943005  0.362550\n",
      "29  30  0.222766  0.943005  0.360396\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-567-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.750000  0.681818  0.714286\n",
      "1    2  0.576923  0.681818  0.625000\n",
      "2    3  0.531250  0.772727  0.629630\n",
      "3    4  0.500000  0.818182  0.620690\n",
      "4    5  0.486486  0.818182  0.610169\n",
      "5    6  0.422222  0.863636  0.567164\n",
      "6    7  0.392157  0.909091  0.547945\n",
      "7    8  0.363636  0.909091  0.519481\n",
      "8    9  0.357143  0.909091  0.512821\n",
      "9   10  0.357143  0.909091  0.512821\n",
      "10  11  0.344828  0.909091  0.500000\n",
      "11  12  0.333333  0.909091  0.487805\n",
      "12  13  0.333333  0.909091  0.487805\n",
      "13  14  0.327869  0.909091  0.481928\n",
      "14  15  0.338710  0.954545  0.500000\n",
      "15  16  0.328125  0.954545  0.488372\n",
      "16  17  0.328125  0.954545  0.488372\n",
      "17  18  0.328125  0.954545  0.488372\n",
      "18  19  0.313433  0.954545  0.471910\n",
      "19  20  0.313433  0.954545  0.471910\n",
      "20  21  0.313433  0.954545  0.471910\n",
      "21  22  0.313433  0.954545  0.471910\n",
      "22  23  0.313433  0.954545  0.471910\n",
      "23  24  0.308824  0.954545  0.466667\n",
      "24  25  0.304348  0.954545  0.461538\n",
      "25  26  0.300000  0.954545  0.456522\n",
      "26  27  0.300000  0.954545  0.456522\n",
      "27  28  0.300000  0.954545  0.456522\n",
      "28  29  0.300000  0.954545  0.456522\n",
      "29  30  0.295775  0.954545  0.451613\n",
      "     k       avg     count       MRR\n",
      "0    1  0.750000  0.545455  0.631579\n",
      "1    2  0.680000  0.772727  0.723404\n",
      "2    3  0.586207  0.772727  0.666667\n",
      "3    4  0.529412  0.818182  0.642857\n",
      "4    5  0.542857  0.863636  0.666667\n",
      "5    6  0.527778  0.863636  0.655172\n",
      "6    7  0.500000  0.863636  0.633333\n",
      "7    8  0.452381  0.863636  0.593750\n",
      "8    9  0.395833  0.863636  0.542857\n",
      "9   10  0.387755  0.863636  0.535211\n",
      "10  11  0.372549  0.863636  0.520548\n",
      "11  12  0.363636  0.909091  0.519481\n",
      "12  13  0.344828  0.909091  0.500000\n",
      "13  14  0.338983  0.909091  0.493827\n",
      "14  15  0.327869  0.909091  0.481928\n",
      "15  16  0.322581  0.909091  0.476190\n",
      "16  17  0.317460  0.909091  0.470588\n",
      "17  18  0.317460  0.909091  0.470588\n",
      "18  19  0.317460  0.909091  0.470588\n",
      "19  20  0.312500  0.909091  0.465116\n",
      "20  21  0.307692  0.909091  0.459770\n",
      "21  22  0.289855  0.909091  0.439560\n",
      "22  23  0.289855  0.909091  0.439560\n",
      "23  24  0.289855  0.909091  0.439560\n",
      "24  25  0.285714  0.909091  0.434783\n",
      "25  26  0.281690  0.909091  0.430108\n",
      "26  27  0.281690  0.909091  0.430108\n",
      "27  28  0.281690  0.909091  0.430108\n",
      "28  29  0.277778  0.909091  0.425532\n",
      "29  30  0.273973  0.909091  0.421053\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-321-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.148148  0.258065\n",
      "1    2  0.714286  0.185185  0.294118\n",
      "2    3  0.800000  0.296296  0.432432\n",
      "3    4  0.818182  0.333333  0.473684\n",
      "4    5  0.692308  0.333333  0.450000\n",
      "5    6  0.666667  0.370370  0.476190\n",
      "6    7  0.625000  0.370370  0.465116\n",
      "7    8  0.588235  0.370370  0.454545\n",
      "8    9  0.555556  0.370370  0.444444\n",
      "9   10  0.500000  0.407407  0.448980\n",
      "10  11  0.500000  0.407407  0.448980\n",
      "11  12  0.500000  0.407407  0.448980\n",
      "12  13  0.500000  0.407407  0.448980\n",
      "13  14  0.478261  0.407407  0.440000\n",
      "14  15  0.500000  0.444444  0.470588\n",
      "15  16  0.480000  0.444444  0.461538\n",
      "16  17  0.461538  0.444444  0.452830\n",
      "17  18  0.461538  0.444444  0.452830\n",
      "18  19  0.461538  0.444444  0.452830\n",
      "19  20  0.413793  0.444444  0.428571\n",
      "20  21  0.413793  0.444444  0.428571\n",
      "21  22  0.400000  0.444444  0.421053\n",
      "22  23  0.400000  0.444444  0.421053\n",
      "23  24  0.400000  0.444444  0.421053\n",
      "24  25  0.406250  0.481481  0.440678\n",
      "25  26  0.406250  0.481481  0.440678\n",
      "26  27  0.424242  0.518519  0.466667\n",
      "27  28  0.424242  0.518519  0.466667\n",
      "28  29  0.411765  0.518519  0.459016\n",
      "29  30  0.411765  0.518519  0.459016\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.074074  0.137931\n",
      "1    2  0.800000  0.148148  0.250000\n",
      "2    3  0.857143  0.222222  0.352941\n",
      "3    4  0.857143  0.222222  0.352941\n",
      "4    5  0.875000  0.259259  0.400000\n",
      "5    6  0.700000  0.259259  0.378378\n",
      "6    7  0.769231  0.370370  0.500000\n",
      "7    8  0.800000  0.444444  0.571429\n",
      "8    9  0.750000  0.444444  0.558140\n",
      "9   10  0.666667  0.444444  0.533333\n",
      "10  11  0.600000  0.444444  0.510638\n",
      "11  12  0.545455  0.444444  0.489796\n",
      "12  13  0.545455  0.444444  0.489796\n",
      "13  14  0.545455  0.444444  0.489796\n",
      "14  15  0.521739  0.444444  0.480000\n",
      "15  16  0.500000  0.444444  0.470588\n",
      "16  17  0.461538  0.444444  0.452830\n",
      "17  18  0.461538  0.444444  0.452830\n",
      "18  19  0.428571  0.444444  0.436364\n",
      "19  20  0.428571  0.444444  0.436364\n",
      "20  21  0.375000  0.444444  0.406780\n",
      "21  22  0.352941  0.444444  0.393443\n",
      "22  23  0.388889  0.518519  0.444444\n",
      "23  24  0.378378  0.518519  0.437500\n",
      "24  25  0.378378  0.518519  0.437500\n",
      "25  26  0.378378  0.518519  0.437500\n",
      "26  27  0.384615  0.555556  0.454545\n",
      "27  28  0.375000  0.555556  0.447761\n",
      "28  29  0.375000  0.555556  0.447761\n",
      "29  30  0.375000  0.555556  0.447761\n",
      "\n",
      "deepmatcher\n",
      "single-triplet \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-6144-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.683721  0.761658  0.720588\n",
      "1    2  0.486486  0.839378  0.615970\n",
      "2    3  0.426768  0.875648  0.573854\n",
      "3    4  0.372807  0.880829  0.523883\n",
      "4    5  0.348884  0.891192  0.501458\n",
      "5    6  0.332054  0.896373  0.484594\n",
      "6    7  0.318681  0.901554  0.470907\n",
      "7    8  0.300518  0.901554  0.450777\n",
      "8    9  0.289517  0.901554  0.438287\n",
      "9   10  0.279743  0.901554  0.426994\n",
      "10  11  0.269767  0.901554  0.415274\n",
      "11  12  0.261654  0.901554  0.405594\n",
      "12  13  0.255132  0.901554  0.397714\n",
      "13  14  0.251076  0.906736  0.393258\n",
      "14  15  0.248588  0.911917  0.390677\n",
      "15  16  0.244105  0.911917  0.385120\n",
      "16  17  0.240437  0.911917  0.380541\n",
      "17  18  0.236559  0.911917  0.375667\n",
      "18  19  0.231884  0.911917  0.369748\n",
      "19  20  0.229167  0.911917  0.366285\n",
      "20  21  0.227506  0.917098  0.364573\n",
      "21  22  0.224051  0.917098  0.360122\n",
      "22  23  0.222642  0.917098  0.358300\n",
      "23  24  0.221527  0.917098  0.356855\n",
      "24  25  0.220149  0.917098  0.355065\n",
      "25  26  0.218519  0.917098  0.352941\n",
      "26  27  0.217445  0.917098  0.351539\n",
      "27  28  0.215328  0.917098  0.348768\n",
      "28  29  0.212996  0.917098  0.345703\n",
      "29  30  0.213604  0.927461  0.347236\n",
      "     k       avg     count       MRR\n",
      "0    1  0.665072  0.720207  0.691542\n",
      "1    2  0.496970  0.849741  0.627151\n",
      "2    3  0.400000  0.870466  0.548124\n",
      "3    4  0.363830  0.886010  0.515837\n",
      "4    5  0.334630  0.891192  0.486563\n",
      "5    6  0.321561  0.896373  0.473324\n",
      "6    7  0.308511  0.901554  0.459709\n",
      "7    8  0.291391  0.911917  0.441656\n",
      "8    9  0.280952  0.917098  0.430134\n",
      "9   10  0.271057  0.917098  0.418440\n",
      "10  11  0.265367  0.917098  0.411628\n",
      "11  12  0.259151  0.917098  0.404110\n",
      "12  13  0.253923  0.922280  0.398210\n",
      "13  14  0.248257  0.922280  0.391209\n",
      "14  15  0.242507  0.922280  0.384035\n",
      "15  16  0.239946  0.927461  0.381257\n",
      "16  17  0.235837  0.927461  0.376050\n",
      "17  18  0.233073  0.927461  0.372529\n",
      "18  19  0.230968  0.927461  0.369835\n",
      "19  20  0.227848  0.932642  0.366226\n",
      "20  21  0.226087  0.943005  0.364729\n",
      "21  22  0.223313  0.943005  0.361111\n",
      "22  23  0.221411  0.943005  0.358621\n",
      "23  24  0.219542  0.943005  0.356164\n",
      "24  25  0.217443  0.943005  0.353398\n",
      "25  26  0.216152  0.943005  0.351691\n",
      "26  27  0.213866  0.943005  0.348659\n",
      "27  28  0.210892  0.943005  0.344697\n",
      "28  29  0.210103  0.948187  0.343985\n",
      "29  30  0.208904  0.948187  0.342376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    #if 'deepmatcher' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "    if 'json' in i and 'deepmatcher' not in i:\n",
    "        conf = load_config(i)\n",
    "        if conf['data'] == 'deepmatcher' and conf['arch'] == 'single-triplet' and 'distilbert' in conf['bert_path']:\n",
    "            config_knn = get_config_knn_dir(i)\n",
    "            print(conf['data'])\n",
    "            print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "            print(i)\n",
    "            files = get_sorted_files(config_knn)\n",
    "            for j in files:\n",
    "                if 'knn_results' in j:\n",
    "                    results = pd.read_pickle(j)\n",
    "                    print(results[['k', 'avg', 'count', 'MRR']])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-burst",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "protected-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.289855  0.097087  0.145455\n",
      "1    2  0.236842  0.131068  0.168750\n",
      "2    3  0.203593  0.165049  0.182306\n",
      "3    4  0.183168  0.179612  0.181373\n",
      "4    5  0.187755  0.223301  0.203991\n",
      "5    6  0.186131  0.247573  0.212500\n",
      "6    7  0.182663  0.286408  0.223062\n",
      "7    8  0.172414  0.291262  0.216606\n",
      "8    9  0.166667  0.305825  0.215753\n",
      "9   10  0.165414  0.320388  0.218182\n",
      "10  11  0.160000  0.330097  0.215531\n",
      "11  12  0.158837  0.344660  0.217458\n",
      "12  13  0.152401  0.354369  0.213139\n",
      "13  14  0.149701  0.364078  0.212164\n",
      "14  15  0.148008  0.378641  0.212824\n",
      "15  16  0.140036  0.378641  0.204456\n",
      "16  17  0.141361  0.393204  0.207959\n",
      "17  18  0.137755  0.393204  0.204030\n",
      "18  19  0.133443  0.393204  0.199262\n",
      "19  20  0.132686  0.398058  0.199029\n",
      "20  21  0.128728  0.398058  0.194543\n",
      "21  22  0.128440  0.407767  0.195349\n",
      "22  23  0.129518  0.417476  0.197701\n",
      "23  24  0.126844  0.417476  0.194570\n",
      "24  25  0.125182  0.417476  0.192609\n",
      "25  26  0.126961  0.432039  0.196251\n",
      "26  27  0.125529  0.432039  0.194536\n",
      "27  28  0.124827  0.436893  0.194175\n",
      "28  29  0.123288  0.436893  0.192308\n",
      "29  30  0.121457  0.436893  0.190074\n",
      "     k       avg     count       MRR\n",
      "0    1  0.289855  0.097087  0.145455\n",
      "1    2  0.236842  0.131068  0.168750\n",
      "2    3  0.203593  0.165049  0.182306\n",
      "3    4  0.183168  0.179612  0.181373\n",
      "4    5  0.187755  0.223301  0.203991\n",
      "5    6  0.186131  0.247573  0.212500\n",
      "6    7  0.182663  0.286408  0.223062\n",
      "7    8  0.172414  0.291262  0.216606\n",
      "8    9  0.166667  0.305825  0.215753\n",
      "9   10  0.165414  0.320388  0.218182\n",
      "10  11  0.160000  0.330097  0.215531\n",
      "11  12  0.158837  0.344660  0.217458\n",
      "12  13  0.152401  0.354369  0.213139\n",
      "13  14  0.149701  0.364078  0.212164\n",
      "14  15  0.148008  0.378641  0.212824\n",
      "15  16  0.140036  0.378641  0.204456\n",
      "16  17  0.141361  0.393204  0.207959\n",
      "17  18  0.137755  0.393204  0.204030\n",
      "18  19  0.133443  0.393204  0.199262\n",
      "19  20  0.132686  0.398058  0.199029\n",
      "20  21  0.128728  0.398058  0.194543\n",
      "21  22  0.128440  0.407767  0.195349\n",
      "22  23  0.129518  0.417476  0.197701\n",
      "23  24  0.126844  0.417476  0.194570\n",
      "24  25  0.125182  0.417476  0.192609\n",
      "25  26  0.126961  0.432039  0.196251\n",
      "26  27  0.125529  0.432039  0.194536\n",
      "27  28  0.124827  0.436893  0.194175\n",
      "28  29  0.123288  0.436893  0.192308\n",
      "29  30  0.121457  0.436893  0.190074\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.587097  0.388889  0.467866\n",
      "1    2  0.479675  0.504274  0.491667\n",
      "2    3  0.405660  0.551282  0.467391\n",
      "3    4  0.371901  0.576923  0.452261\n",
      "4    5  0.342995  0.606838  0.438272\n",
      "5    6  0.319149  0.641026  0.426136\n",
      "6    7  0.297830  0.645299  0.407557\n",
      "7    8  0.283054  0.649573  0.394293\n",
      "8    9  0.268551  0.649573  0.380000\n",
      "9   10  0.258765  0.662393  0.372149\n",
      "10  11  0.250394  0.679487  0.365938\n",
      "11  12  0.239940  0.688034  0.355801\n",
      "12  13  0.233859  0.696581  0.350161\n",
      "13  14  0.227147  0.700855  0.343096\n",
      "14  15  0.222520  0.709402  0.338776\n",
      "15  16  0.218873  0.713675  0.335005\n",
      "16  17  0.213282  0.713675  0.328417\n",
      "17  18  0.211321  0.717949  0.326531\n",
      "18  19  0.205630  0.717949  0.319696\n",
      "19  20  0.203369  0.722222  0.317371\n",
      "20  21  0.201190  0.722222  0.314711\n",
      "21  22  0.197661  0.722222  0.310376\n",
      "22  23  0.197674  0.726496  0.310786\n",
      "23  24  0.193843  0.726496  0.306031\n",
      "24  25  0.190157  0.726496  0.301418\n",
      "25  26  0.188119  0.730769  0.299213\n",
      "26  27  0.185870  0.730769  0.296360\n",
      "27  28  0.183957  0.735043  0.294269\n",
      "28  29  0.181243  0.735043  0.290786\n",
      "29  30  0.179834  0.739316  0.289298\n",
      "     k       avg     count       MRR\n",
      "0    1  0.587097  0.388889  0.467866\n",
      "1    2  0.479675  0.504274  0.491667\n",
      "2    3  0.405660  0.551282  0.467391\n",
      "3    4  0.371901  0.576923  0.452261\n",
      "4    5  0.342995  0.606838  0.438272\n",
      "5    6  0.319149  0.641026  0.426136\n",
      "6    7  0.297830  0.645299  0.407557\n",
      "7    8  0.283054  0.649573  0.394293\n",
      "8    9  0.268551  0.649573  0.380000\n",
      "9   10  0.258765  0.662393  0.372149\n",
      "10  11  0.250394  0.679487  0.365938\n",
      "11  12  0.239940  0.688034  0.355801\n",
      "12  13  0.233859  0.696581  0.350161\n",
      "13  14  0.227147  0.700855  0.343096\n",
      "14  15  0.222520  0.709402  0.338776\n",
      "15  16  0.218873  0.713675  0.335005\n",
      "16  17  0.213282  0.713675  0.328417\n",
      "17  18  0.211321  0.717949  0.326531\n",
      "18  19  0.205630  0.717949  0.319696\n",
      "19  20  0.203369  0.722222  0.317371\n",
      "20  21  0.201190  0.722222  0.314711\n",
      "21  22  0.197661  0.722222  0.310376\n",
      "22  23  0.197674  0.726496  0.310786\n",
      "23  24  0.193843  0.726496  0.306031\n",
      "24  25  0.190157  0.726496  0.301418\n",
      "25  26  0.188119  0.730769  0.299213\n",
      "26  27  0.185870  0.730769  0.296360\n",
      "27  28  0.183957  0.735043  0.294269\n",
      "28  29  0.181243  0.735043  0.290786\n",
      "29  30  0.179834  0.739316  0.289298\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.600000  0.214286  0.315789\n",
      "1    2  0.500000  0.214286  0.300000\n",
      "2    3  0.500000  0.214286  0.300000\n",
      "3    4  0.500000  0.214286  0.300000\n",
      "4    5  0.500000  0.214286  0.300000\n",
      "5    6  0.500000  0.214286  0.300000\n",
      "6    7  0.500000  0.214286  0.300000\n",
      "7    8  0.428571  0.214286  0.285714\n",
      "8    9  0.500000  0.285714  0.363636\n",
      "9   10  0.500000  0.285714  0.363636\n",
      "10  11  0.500000  0.285714  0.363636\n",
      "11  12  0.500000  0.285714  0.363636\n",
      "12  13  0.500000  0.285714  0.363636\n",
      "13  14  0.500000  0.285714  0.363636\n",
      "14  15  0.500000  0.285714  0.363636\n",
      "15  16  0.500000  0.285714  0.363636\n",
      "16  17  0.500000  0.285714  0.363636\n",
      "17  18  0.500000  0.285714  0.363636\n",
      "18  19  0.444444  0.285714  0.347826\n",
      "19  20  0.444444  0.285714  0.347826\n",
      "20  21  0.444444  0.285714  0.347826\n",
      "21  22  0.444444  0.285714  0.347826\n",
      "22  23  0.444444  0.285714  0.347826\n",
      "23  24  0.444444  0.285714  0.347826\n",
      "24  25  0.444444  0.285714  0.347826\n",
      "25  26  0.444444  0.285714  0.347826\n",
      "26  27  0.500000  0.357143  0.416667\n",
      "27  28  0.500000  0.357143  0.416667\n",
      "28  29  0.500000  0.357143  0.416667\n",
      "29  30  0.454545  0.357143  0.400000\n",
      "     k       avg     count       MRR\n",
      "0    1  0.600000  0.214286  0.315789\n",
      "1    2  0.500000  0.214286  0.300000\n",
      "2    3  0.500000  0.214286  0.300000\n",
      "3    4  0.500000  0.214286  0.300000\n",
      "4    5  0.500000  0.214286  0.300000\n",
      "5    6  0.500000  0.214286  0.300000\n",
      "6    7  0.500000  0.214286  0.300000\n",
      "7    8  0.428571  0.214286  0.285714\n",
      "8    9  0.500000  0.285714  0.363636\n",
      "9   10  0.500000  0.285714  0.363636\n",
      "10  11  0.500000  0.285714  0.363636\n",
      "11  12  0.500000  0.285714  0.363636\n",
      "12  13  0.500000  0.285714  0.363636\n",
      "13  14  0.500000  0.285714  0.363636\n",
      "14  15  0.500000  0.285714  0.363636\n",
      "15  16  0.500000  0.285714  0.363636\n",
      "16  17  0.500000  0.285714  0.363636\n",
      "17  18  0.500000  0.285714  0.363636\n",
      "18  19  0.444444  0.285714  0.347826\n",
      "19  20  0.444444  0.285714  0.347826\n",
      "20  21  0.444444  0.285714  0.347826\n",
      "21  22  0.444444  0.285714  0.347826\n",
      "22  23  0.444444  0.285714  0.347826\n",
      "23  24  0.444444  0.285714  0.347826\n",
      "24  25  0.444444  0.285714  0.347826\n",
      "25  26  0.444444  0.285714  0.347826\n",
      "26  27  0.500000  0.357143  0.416667\n",
      "27  28  0.500000  0.357143  0.416667\n",
      "28  29  0.500000  0.357143  0.416667\n",
      "29  30  0.454545  0.357143  0.400000\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//company_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.954167  0.040603  0.077891\n",
      "1    2  0.935103  0.056206  0.106038\n",
      "2    3  0.908416  0.065071  0.121443\n",
      "3    4  0.895425  0.072872  0.134776\n",
      "4    5  0.877629  0.081383  0.148953\n",
      "5    6  0.861646  0.087234  0.158429\n",
      "6    7  0.850891  0.093085  0.167812\n",
      "7    8  0.844512  0.098227  0.175985\n",
      "8    9  0.840288  0.103546  0.184373\n",
      "9   10  0.840878  0.108688  0.192495\n",
      "10  11  0.837270  0.113121  0.199313\n",
      "11  12  0.835000  0.118440  0.207453\n",
      "12  13  0.833741  0.120922  0.211211\n",
      "13  14  0.830166  0.123936  0.215674\n",
      "14  15  0.830626  0.126950  0.220240\n",
      "15  16  0.826772  0.130319  0.225149\n",
      "16  17  0.823913  0.134397  0.231098\n",
      "17  18  0.822151  0.136879  0.234686\n",
      "18  19  0.822060  0.140071  0.239358\n",
      "19  20  0.819388  0.142376  0.242598\n",
      "20  21  0.808448  0.145922  0.247221\n",
      "21  22  0.807287  0.149291  0.251983\n",
      "22  23  0.804327  0.151596  0.255110\n",
      "23  24  0.803128  0.154787  0.259551\n",
      "24  25  0.800546  0.155851  0.260908\n",
      "25  26  0.796959  0.157979  0.263687\n",
      "26  27  0.794351  0.159574  0.265761\n",
      "27  28  0.791703  0.162411  0.269531\n",
      "28  29  0.789966  0.164716  0.272594\n",
      "29  30  0.788413  0.166489  0.274923\n",
      "     k       avg     count       MRR\n",
      "0    1  0.954167  0.040603  0.077891\n",
      "1    2  0.935103  0.056206  0.106038\n",
      "2    3  0.908416  0.065071  0.121443\n",
      "3    4  0.895425  0.072872  0.134776\n",
      "4    5  0.877629  0.081383  0.148953\n",
      "5    6  0.861646  0.087234  0.158429\n",
      "6    7  0.850891  0.093085  0.167812\n",
      "7    8  0.844512  0.098227  0.175985\n",
      "8    9  0.840288  0.103546  0.184373\n",
      "9   10  0.840878  0.108688  0.192495\n",
      "10  11  0.837270  0.113121  0.199313\n",
      "11  12  0.835000  0.118440  0.207453\n",
      "12  13  0.833741  0.120922  0.211211\n",
      "13  14  0.830166  0.123936  0.215674\n",
      "14  15  0.830626  0.126950  0.220240\n",
      "15  16  0.826772  0.130319  0.225149\n",
      "16  17  0.823913  0.134397  0.231098\n",
      "17  18  0.822151  0.136879  0.234686\n",
      "18  19  0.822060  0.140071  0.239358\n",
      "19  20  0.819388  0.142376  0.242598\n",
      "20  21  0.808448  0.145922  0.247221\n",
      "21  22  0.807287  0.149291  0.251983\n",
      "22  23  0.804327  0.151596  0.255110\n",
      "23  24  0.803128  0.154787  0.259551\n",
      "24  25  0.800546  0.155851  0.260908\n",
      "25  26  0.796959  0.157979  0.263687\n",
      "26  27  0.794351  0.159574  0.265761\n",
      "27  28  0.791703  0.162411  0.269531\n",
      "28  29  0.789966  0.164716  0.272594\n",
      "29  30  0.788413  0.166489  0.274923\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.947242  0.889640  0.917538\n",
      "1    2  0.864979  0.923423  0.893246\n",
      "2    3  0.825651  0.927928  0.873807\n",
      "3    4  0.797688  0.932432  0.859813\n",
      "4    5  0.780899  0.939189  0.852761\n",
      "5    6  0.763736  0.939189  0.842424\n",
      "6    7  0.752708  0.939189  0.835671\n",
      "7    8  0.746881  0.943694  0.833831\n",
      "8    9  0.737676  0.943694  0.828063\n",
      "9   10  0.727903  0.945946  0.822723\n",
      "10  11  0.722127  0.948198  0.819864\n",
      "11  12  0.718910  0.950450  0.818623\n",
      "12  13  0.711409  0.954955  0.815385\n",
      "13  14  0.700165  0.957207  0.808754\n",
      "14  15  0.694943  0.959459  0.806055\n",
      "15  16  0.687601  0.961712  0.801878\n",
      "16  17  0.682109  0.961712  0.798131\n",
      "17  18  0.672441  0.961712  0.791474\n",
      "18  19  0.668232  0.961712  0.788550\n",
      "19  20  0.665109  0.961712  0.786372\n",
      "20  21  0.660991  0.961712  0.783486\n",
      "21  22  0.656923  0.961712  0.780622\n",
      "22  23  0.650915  0.961712  0.776364\n",
      "23  24  0.645991  0.961712  0.772851\n",
      "24  25  0.639222  0.961712  0.767986\n",
      "25  26  0.635417  0.961712  0.765233\n",
      "26  27  0.627941  0.961712  0.759786\n",
      "27  28  0.627566  0.963964  0.760213\n",
      "28  29  0.622999  0.963964  0.756852\n",
      "29  30  0.622093  0.963964  0.756184\n",
      "     k       avg     count       MRR\n",
      "0    1  0.947242  0.889640  0.917538\n",
      "1    2  0.864979  0.923423  0.893246\n",
      "2    3  0.825651  0.927928  0.873807\n",
      "3    4  0.797688  0.932432  0.859813\n",
      "4    5  0.780899  0.939189  0.852761\n",
      "5    6  0.763736  0.939189  0.842424\n",
      "6    7  0.752708  0.939189  0.835671\n",
      "7    8  0.746881  0.943694  0.833831\n",
      "8    9  0.737676  0.943694  0.828063\n",
      "9   10  0.727903  0.945946  0.822723\n",
      "10  11  0.722127  0.948198  0.819864\n",
      "11  12  0.718910  0.950450  0.818623\n",
      "12  13  0.711409  0.954955  0.815385\n",
      "13  14  0.700165  0.957207  0.808754\n",
      "14  15  0.694943  0.959459  0.806055\n",
      "15  16  0.687601  0.961712  0.801878\n",
      "16  17  0.682109  0.961712  0.798131\n",
      "17  18  0.672441  0.961712  0.791474\n",
      "18  19  0.668232  0.961712  0.788550\n",
      "19  20  0.665109  0.961712  0.786372\n",
      "20  21  0.660991  0.961712  0.783486\n",
      "21  22  0.656923  0.961712  0.780622\n",
      "22  23  0.650915  0.961712  0.776364\n",
      "23  24  0.645991  0.961712  0.772851\n",
      "24  25  0.639222  0.961712  0.767986\n",
      "25  26  0.635417  0.961712  0.765233\n",
      "26  27  0.627941  0.961712  0.759786\n",
      "27  28  0.627566  0.963964  0.760213\n",
      "28  29  0.622999  0.963964  0.756852\n",
      "29  30  0.622093  0.963964  0.756184\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.971429  0.285981  0.441877\n",
      "1    2  0.936620  0.372897  0.533422\n",
      "2    3  0.914460  0.419626  0.575272\n",
      "3    4  0.900000  0.445794  0.596250\n",
      "4    5  0.888689  0.462617  0.608482\n",
      "5    6  0.879310  0.476636  0.618182\n",
      "6    7  0.873147  0.495327  0.632081\n",
      "7    8  0.868932  0.501869  0.636256\n",
      "8    9  0.863492  0.508411  0.640000\n",
      "9   10  0.857367  0.511215  0.640515\n",
      "10  11  0.854037  0.514019  0.641774\n",
      "11  12  0.846505  0.520561  0.644676\n",
      "12  13  0.844880  0.524299  0.647059\n",
      "13  14  0.840237  0.530841  0.650630\n",
      "14  15  0.838192  0.537383  0.654897\n",
      "15  16  0.827143  0.541121  0.654237\n",
      "16  17  0.826025  0.545794  0.657288\n",
      "17  18  0.820477  0.546729  0.656197\n",
      "18  19  0.815534  0.549533  0.656616\n",
      "19  20  0.811475  0.555140  0.659267\n",
      "20  21  0.807848  0.557944  0.660033\n",
      "21  22  0.806971  0.562617  0.662996\n",
      "22  23  0.804781  0.566355  0.664838\n",
      "23  24  0.797386  0.570093  0.664850\n",
      "24  25  0.791237  0.573832  0.665222\n",
      "25  26  0.791026  0.576636  0.667027\n",
      "26  27  0.787995  0.576636  0.665947\n",
      "27  28  0.780856  0.579439  0.665236\n",
      "28  29  0.777222  0.580374  0.664526\n",
      "29  30  0.771323  0.583178  0.664183\n",
      "     k       avg     count       MRR\n",
      "0    1  0.971429  0.285981  0.441877\n",
      "1    2  0.936620  0.372897  0.533422\n",
      "2    3  0.914460  0.419626  0.575272\n",
      "3    4  0.900000  0.445794  0.596250\n",
      "4    5  0.888689  0.462617  0.608482\n",
      "5    6  0.879310  0.476636  0.618182\n",
      "6    7  0.873147  0.495327  0.632081\n",
      "7    8  0.868932  0.501869  0.636256\n",
      "8    9  0.863492  0.508411  0.640000\n",
      "9   10  0.857367  0.511215  0.640515\n",
      "10  11  0.854037  0.514019  0.641774\n",
      "11  12  0.846505  0.520561  0.644676\n",
      "12  13  0.844880  0.524299  0.647059\n",
      "13  14  0.840237  0.530841  0.650630\n",
      "14  15  0.838192  0.537383  0.654897\n",
      "15  16  0.827143  0.541121  0.654237\n",
      "16  17  0.826025  0.545794  0.657288\n",
      "17  18  0.820477  0.546729  0.656197\n",
      "18  19  0.815534  0.549533  0.656616\n",
      "19  20  0.811475  0.555140  0.659267\n",
      "20  21  0.807848  0.557944  0.660033\n",
      "21  22  0.806971  0.562617  0.662996\n",
      "22  23  0.804781  0.566355  0.664838\n",
      "23  24  0.797386  0.570093  0.664850\n",
      "24  25  0.791237  0.573832  0.665222\n",
      "25  26  0.791026  0.576636  0.667027\n",
      "26  27  0.787995  0.576636  0.665947\n",
      "27  28  0.780856  0.579439  0.665236\n",
      "28  29  0.777222  0.580374  0.664526\n",
      "29  30  0.771323  0.583178  0.664183\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.939481  0.734234  0.824273\n",
      "1    2  0.870000  0.783784  0.824645\n",
      "2    3  0.831435  0.822072  0.826727\n",
      "3    4  0.810870  0.840090  0.825221\n",
      "4    5  0.795359  0.849099  0.821351\n",
      "5    6  0.788382  0.855856  0.820734\n",
      "6    7  0.783505  0.855856  0.818084\n",
      "7    8  0.781377  0.869369  0.823028\n",
      "8    9  0.776447  0.876126  0.823280\n",
      "9   10  0.761252  0.876126  0.814660\n",
      "10  11  0.749522  0.882883  0.810755\n",
      "11  12  0.745731  0.885135  0.809475\n",
      "12  13  0.737828  0.887387  0.805726\n",
      "13  14  0.728782  0.889640  0.801217\n",
      "14  15  0.726103  0.889640  0.799595\n",
      "15  16  0.723949  0.891892  0.799193\n",
      "16  17  0.720508  0.894144  0.797990\n",
      "17  18  0.715827  0.896396  0.796000\n",
      "18  19  0.707965  0.900901  0.792864\n",
      "19  20  0.694444  0.900901  0.784314\n",
      "20  21  0.689655  0.900901  0.781250\n",
      "21  22  0.682594  0.900901  0.776699\n",
      "22  23  0.679661  0.903153  0.775629\n",
      "23  24  0.676174  0.907658  0.775000\n",
      "24  25  0.674457  0.909910  0.774688\n",
      "25  26  0.668874  0.909910  0.770992\n",
      "26  27  0.668317  0.912162  0.771429\n",
      "27  28  0.660163  0.914414  0.766761\n",
      "28  29  0.656452  0.916667  0.765038\n",
      "29  30  0.653846  0.918919  0.764045\n",
      "     k       avg     count       MRR\n",
      "0    1  0.939481  0.734234  0.824273\n",
      "1    2  0.870000  0.783784  0.824645\n",
      "2    3  0.831435  0.822072  0.826727\n",
      "3    4  0.810870  0.840090  0.825221\n",
      "4    5  0.795359  0.849099  0.821351\n",
      "5    6  0.788382  0.855856  0.820734\n",
      "6    7  0.783505  0.855856  0.818084\n",
      "7    8  0.781377  0.869369  0.823028\n",
      "8    9  0.776447  0.876126  0.823280\n",
      "9   10  0.761252  0.876126  0.814660\n",
      "10  11  0.749522  0.882883  0.810755\n",
      "11  12  0.745731  0.885135  0.809475\n",
      "12  13  0.737828  0.887387  0.805726\n",
      "13  14  0.728782  0.889640  0.801217\n",
      "14  15  0.726103  0.889640  0.799595\n",
      "15  16  0.723949  0.891892  0.799193\n",
      "16  17  0.720508  0.894144  0.797990\n",
      "17  18  0.715827  0.896396  0.796000\n",
      "18  19  0.707965  0.900901  0.792864\n",
      "19  20  0.694444  0.900901  0.784314\n",
      "20  21  0.689655  0.900901  0.781250\n",
      "21  22  0.682594  0.900901  0.776699\n",
      "22  23  0.679661  0.903153  0.775629\n",
      "23  24  0.676174  0.907658  0.775000\n",
      "24  25  0.674457  0.909910  0.774688\n",
      "25  26  0.668874  0.909910  0.770992\n",
      "26  27  0.668317  0.912162  0.771429\n",
      "27  28  0.660163  0.914414  0.766761\n",
      "28  29  0.656452  0.916667  0.765038\n",
      "29  30  0.653846  0.918919  0.764045\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.944056  0.252336  0.398230\n",
      "1    2  0.924282  0.330841  0.487268\n",
      "2    3  0.904762  0.372897  0.528127\n",
      "3    4  0.887064  0.403738  0.554913\n",
      "4    5  0.877953  0.416822  0.565272\n",
      "5    6  0.870544  0.433645  0.578915\n",
      "6    7  0.856624  0.441121  0.582357\n",
      "7    8  0.849558  0.448598  0.587156\n",
      "8    9  0.847222  0.456075  0.592953\n",
      "9   10  0.836149  0.462617  0.595668\n",
      "10  11  0.825371  0.468224  0.597496\n",
      "11  12  0.823910  0.476636  0.603908\n",
      "12  13  0.821940  0.483178  0.608593\n",
      "13  14  0.817896  0.486916  0.610428\n",
      "14  15  0.810185  0.490654  0.611176\n",
      "15  16  0.808576  0.493458  0.612885\n",
      "16  17  0.803625  0.497196  0.614319\n",
      "17  18  0.799100  0.498131  0.613702\n",
      "18  19  0.795556  0.501869  0.615473\n",
      "19  20  0.790323  0.503738  0.615297\n",
      "20  21  0.787265  0.508411  0.617831\n",
      "21  22  0.787050  0.511215  0.619830\n",
      "22  23  0.788571  0.515888  0.623729\n",
      "23  24  0.783593  0.517757  0.623523\n",
      "24  25  0.779021  0.520561  0.624090\n",
      "25  26  0.776078  0.521495  0.623812\n",
      "26  27  0.773793  0.524299  0.625070\n",
      "27  28  0.768810  0.525234  0.624098\n",
      "28  29  0.764626  0.525234  0.622715\n",
      "29  30  0.764865  0.528972  0.625414\n",
      "     k       avg     count       MRR\n",
      "0    1  0.944056  0.252336  0.398230\n",
      "1    2  0.924282  0.330841  0.487268\n",
      "2    3  0.904762  0.372897  0.528127\n",
      "3    4  0.887064  0.403738  0.554913\n",
      "4    5  0.877953  0.416822  0.565272\n",
      "5    6  0.870544  0.433645  0.578915\n",
      "6    7  0.856624  0.441121  0.582357\n",
      "7    8  0.849558  0.448598  0.587156\n",
      "8    9  0.847222  0.456075  0.592953\n",
      "9   10  0.836149  0.462617  0.595668\n",
      "10  11  0.825371  0.468224  0.597496\n",
      "11  12  0.823910  0.476636  0.603908\n",
      "12  13  0.821940  0.483178  0.608593\n",
      "13  14  0.817896  0.486916  0.610428\n",
      "14  15  0.810185  0.490654  0.611176\n",
      "15  16  0.808576  0.493458  0.612885\n",
      "16  17  0.803625  0.497196  0.614319\n",
      "17  18  0.799100  0.498131  0.613702\n",
      "18  19  0.795556  0.501869  0.615473\n",
      "19  20  0.790323  0.503738  0.615297\n",
      "20  21  0.787265  0.508411  0.617831\n",
      "21  22  0.787050  0.511215  0.619830\n",
      "22  23  0.788571  0.515888  0.623729\n",
      "23  24  0.783593  0.517757  0.623523\n",
      "24  25  0.779021  0.520561  0.624090\n",
      "25  26  0.776078  0.521495  0.623812\n",
      "26  27  0.773793  0.524299  0.625070\n",
      "27  28  0.768810  0.525234  0.624098\n",
      "28  29  0.764626  0.525234  0.622715\n",
      "29  30  0.764865  0.528972  0.625414\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.074074  0.137931\n",
      "1    2  1.000000  0.074074  0.137931\n",
      "2    3  0.500000  0.074074  0.129032\n",
      "3    4  0.500000  0.074074  0.129032\n",
      "4    5  0.600000  0.111111  0.187500\n",
      "5    6  0.600000  0.111111  0.187500\n",
      "6    7  0.666667  0.148148  0.242424\n",
      "7    8  0.571429  0.148148  0.235294\n",
      "8    9  0.444444  0.148148  0.222222\n",
      "9   10  0.400000  0.148148  0.216216\n",
      "10  11  0.454545  0.185185  0.263158\n",
      "11  12  0.454545  0.185185  0.263158\n",
      "12  13  0.454545  0.185185  0.263158\n",
      "13  14  0.454545  0.185185  0.263158\n",
      "14  15  0.500000  0.222222  0.307692\n",
      "15  16  0.500000  0.222222  0.307692\n",
      "16  17  0.538462  0.259259  0.350000\n",
      "17  18  0.538462  0.259259  0.350000\n",
      "18  19  0.466667  0.259259  0.333333\n",
      "19  20  0.466667  0.259259  0.333333\n",
      "20  21  0.466667  0.259259  0.333333\n",
      "21  22  0.466667  0.259259  0.333333\n",
      "22  23  0.466667  0.259259  0.333333\n",
      "23  24  0.466667  0.259259  0.333333\n",
      "24  25  0.466667  0.259259  0.333333\n",
      "25  26  0.466667  0.259259  0.333333\n",
      "26  27  0.466667  0.259259  0.333333\n",
      "27  28  0.437500  0.259259  0.325581\n",
      "28  29  0.437500  0.259259  0.325581\n",
      "29  30  0.437500  0.259259  0.325581\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.074074  0.137931\n",
      "1    2  1.000000  0.074074  0.137931\n",
      "2    3  0.500000  0.074074  0.129032\n",
      "3    4  0.500000  0.074074  0.129032\n",
      "4    5  0.600000  0.111111  0.187500\n",
      "5    6  0.600000  0.111111  0.187500\n",
      "6    7  0.666667  0.148148  0.242424\n",
      "7    8  0.571429  0.148148  0.235294\n",
      "8    9  0.444444  0.148148  0.222222\n",
      "9   10  0.400000  0.148148  0.216216\n",
      "10  11  0.454545  0.185185  0.263158\n",
      "11  12  0.454545  0.185185  0.263158\n",
      "12  13  0.454545  0.185185  0.263158\n",
      "13  14  0.454545  0.185185  0.263158\n",
      "14  15  0.500000  0.222222  0.307692\n",
      "15  16  0.500000  0.222222  0.307692\n",
      "16  17  0.538462  0.259259  0.350000\n",
      "17  18  0.538462  0.259259  0.350000\n",
      "18  19  0.466667  0.259259  0.333333\n",
      "19  20  0.466667  0.259259  0.333333\n",
      "20  21  0.466667  0.259259  0.333333\n",
      "21  22  0.466667  0.259259  0.333333\n",
      "22  23  0.466667  0.259259  0.333333\n",
      "23  24  0.466667  0.259259  0.333333\n",
      "24  25  0.466667  0.259259  0.333333\n",
      "25  26  0.466667  0.259259  0.333333\n",
      "26  27  0.466667  0.259259  0.333333\n",
      "27  28  0.437500  0.259259  0.325581\n",
      "28  29  0.437500  0.259259  0.325581\n",
      "29  30  0.437500  0.259259  0.325581\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.314815  0.176166  0.225914\n",
      "1    2  0.240000  0.217617  0.228261\n",
      "2    3  0.193966  0.233161  0.211765\n",
      "3    4  0.187943  0.274611  0.223158\n",
      "4    5  0.168750  0.279793  0.210526\n",
      "5    6  0.157143  0.284974  0.202578\n",
      "6    7  0.158854  0.316062  0.211438\n",
      "7    8  0.151589  0.321244  0.205980\n",
      "8    9  0.148984  0.341969  0.207547\n",
      "9   10  0.150106  0.367876  0.213213\n",
      "10  11  0.147177  0.378238  0.211901\n",
      "11  12  0.147287  0.393782  0.214386\n",
      "12  13  0.144195  0.398964  0.211829\n",
      "13  14  0.142599  0.409326  0.211513\n",
      "14  15  0.138840  0.409326  0.207349\n",
      "15  16  0.137457  0.414508  0.206452\n",
      "16  17  0.136213  0.424870  0.206289\n",
      "17  18  0.133871  0.430052  0.204182\n",
      "18  19  0.132911  0.435233  0.203636\n",
      "19  20  0.132308  0.445596  0.204033\n",
      "20  21  0.131024  0.450777  0.203034\n",
      "21  22  0.133041  0.471503  0.207526\n",
      "22  23  0.132102  0.481865  0.207358\n",
      "23  24  0.130252  0.481865  0.205072\n",
      "24  25  0.129834  0.487047  0.205016\n",
      "25  26  0.129428  0.492228  0.204962\n",
      "26  27  0.130201  0.502591  0.206823\n",
      "27  28  0.128307  0.502591  0.204426\n",
      "28  29  0.127438  0.507772  0.203742\n",
      "29  30  0.125794  0.512953  0.202041\n",
      "     k       avg     count       MRR\n",
      "0    1  0.314815  0.176166  0.225914\n",
      "1    2  0.240000  0.217617  0.228261\n",
      "2    3  0.193966  0.233161  0.211765\n",
      "3    4  0.187943  0.274611  0.223158\n",
      "4    5  0.168750  0.279793  0.210526\n",
      "5    6  0.157143  0.284974  0.202578\n",
      "6    7  0.158854  0.316062  0.211438\n",
      "7    8  0.151589  0.321244  0.205980\n",
      "8    9  0.148984  0.341969  0.207547\n",
      "9   10  0.150106  0.367876  0.213213\n",
      "10  11  0.147177  0.378238  0.211901\n",
      "11  12  0.147287  0.393782  0.214386\n",
      "12  13  0.144195  0.398964  0.211829\n",
      "13  14  0.142599  0.409326  0.211513\n",
      "14  15  0.138840  0.409326  0.207349\n",
      "15  16  0.137457  0.414508  0.206452\n",
      "16  17  0.136213  0.424870  0.206289\n",
      "17  18  0.133871  0.430052  0.204182\n",
      "18  19  0.132911  0.435233  0.203636\n",
      "19  20  0.132308  0.445596  0.204033\n",
      "20  21  0.131024  0.450777  0.203034\n",
      "21  22  0.133041  0.471503  0.207526\n",
      "22  23  0.132102  0.481865  0.207358\n",
      "23  24  0.130252  0.481865  0.205072\n",
      "24  25  0.129834  0.487047  0.205016\n",
      "25  26  0.129428  0.492228  0.204962\n",
      "26  27  0.130201  0.502591  0.206823\n",
      "27  28  0.128307  0.502591  0.204426\n",
      "28  29  0.127438  0.507772  0.203742\n",
      "29  30  0.125794  0.512953  0.202041\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.631579  0.545455  0.585366\n",
      "1    2  0.538462  0.636364  0.583333\n",
      "2    3  0.500000  0.727273  0.592593\n",
      "3    4  0.472222  0.772727  0.586207\n",
      "4    5  0.435897  0.772727  0.557377\n",
      "5    6  0.425000  0.772727  0.548387\n",
      "6    7  0.404762  0.772727  0.531250\n",
      "7    8  0.377778  0.772727  0.507463\n",
      "8    9  0.369565  0.772727  0.500000\n",
      "9   10  0.361702  0.772727  0.492754\n",
      "10  11  0.354167  0.772727  0.485714\n",
      "11  12  0.354167  0.772727  0.485714\n",
      "12  13  0.333333  0.772727  0.465753\n",
      "13  14  0.310345  0.818182  0.450000\n",
      "14  15  0.305085  0.818182  0.444444\n",
      "15  16  0.290323  0.818182  0.428571\n",
      "16  17  0.290323  0.818182  0.428571\n",
      "17  18  0.281250  0.818182  0.418605\n",
      "18  19  0.298507  0.909091  0.449438\n",
      "19  20  0.298507  0.909091  0.449438\n",
      "20  21  0.285714  0.909091  0.434783\n",
      "21  22  0.281690  0.909091  0.430108\n",
      "22  23  0.281690  0.909091  0.430108\n",
      "23  24  0.273973  0.909091  0.421053\n",
      "24  25  0.273973  0.909091  0.421053\n",
      "25  26  0.270270  0.909091  0.416667\n",
      "26  27  0.272727  0.954545  0.424242\n",
      "27  28  0.269231  0.954545  0.420000\n",
      "28  29  0.265823  0.954545  0.415842\n",
      "29  30  0.265823  0.954545  0.415842\n",
      "     k       avg     count       MRR\n",
      "0    1  0.631579  0.545455  0.585366\n",
      "1    2  0.538462  0.636364  0.583333\n",
      "2    3  0.500000  0.727273  0.592593\n",
      "3    4  0.472222  0.772727  0.586207\n",
      "4    5  0.435897  0.772727  0.557377\n",
      "5    6  0.425000  0.772727  0.548387\n",
      "6    7  0.404762  0.772727  0.531250\n",
      "7    8  0.377778  0.772727  0.507463\n",
      "8    9  0.369565  0.772727  0.500000\n",
      "9   10  0.361702  0.772727  0.492754\n",
      "10  11  0.354167  0.772727  0.485714\n",
      "11  12  0.354167  0.772727  0.485714\n",
      "12  13  0.333333  0.772727  0.465753\n",
      "13  14  0.310345  0.818182  0.450000\n",
      "14  15  0.305085  0.818182  0.444444\n",
      "15  16  0.290323  0.818182  0.428571\n",
      "16  17  0.290323  0.818182  0.428571\n",
      "17  18  0.281250  0.818182  0.418605\n",
      "18  19  0.298507  0.909091  0.449438\n",
      "19  20  0.298507  0.909091  0.449438\n",
      "20  21  0.285714  0.909091  0.434783\n",
      "21  22  0.281690  0.909091  0.430108\n",
      "22  23  0.281690  0.909091  0.430108\n",
      "23  24  0.273973  0.909091  0.421053\n",
      "24  25  0.273973  0.909091  0.421053\n",
      "25  26  0.270270  0.909091  0.416667\n",
      "26  27  0.272727  0.954545  0.424242\n",
      "27  28  0.269231  0.954545  0.420000\n",
      "28  29  0.265823  0.954545  0.415842\n",
      "29  30  0.265823  0.954545  0.415842\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.111111  0.200000\n",
      "1    2  1.000000  0.185185  0.312500\n",
      "2    3  1.000000  0.222222  0.363636\n",
      "3    4  1.000000  0.222222  0.363636\n",
      "4    5  1.000000  0.222222  0.363636\n",
      "5    6  1.000000  0.259259  0.411765\n",
      "6    7  0.777778  0.259259  0.388889\n",
      "7    8  0.777778  0.259259  0.388889\n",
      "8    9  0.777778  0.259259  0.388889\n",
      "9   10  0.700000  0.259259  0.378378\n",
      "10  11  0.700000  0.259259  0.378378\n",
      "11  12  0.700000  0.259259  0.378378\n",
      "12  13  0.700000  0.259259  0.378378\n",
      "13  14  0.700000  0.259259  0.378378\n",
      "14  15  0.700000  0.259259  0.378378\n",
      "15  16  0.700000  0.259259  0.378378\n",
      "16  17  0.750000  0.333333  0.461538\n",
      "17  18  0.692308  0.333333  0.450000\n",
      "18  19  0.692308  0.333333  0.450000\n",
      "19  20  0.562500  0.333333  0.418605\n",
      "20  21  0.529412  0.333333  0.409091\n",
      "21  22  0.529412  0.333333  0.409091\n",
      "22  23  0.500000  0.333333  0.400000\n",
      "23  24  0.500000  0.333333  0.400000\n",
      "24  25  0.473684  0.333333  0.391304\n",
      "25  26  0.473684  0.333333  0.391304\n",
      "26  27  0.450000  0.333333  0.382979\n",
      "27  28  0.450000  0.333333  0.382979\n",
      "28  29  0.450000  0.333333  0.382979\n",
      "29  30  0.450000  0.333333  0.382979\n",
      "     k       avg     count       MRR\n",
      "0    1  1.000000  0.111111  0.200000\n",
      "1    2  1.000000  0.185185  0.312500\n",
      "2    3  1.000000  0.222222  0.363636\n",
      "3    4  1.000000  0.222222  0.363636\n",
      "4    5  1.000000  0.222222  0.363636\n",
      "5    6  1.000000  0.259259  0.411765\n",
      "6    7  0.777778  0.259259  0.388889\n",
      "7    8  0.777778  0.259259  0.388889\n",
      "8    9  0.777778  0.259259  0.388889\n",
      "9   10  0.700000  0.259259  0.378378\n",
      "10  11  0.700000  0.259259  0.378378\n",
      "11  12  0.700000  0.259259  0.378378\n",
      "12  13  0.700000  0.259259  0.378378\n",
      "13  14  0.700000  0.259259  0.378378\n",
      "14  15  0.700000  0.259259  0.378378\n",
      "15  16  0.700000  0.259259  0.378378\n",
      "16  17  0.750000  0.333333  0.461538\n",
      "17  18  0.692308  0.333333  0.450000\n",
      "18  19  0.692308  0.333333  0.450000\n",
      "19  20  0.562500  0.333333  0.418605\n",
      "20  21  0.529412  0.333333  0.409091\n",
      "21  22  0.529412  0.333333  0.409091\n",
      "22  23  0.500000  0.333333  0.400000\n",
      "23  24  0.500000  0.333333  0.400000\n",
      "24  25  0.473684  0.333333  0.391304\n",
      "25  26  0.473684  0.333333  0.391304\n",
      "26  27  0.450000  0.333333  0.382979\n",
      "27  28  0.450000  0.333333  0.382979\n",
      "28  29  0.450000  0.333333  0.382979\n",
      "29  30  0.450000  0.333333  0.382979\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t distilbert-base-uncased\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-pretrained-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.409722  0.305699  0.350148\n",
      "1    2  0.336100  0.419689  0.373272\n",
      "2    3  0.268371  0.435233  0.332016\n",
      "3    4  0.231608  0.440415  0.303571\n",
      "4    5  0.205543  0.461140  0.284345\n",
      "5    6  0.194444  0.471503  0.275340\n",
      "6    7  0.181641  0.481865  0.263830\n",
      "7    8  0.176147  0.497409  0.260163\n",
      "8    9  0.167832  0.497409  0.250980\n",
      "9   10  0.163636  0.512953  0.248120\n",
      "10  11  0.157729  0.518135  0.241838\n",
      "11  12  0.153383  0.528497  0.237762\n",
      "12  13  0.149927  0.533679  0.234091\n",
      "13  14  0.148876  0.549223  0.234254\n",
      "14  15  0.148501  0.564767  0.235167\n",
      "15  16  0.144562  0.564767  0.230201\n",
      "16  17  0.142672  0.569948  0.228216\n",
      "17  18  0.141221  0.575130  0.226762\n",
      "18  19  0.140373  0.585492  0.226453\n",
      "19  20  0.137515  0.590674  0.223092\n",
      "20  21  0.135613  0.595855  0.220941\n",
      "21  22  0.134483  0.606218  0.220132\n",
      "22  23  0.131757  0.606218  0.216466\n",
      "23  24  0.131723  0.621762  0.217391\n",
      "24  25  0.129310  0.621762  0.214095\n",
      "25  26  0.128998  0.626943  0.213970\n",
      "26  27  0.127883  0.632124  0.212729\n",
      "27  28  0.127083  0.632124  0.211622\n",
      "28  29  0.125773  0.632124  0.209802\n",
      "29  30  0.125510  0.637306  0.209719\n",
      "     k       avg     count       MRR\n",
      "0    1  0.409722  0.305699  0.350148\n",
      "1    2  0.336100  0.419689  0.373272\n",
      "2    3  0.268371  0.435233  0.332016\n",
      "3    4  0.231608  0.440415  0.303571\n",
      "4    5  0.205543  0.461140  0.284345\n",
      "5    6  0.194444  0.471503  0.275340\n",
      "6    7  0.181641  0.481865  0.263830\n",
      "7    8  0.176147  0.497409  0.260163\n",
      "8    9  0.167832  0.497409  0.250980\n",
      "9   10  0.163636  0.512953  0.248120\n",
      "10  11  0.157729  0.518135  0.241838\n",
      "11  12  0.153383  0.528497  0.237762\n",
      "12  13  0.149927  0.533679  0.234091\n",
      "13  14  0.148876  0.549223  0.234254\n",
      "14  15  0.148501  0.564767  0.235167\n",
      "15  16  0.144562  0.564767  0.230201\n",
      "16  17  0.142672  0.569948  0.228216\n",
      "17  18  0.141221  0.575130  0.226762\n",
      "18  19  0.140373  0.585492  0.226453\n",
      "19  20  0.137515  0.590674  0.223092\n",
      "20  21  0.135613  0.595855  0.220941\n",
      "21  22  0.134483  0.606218  0.220132\n",
      "22  23  0.131757  0.606218  0.216466\n",
      "23  24  0.131723  0.621762  0.217391\n",
      "24  25  0.129310  0.621762  0.214095\n",
      "25  26  0.128998  0.626943  0.213970\n",
      "26  27  0.127883  0.632124  0.212729\n",
      "27  28  0.127083  0.632124  0.211622\n",
      "28  29  0.125773  0.632124  0.209802\n",
      "29  30  0.125510  0.637306  0.209719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    #if 'deepmatcher' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "    if 'json' in i and 'deepmatcher' not in i:\n",
    "        conf = load_config(i)\n",
    "        if conf['data'] == 'deepmatcher' and conf['arch'] == 'pretrained' and 'distilbert' in conf['bert_path']:\n",
    "            config_knn = get_config_knn_dir(i)\n",
    "            print(conf['data'])\n",
    "            print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "            print(i)\n",
    "            files = get_sorted_files(config_knn)\n",
    "            for j in files:\n",
    "                if 'knn_results' in j:\n",
    "                    results = pd.read_pickle(j)\n",
    "                    print(results[['k', 'avg', 'count', 'MRR']])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-motorcycle",
   "metadata": {},
   "source": [
    "## Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "complicated-produce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/abt_buy_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.319328  0.184466  0.233846\n",
      "1    2  0.278539  0.296117  0.287059\n",
      "2    3  0.244300  0.364078  0.292398\n",
      "3    4  0.228117  0.417476  0.295026\n",
      "4    5  0.213974  0.475728  0.295181\n",
      "5    6  0.198113  0.509709  0.285326\n",
      "6    7  0.178512  0.524272  0.266338\n",
      "7    8  0.168657  0.548544  0.257991\n",
      "8    9  0.162791  0.577670  0.254002\n",
      "9   10  0.156812  0.592233  0.247967\n",
      "10  11  0.150784  0.606796  0.241546\n",
      "11  12  0.146591  0.626214  0.237569\n",
      "12  13  0.143469  0.650485  0.235088\n",
      "13  14  0.141837  0.674757  0.234401\n",
      "14  15  0.138235  0.684466  0.230016\n",
      "15  16  0.134525  0.694175  0.225374\n",
      "16  17  0.134301  0.718447  0.226300\n",
      "17  18  0.132159  0.728155  0.223714\n",
      "18  19  0.130809  0.737864  0.222222\n",
      "19  20  0.129958  0.747573  0.221423\n",
      "20  21  0.130903  0.766990  0.223638\n",
      "21  22  0.130293  0.776699  0.223152\n",
      "22  23  0.129600  0.786408  0.222527\n",
      "23  24  0.128326  0.796117  0.221024\n",
      "24  25  0.127594  0.805825  0.220305\n",
      "25  26  0.127854  0.815534  0.221053\n",
      "26  27  0.128496  0.825243  0.222368\n",
      "27  28  0.127246  0.825243  0.220493\n",
      "28  29  0.127125  0.834951  0.220654\n",
      "29  30  0.125823  0.834951  0.218690\n",
      "     k       avg     count       MRR\n",
      "0    1  0.319328  0.184466  0.233846\n",
      "1    2  0.278539  0.296117  0.287059\n",
      "2    3  0.244300  0.364078  0.292398\n",
      "3    4  0.228117  0.417476  0.295026\n",
      "4    5  0.213974  0.475728  0.295181\n",
      "5    6  0.198113  0.509709  0.285326\n",
      "6    7  0.178512  0.524272  0.266338\n",
      "7    8  0.168657  0.548544  0.257991\n",
      "8    9  0.162791  0.577670  0.254002\n",
      "9   10  0.156812  0.592233  0.247967\n",
      "10  11  0.150784  0.606796  0.241546\n",
      "11  12  0.146591  0.626214  0.237569\n",
      "12  13  0.143469  0.650485  0.235088\n",
      "13  14  0.141837  0.674757  0.234401\n",
      "14  15  0.138235  0.684466  0.230016\n",
      "15  16  0.134525  0.694175  0.225374\n",
      "16  17  0.134301  0.718447  0.226300\n",
      "17  18  0.132159  0.728155  0.223714\n",
      "18  19  0.130809  0.737864  0.222222\n",
      "19  20  0.129958  0.747573  0.221423\n",
      "20  21  0.130903  0.766990  0.223638\n",
      "21  22  0.130293  0.776699  0.223152\n",
      "22  23  0.129600  0.786408  0.222527\n",
      "23  24  0.128326  0.796117  0.221024\n",
      "24  25  0.127594  0.805825  0.220305\n",
      "25  26  0.127854  0.815534  0.221053\n",
      "26  27  0.128496  0.825243  0.222368\n",
      "27  28  0.127246  0.825243  0.220493\n",
      "28  29  0.127125  0.834951  0.220654\n",
      "29  30  0.125823  0.834951  0.218690\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/amazon_google_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.560748  0.512821  0.535714\n",
      "1    2  0.422287  0.615385  0.500870\n",
      "2    3  0.383178  0.700855  0.495468\n",
      "3    4  0.346380  0.756410  0.475168\n",
      "4    5  0.323529  0.799145  0.460591\n",
      "5    6  0.309904  0.829060  0.451163\n",
      "6    7  0.283019  0.833333  0.422535\n",
      "7    8  0.272358  0.858974  0.413580\n",
      "8    9  0.257033  0.858974  0.395669\n",
      "9   10  0.245466  0.867521  0.382658\n",
      "10  11  0.236659  0.871795  0.372263\n",
      "11  12  0.230599  0.888889  0.366197\n",
      "12  13  0.223291  0.893162  0.357265\n",
      "13  14  0.214800  0.893162  0.346313\n",
      "14  15  0.208955  0.897436  0.338983\n",
      "15  16  0.205029  0.905983  0.334385\n",
      "16  17  0.199436  0.905983  0.326908\n",
      "17  18  0.196313  0.910256  0.322972\n",
      "18  19  0.192065  0.910256  0.317200\n",
      "19  20  0.187500  0.910256  0.310949\n",
      "20  21  0.183147  0.910256  0.304939\n",
      "21  22  0.181895  0.918803  0.303672\n",
      "22  23  0.179766  0.918803  0.300699\n",
      "23  24  0.179043  0.927350  0.300138\n",
      "24  25  0.176566  0.927350  0.296651\n",
      "25  26  0.173739  0.927350  0.292650\n",
      "26  27  0.171271  0.927350  0.289141\n",
      "27  28  0.169782  0.931624  0.287220\n",
      "28  29  0.167435  0.931624  0.283854\n",
      "29  30  0.166159  0.931624  0.282018\n",
      "     k       avg     count       MRR\n",
      "0    1  0.560748  0.512821  0.535714\n",
      "1    2  0.422287  0.615385  0.500870\n",
      "2    3  0.383178  0.700855  0.495468\n",
      "3    4  0.346380  0.756410  0.475168\n",
      "4    5  0.323529  0.799145  0.460591\n",
      "5    6  0.309904  0.829060  0.451163\n",
      "6    7  0.283019  0.833333  0.422535\n",
      "7    8  0.272358  0.858974  0.413580\n",
      "8    9  0.257033  0.858974  0.395669\n",
      "9   10  0.245466  0.867521  0.382658\n",
      "10  11  0.236659  0.871795  0.372263\n",
      "11  12  0.230599  0.888889  0.366197\n",
      "12  13  0.223291  0.893162  0.357265\n",
      "13  14  0.214800  0.893162  0.346313\n",
      "14  15  0.208955  0.897436  0.338983\n",
      "15  16  0.205029  0.905983  0.334385\n",
      "16  17  0.199436  0.905983  0.326908\n",
      "17  18  0.196313  0.910256  0.322972\n",
      "18  19  0.192065  0.910256  0.317200\n",
      "19  20  0.187500  0.910256  0.310949\n",
      "20  21  0.183147  0.910256  0.304939\n",
      "21  22  0.181895  0.918803  0.303672\n",
      "22  23  0.179766  0.918803  0.300699\n",
      "23  24  0.179043  0.927350  0.300138\n",
      "24  25  0.176566  0.927350  0.296651\n",
      "25  26  0.173739  0.927350  0.292650\n",
      "26  27  0.171271  0.927350  0.289141\n",
      "27  28  0.169782  0.931624  0.287220\n",
      "28  29  0.167435  0.931624  0.283854\n",
      "29  30  0.166159  0.931624  0.282018\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/beer_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.846154  0.785714  0.814815\n",
      "1    2  0.750000  0.857143  0.800000\n",
      "2    3  0.705882  0.857143  0.774194\n",
      "3    4  0.631579  0.857143  0.727273\n",
      "4    5  0.631579  0.857143  0.727273\n",
      "5    6  0.631579  0.857143  0.727273\n",
      "6    7  0.631579  0.857143  0.727273\n",
      "7    8  0.631579  0.857143  0.727273\n",
      "8    9  0.631579  0.857143  0.727273\n",
      "9   10  0.631579  0.857143  0.727273\n",
      "10  11  0.631579  0.857143  0.727273\n",
      "11  12  0.600000  0.857143  0.705882\n",
      "12  13  0.571429  0.857143  0.685714\n",
      "13  14  0.571429  0.857143  0.685714\n",
      "14  15  0.571429  0.857143  0.685714\n",
      "15  16  0.571429  0.857143  0.685714\n",
      "16  17  0.571429  0.857143  0.685714\n",
      "17  18  0.571429  0.857143  0.685714\n",
      "18  19  0.545455  0.857143  0.666667\n",
      "19  20  0.545455  0.857143  0.666667\n",
      "20  21  0.521739  0.857143  0.648649\n",
      "21  22  0.521739  0.857143  0.648649\n",
      "22  23  0.521739  0.857143  0.648649\n",
      "23  24  0.521739  0.857143  0.648649\n",
      "24  25  0.521739  0.857143  0.648649\n",
      "25  26  0.521739  0.857143  0.648649\n",
      "26  27  0.521739  0.857143  0.648649\n",
      "27  28  0.500000  0.857143  0.631579\n",
      "28  29  0.500000  0.857143  0.631579\n",
      "29  30  0.500000  0.857143  0.631579\n",
      "     k       avg     count       MRR\n",
      "0    1  0.846154  0.785714  0.814815\n",
      "1    2  0.750000  0.857143  0.800000\n",
      "2    3  0.705882  0.857143  0.774194\n",
      "3    4  0.631579  0.857143  0.727273\n",
      "4    5  0.631579  0.857143  0.727273\n",
      "5    6  0.631579  0.857143  0.727273\n",
      "6    7  0.631579  0.857143  0.727273\n",
      "7    8  0.631579  0.857143  0.727273\n",
      "8    9  0.631579  0.857143  0.727273\n",
      "9   10  0.631579  0.857143  0.727273\n",
      "10  11  0.631579  0.857143  0.727273\n",
      "11  12  0.600000  0.857143  0.705882\n",
      "12  13  0.571429  0.857143  0.685714\n",
      "13  14  0.571429  0.857143  0.685714\n",
      "14  15  0.571429  0.857143  0.685714\n",
      "15  16  0.571429  0.857143  0.685714\n",
      "16  17  0.571429  0.857143  0.685714\n",
      "17  18  0.571429  0.857143  0.685714\n",
      "18  19  0.545455  0.857143  0.666667\n",
      "19  20  0.545455  0.857143  0.666667\n",
      "20  21  0.521739  0.857143  0.648649\n",
      "21  22  0.521739  0.857143  0.648649\n",
      "22  23  0.521739  0.857143  0.648649\n",
      "23  24  0.521739  0.857143  0.648649\n",
      "24  25  0.521739  0.857143  0.648649\n",
      "25  26  0.521739  0.857143  0.648649\n",
      "26  27  0.521739  0.857143  0.648649\n",
      "27  28  0.500000  0.857143  0.631579\n",
      "28  29  0.500000  0.857143  0.631579\n",
      "29  30  0.500000  0.857143  0.631579\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/company_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//company_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.965517  0.089362  0.163583\n",
      "1    2  0.932249  0.121986  0.215742\n",
      "2    3  0.923603  0.143617  0.248581\n",
      "3    4  0.911585  0.159043  0.270833\n",
      "4    5  0.899441  0.171277  0.287757\n",
      "5    6  0.890043  0.182270  0.302575\n",
      "6    7  0.881494  0.192553  0.316065\n",
      "7    8  0.874426  0.202482  0.328822\n",
      "8    9  0.868382  0.209397  0.337429\n",
      "9   10  0.856745  0.218440  0.348121\n",
      "10  11  0.851678  0.225000  0.355961\n",
      "11  12  0.844761  0.231560  0.363485\n",
      "12  13  0.839748  0.235993  0.368443\n",
      "13  14  0.833026  0.240603  0.373366\n",
      "14  15  0.831933  0.245745  0.379414\n",
      "15  16  0.834503  0.253014  0.388299\n",
      "16  17  0.831525  0.258156  0.393993\n",
      "17  18  0.829596  0.262411  0.398707\n",
      "18  19  0.826278  0.266489  0.403003\n",
      "19  20  0.820527  0.270745  0.407146\n",
      "20  21  0.818806  0.274823  0.411523\n",
      "21  22  0.812500  0.278901  0.415259\n",
      "22  23  0.808024  0.282092  0.418189\n",
      "23  24  0.801985  0.286525  0.422208\n",
      "24  25  0.800783  0.290071  0.425875\n",
      "25  26  0.796430  0.292730  0.428108\n",
      "26  27  0.795714  0.296277  0.431783\n",
      "27  28  0.792391  0.299113  0.434290\n",
      "28  29  0.789986  0.302128  0.437091\n",
      "29  30  0.789231  0.304078  0.439012\n",
      "     k       avg     count       MRR\n",
      "0    1  0.965517  0.089362  0.163583\n",
      "1    2  0.932249  0.121986  0.215742\n",
      "2    3  0.923603  0.143617  0.248581\n",
      "3    4  0.911585  0.159043  0.270833\n",
      "4    5  0.899441  0.171277  0.287757\n",
      "5    6  0.890043  0.182270  0.302575\n",
      "6    7  0.881494  0.192553  0.316065\n",
      "7    8  0.874426  0.202482  0.328822\n",
      "8    9  0.868382  0.209397  0.337429\n",
      "9   10  0.856745  0.218440  0.348121\n",
      "10  11  0.851678  0.225000  0.355961\n",
      "11  12  0.844761  0.231560  0.363485\n",
      "12  13  0.839748  0.235993  0.368443\n",
      "13  14  0.833026  0.240603  0.373366\n",
      "14  15  0.831933  0.245745  0.379414\n",
      "15  16  0.834503  0.253014  0.388299\n",
      "16  17  0.831525  0.258156  0.393993\n",
      "17  18  0.829596  0.262411  0.398707\n",
      "18  19  0.826278  0.266489  0.403003\n",
      "19  20  0.820527  0.270745  0.407146\n",
      "20  21  0.818806  0.274823  0.411523\n",
      "21  22  0.812500  0.278901  0.415259\n",
      "22  23  0.808024  0.282092  0.418189\n",
      "23  24  0.801985  0.286525  0.422208\n",
      "24  25  0.800783  0.290071  0.425875\n",
      "25  26  0.796430  0.292730  0.428108\n",
      "26  27  0.795714  0.296277  0.431783\n",
      "27  28  0.792391  0.299113  0.434290\n",
      "28  29  0.789986  0.302128  0.437091\n",
      "29  30  0.789231  0.304078  0.439012\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.951860  0.979730  0.965594\n",
      "1    2  0.764808  0.988739  0.862475\n",
      "2    3  0.690141  0.993243  0.814404\n",
      "3    4  0.644737  0.993243  0.781915\n",
      "4    5  0.606602  0.993243  0.753202\n",
      "5    6  0.581028  0.993243  0.733167\n",
      "6    7  0.566110  0.993243  0.721177\n",
      "7    8  0.543773  0.993243  0.702789\n",
      "8    9  0.530048  0.993243  0.691223\n",
      "9   10  0.511008  0.993243  0.674828\n",
      "10  11  0.502278  0.993243  0.667171\n",
      "11  12  0.490000  0.993243  0.656250\n",
      "12  13  0.476757  0.993243  0.644266\n",
      "13  14  0.468153  0.993243  0.636364\n",
      "14  15  0.460815  0.993243  0.629550\n",
      "15  16  0.453799  0.995495  0.623413\n",
      "16  17  0.446014  0.995495  0.616028\n",
      "17  18  0.439484  0.997748  0.610193\n",
      "18  19  0.432195  0.997748  0.603131\n",
      "19  20  0.429680  0.997748  0.600678\n",
      "20  21  0.426372  0.997748  0.597438\n",
      "21  22  0.419905  0.997748  0.591061\n",
      "22  23  0.417137  0.997748  0.588313\n",
      "23  24  0.413246  0.997748  0.584433\n",
      "24  25  0.408672  0.997748  0.579843\n",
      "25  26  0.405678  0.997748  0.576823\n",
      "26  27  0.403829  0.997748  0.574951\n",
      "27  28  0.400905  0.997748  0.571982\n",
      "28  29  0.398381  0.997748  0.569409\n",
      "29  30  0.396953  0.997748  0.567949\n",
      "     k       avg     count       MRR\n",
      "0    1  0.951860  0.979730  0.965594\n",
      "1    2  0.764808  0.988739  0.862475\n",
      "2    3  0.690141  0.993243  0.814404\n",
      "3    4  0.644737  0.993243  0.781915\n",
      "4    5  0.606602  0.993243  0.753202\n",
      "5    6  0.581028  0.993243  0.733167\n",
      "6    7  0.566110  0.993243  0.721177\n",
      "7    8  0.543773  0.993243  0.702789\n",
      "8    9  0.530048  0.993243  0.691223\n",
      "9   10  0.511008  0.993243  0.674828\n",
      "10  11  0.502278  0.993243  0.667171\n",
      "11  12  0.490000  0.993243  0.656250\n",
      "12  13  0.476757  0.993243  0.644266\n",
      "13  14  0.468153  0.993243  0.636364\n",
      "14  15  0.460815  0.993243  0.629550\n",
      "15  16  0.453799  0.995495  0.623413\n",
      "16  17  0.446014  0.995495  0.616028\n",
      "17  18  0.439484  0.997748  0.610193\n",
      "18  19  0.432195  0.997748  0.603131\n",
      "19  20  0.429680  0.997748  0.600678\n",
      "20  21  0.426372  0.997748  0.597438\n",
      "21  22  0.419905  0.997748  0.591061\n",
      "22  23  0.417137  0.997748  0.588313\n",
      "23  24  0.413246  0.997748  0.584433\n",
      "24  25  0.408672  0.997748  0.579843\n",
      "25  26  0.405678  0.997748  0.576823\n",
      "26  27  0.403829  0.997748  0.574951\n",
      "27  28  0.400905  0.997748  0.571982\n",
      "28  29  0.398381  0.997748  0.569409\n",
      "29  30  0.396953  0.997748  0.567949\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.902439  0.345794  0.500000\n",
      "1    2  0.867110  0.487850  0.624402\n",
      "2    3  0.842105  0.553271  0.667795\n",
      "3    4  0.814013  0.597196  0.688949\n",
      "4    5  0.790226  0.619626  0.694605\n",
      "5    6  0.776644  0.640187  0.701844\n",
      "6    7  0.766447  0.653271  0.705348\n",
      "7    8  0.756642  0.665421  0.708105\n",
      "8    9  0.744813  0.671028  0.705998\n",
      "9   10  0.735146  0.682243  0.707707\n",
      "10  11  0.729435  0.687850  0.708033\n",
      "11  12  0.719383  0.697196  0.708116\n",
      "12  13  0.714558  0.701869  0.708157\n",
      "13  14  0.705332  0.704673  0.705002\n",
      "14  15  0.701107  0.710280  0.705664\n",
      "15  16  0.693563  0.714953  0.704096\n",
      "16  17  0.687500  0.719626  0.703196\n",
      "17  18  0.682905  0.720561  0.701228\n",
      "18  19  0.678947  0.723364  0.700452\n",
      "19  20  0.675347  0.727103  0.700270\n",
      "20  21  0.672994  0.728972  0.699865\n",
      "21  22  0.670094  0.730841  0.699151\n",
      "22  23  0.669513  0.732710  0.699688\n",
      "23  24  0.666384  0.735514  0.699245\n",
      "24  25  0.664148  0.739252  0.699690\n",
      "25  26  0.661679  0.743925  0.700396\n",
      "26  27  0.656766  0.743925  0.697634\n",
      "27  28  0.654635  0.745794  0.697248\n",
      "28  29  0.652778  0.746729  0.696600\n",
      "29  30  0.648583  0.748598  0.695011\n",
      "     k       avg     count       MRR\n",
      "0    1  0.902439  0.345794  0.500000\n",
      "1    2  0.867110  0.487850  0.624402\n",
      "2    3  0.842105  0.553271  0.667795\n",
      "3    4  0.814013  0.597196  0.688949\n",
      "4    5  0.790226  0.619626  0.694605\n",
      "5    6  0.776644  0.640187  0.701844\n",
      "6    7  0.766447  0.653271  0.705348\n",
      "7    8  0.756642  0.665421  0.708105\n",
      "8    9  0.744813  0.671028  0.705998\n",
      "9   10  0.735146  0.682243  0.707707\n",
      "10  11  0.729435  0.687850  0.708033\n",
      "11  12  0.719383  0.697196  0.708116\n",
      "12  13  0.714558  0.701869  0.708157\n",
      "13  14  0.705332  0.704673  0.705002\n",
      "14  15  0.701107  0.710280  0.705664\n",
      "15  16  0.693563  0.714953  0.704096\n",
      "16  17  0.687500  0.719626  0.703196\n",
      "17  18  0.682905  0.720561  0.701228\n",
      "18  19  0.678947  0.723364  0.700452\n",
      "19  20  0.675347  0.727103  0.700270\n",
      "20  21  0.672994  0.728972  0.699865\n",
      "21  22  0.670094  0.730841  0.699151\n",
      "22  23  0.669513  0.732710  0.699688\n",
      "23  24  0.666384  0.735514  0.699245\n",
      "24  25  0.664148  0.739252  0.699690\n",
      "25  26  0.661679  0.743925  0.700396\n",
      "26  27  0.656766  0.743925  0.697634\n",
      "27  28  0.654635  0.745794  0.697248\n",
      "28  29  0.652778  0.746729  0.696600\n",
      "29  30  0.648583  0.748598  0.695011\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.946636  0.918919  0.932571\n",
      "1    2  0.788280  0.939189  0.857143\n",
      "2    3  0.715254  0.950450  0.816248\n",
      "3    4  0.671429  0.952703  0.787709\n",
      "4    5  0.635682  0.954955  0.763276\n",
      "5    6  0.618497  0.963964  0.753521\n",
      "6    7  0.599162  0.966216  0.739655\n",
      "7    8  0.579730  0.966216  0.724662\n",
      "8    9  0.570479  0.966216  0.717391\n",
      "9   10  0.561358  0.968468  0.710744\n",
      "10  11  0.549872  0.968468  0.701468\n",
      "11  12  0.537500  0.968468  0.691318\n",
      "12  13  0.531520  0.968468  0.686353\n",
      "13  14  0.526316  0.968468  0.681998\n",
      "14  15  0.522424  0.970721  0.679275\n",
      "15  16  0.513642  0.975225  0.672883\n",
      "16  17  0.507026  0.975225  0.667180\n",
      "17  18  0.502315  0.977477  0.663609\n",
      "18  19  0.495434  0.977477  0.657576\n",
      "19  20  0.489290  0.977477  0.652141\n",
      "20  21  0.485459  0.977477  0.648729\n",
      "21  22  0.482222  0.977477  0.645833\n",
      "22  23  0.475877  0.977477  0.640118\n",
      "23  24  0.469697  0.977477  0.634503\n",
      "24  25  0.467310  0.981982  0.633261\n",
      "25  26  0.463830  0.981982  0.630058\n",
      "26  27  0.460401  0.981982  0.626887\n",
      "27  28  0.457983  0.981982  0.624642\n",
      "28  29  0.454735  0.984234  0.622064\n",
      "29  30  0.451913  0.984234  0.619419\n",
      "     k       avg     count       MRR\n",
      "0    1  0.946636  0.918919  0.932571\n",
      "1    2  0.788280  0.939189  0.857143\n",
      "2    3  0.715254  0.950450  0.816248\n",
      "3    4  0.671429  0.952703  0.787709\n",
      "4    5  0.635682  0.954955  0.763276\n",
      "5    6  0.618497  0.963964  0.753521\n",
      "6    7  0.599162  0.966216  0.739655\n",
      "7    8  0.579730  0.966216  0.724662\n",
      "8    9  0.570479  0.966216  0.717391\n",
      "9   10  0.561358  0.968468  0.710744\n",
      "10  11  0.549872  0.968468  0.701468\n",
      "11  12  0.537500  0.968468  0.691318\n",
      "12  13  0.531520  0.968468  0.686353\n",
      "13  14  0.526316  0.968468  0.681998\n",
      "14  15  0.522424  0.970721  0.679275\n",
      "15  16  0.513642  0.975225  0.672883\n",
      "16  17  0.507026  0.975225  0.667180\n",
      "17  18  0.502315  0.977477  0.663609\n",
      "18  19  0.495434  0.977477  0.657576\n",
      "19  20  0.489290  0.977477  0.652141\n",
      "20  21  0.485459  0.977477  0.648729\n",
      "21  22  0.482222  0.977477  0.645833\n",
      "22  23  0.475877  0.977477  0.640118\n",
      "23  24  0.469697  0.977477  0.634503\n",
      "24  25  0.467310  0.981982  0.633261\n",
      "25  26  0.463830  0.981982  0.630058\n",
      "26  27  0.460401  0.981982  0.626887\n",
      "27  28  0.457983  0.981982  0.624642\n",
      "28  29  0.454735  0.984234  0.622064\n",
      "29  30  0.451913  0.984234  0.619419\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.910638  0.400000  0.555844\n",
      "1    2  0.838542  0.601869  0.700762\n",
      "2    3  0.804233  0.710280  0.754342\n",
      "3    4  0.776727  0.767290  0.771979\n",
      "4    5  0.747818  0.800935  0.773466\n",
      "5    6  0.723825  0.820561  0.769163\n",
      "6    7  0.698587  0.831776  0.759386\n",
      "7    8  0.683131  0.840187  0.753562\n",
      "8    9  0.674815  0.851402  0.752893\n",
      "9   10  0.657593  0.857944  0.744526\n",
      "10  11  0.644645  0.866355  0.739234\n",
      "11  12  0.636177  0.871028  0.735306\n",
      "12  13  0.630128  0.875701  0.732890\n",
      "13  14  0.620053  0.878505  0.726991\n",
      "14  15  0.611688  0.880374  0.721839\n",
      "15  16  0.604978  0.885981  0.718999\n",
      "16  17  0.597996  0.892523  0.716160\n",
      "17  18  0.592455  0.895327  0.713063\n",
      "18  19  0.587263  0.896262  0.709582\n",
      "19  20  0.581269  0.899065  0.706055\n",
      "20  21  0.575179  0.900935  0.702112\n",
      "21  22  0.569912  0.902804  0.698734\n",
      "22  23  0.566258  0.906542  0.697089\n",
      "23  24  0.565698  0.909346  0.697491\n",
      "24  25  0.560414  0.910280  0.693732\n",
      "25  26  0.554923  0.911215  0.689777\n",
      "26  27  0.550536  0.911215  0.686378\n",
      "27  28  0.548369  0.911215  0.684691\n",
      "28  29  0.545455  0.914019  0.683199\n",
      "29  30  0.540331  0.914019  0.679167\n",
      "     k       avg     count       MRR\n",
      "0    1  0.910638  0.400000  0.555844\n",
      "1    2  0.838542  0.601869  0.700762\n",
      "2    3  0.804233  0.710280  0.754342\n",
      "3    4  0.776727  0.767290  0.771979\n",
      "4    5  0.747818  0.800935  0.773466\n",
      "5    6  0.723825  0.820561  0.769163\n",
      "6    7  0.698587  0.831776  0.759386\n",
      "7    8  0.683131  0.840187  0.753562\n",
      "8    9  0.674815  0.851402  0.752893\n",
      "9   10  0.657593  0.857944  0.744526\n",
      "10  11  0.644645  0.866355  0.739234\n",
      "11  12  0.636177  0.871028  0.735306\n",
      "12  13  0.630128  0.875701  0.732890\n",
      "13  14  0.620053  0.878505  0.726991\n",
      "14  15  0.611688  0.880374  0.721839\n",
      "15  16  0.604978  0.885981  0.718999\n",
      "16  17  0.597996  0.892523  0.716160\n",
      "17  18  0.592455  0.895327  0.713063\n",
      "18  19  0.587263  0.896262  0.709582\n",
      "19  20  0.581269  0.899065  0.706055\n",
      "20  21  0.575179  0.900935  0.702112\n",
      "21  22  0.569912  0.902804  0.698734\n",
      "22  23  0.566258  0.906542  0.697089\n",
      "23  24  0.565698  0.909346  0.697491\n",
      "24  25  0.560414  0.910280  0.693732\n",
      "25  26  0.554923  0.911215  0.689777\n",
      "26  27  0.550536  0.911215  0.686378\n",
      "27  28  0.548369  0.911215  0.684691\n",
      "28  29  0.545455  0.914019  0.683199\n",
      "29  30  0.540331  0.914019  0.679167\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.750000  0.111111  0.193548\n",
      "1    2  0.833333  0.185185  0.303030\n",
      "2    3  0.750000  0.222222  0.342857\n",
      "3    4  0.700000  0.259259  0.378378\n",
      "4    5  0.700000  0.259259  0.378378\n",
      "5    6  0.727273  0.296296  0.421053\n",
      "6    7  0.666667  0.296296  0.410256\n",
      "7    8  0.666667  0.296296  0.410256\n",
      "8    9  0.600000  0.333333  0.428571\n",
      "9   10  0.600000  0.333333  0.428571\n",
      "10  11  0.588235  0.370370  0.454545\n",
      "11  12  0.550000  0.407407  0.468085\n",
      "12  13  0.500000  0.407407  0.448980\n",
      "13  14  0.478261  0.407407  0.440000\n",
      "14  15  0.478261  0.407407  0.440000\n",
      "15  16  0.440000  0.407407  0.423077\n",
      "16  17  0.440000  0.407407  0.423077\n",
      "17  18  0.440000  0.407407  0.423077\n",
      "18  19  0.444444  0.444444  0.444444\n",
      "19  20  0.428571  0.444444  0.436364\n",
      "20  21  0.413793  0.444444  0.428571\n",
      "21  22  0.400000  0.444444  0.421053\n",
      "22  23  0.393939  0.481481  0.433333\n",
      "23  24  0.393939  0.481481  0.433333\n",
      "24  25  0.371429  0.481481  0.419355\n",
      "25  26  0.368421  0.518519  0.430769\n",
      "26  27  0.368421  0.518519  0.430769\n",
      "27  28  0.375000  0.555556  0.447761\n",
      "28  29  0.375000  0.555556  0.447761\n",
      "29  30  0.375000  0.555556  0.447761\n",
      "     k       avg     count       MRR\n",
      "0    1  0.750000  0.111111  0.193548\n",
      "1    2  0.833333  0.185185  0.303030\n",
      "2    3  0.750000  0.222222  0.342857\n",
      "3    4  0.700000  0.259259  0.378378\n",
      "4    5  0.700000  0.259259  0.378378\n",
      "5    6  0.727273  0.296296  0.421053\n",
      "6    7  0.666667  0.296296  0.410256\n",
      "7    8  0.666667  0.296296  0.410256\n",
      "8    9  0.600000  0.333333  0.428571\n",
      "9   10  0.600000  0.333333  0.428571\n",
      "10  11  0.588235  0.370370  0.454545\n",
      "11  12  0.550000  0.407407  0.468085\n",
      "12  13  0.500000  0.407407  0.448980\n",
      "13  14  0.478261  0.407407  0.440000\n",
      "14  15  0.478261  0.407407  0.440000\n",
      "15  16  0.440000  0.407407  0.423077\n",
      "16  17  0.440000  0.407407  0.423077\n",
      "17  18  0.440000  0.407407  0.423077\n",
      "18  19  0.444444  0.444444  0.444444\n",
      "19  20  0.428571  0.444444  0.436364\n",
      "20  21  0.413793  0.444444  0.428571\n",
      "21  22  0.400000  0.444444  0.421053\n",
      "22  23  0.393939  0.481481  0.433333\n",
      "23  24  0.393939  0.481481  0.433333\n",
      "24  25  0.371429  0.481481  0.419355\n",
      "25  26  0.368421  0.518519  0.430769\n",
      "26  27  0.368421  0.518519  0.430769\n",
      "27  28  0.375000  0.555556  0.447761\n",
      "28  29  0.375000  0.555556  0.447761\n",
      "29  30  0.375000  0.555556  0.447761\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.326203  0.316062  0.321053\n",
      "1    2  0.254545  0.435233  0.321224\n",
      "2    3  0.235698  0.533679  0.326984\n",
      "3    4  0.217472  0.606218  0.320109\n",
      "4    5  0.209493  0.663212  0.318408\n",
      "5    6  0.191860  0.683938  0.299659\n",
      "6    7  0.184000  0.715026  0.292683\n",
      "7    8  0.171182  0.720207  0.276617\n",
      "8    9  0.165501  0.735751  0.270219\n",
      "9   10  0.159341  0.751295  0.262919\n",
      "10  11  0.153927  0.761658  0.256098\n",
      "11  12  0.149598  0.772021  0.250631\n",
      "12  13  0.145631  0.777202  0.245298\n",
      "13  14  0.140741  0.787565  0.238806\n",
      "14  15  0.141697  0.813472  0.241353\n",
      "15  16  0.139738  0.829016  0.239163\n",
      "16  17  0.136054  0.829016  0.233747\n",
      "17  18  0.133168  0.834197  0.229672\n",
      "18  19  0.130576  0.834197  0.225806\n",
      "19  20  0.129290  0.839378  0.224066\n",
      "20  21  0.128627  0.849741  0.223433\n",
      "21  22  0.126154  0.849741  0.219692\n",
      "22  23  0.124341  0.854922  0.217105\n",
      "23  24  0.123420  0.860104  0.215865\n",
      "24  25  0.122344  0.865285  0.214377\n",
      "25  26  0.121037  0.870466  0.212524\n",
      "26  27  0.120285  0.875648  0.211514\n",
      "27  28  0.120141  0.880829  0.211443\n",
      "28  29  0.118798  0.880829  0.209360\n",
      "29  30  0.117403  0.880829  0.207191\n",
      "     k       avg     count       MRR\n",
      "0    1  0.326203  0.316062  0.321053\n",
      "1    2  0.254545  0.435233  0.321224\n",
      "2    3  0.235698  0.533679  0.326984\n",
      "3    4  0.217472  0.606218  0.320109\n",
      "4    5  0.209493  0.663212  0.318408\n",
      "5    6  0.191860  0.683938  0.299659\n",
      "6    7  0.184000  0.715026  0.292683\n",
      "7    8  0.171182  0.720207  0.276617\n",
      "8    9  0.165501  0.735751  0.270219\n",
      "9   10  0.159341  0.751295  0.262919\n",
      "10  11  0.153927  0.761658  0.256098\n",
      "11  12  0.149598  0.772021  0.250631\n",
      "12  13  0.145631  0.777202  0.245298\n",
      "13  14  0.140741  0.787565  0.238806\n",
      "14  15  0.141697  0.813472  0.241353\n",
      "15  16  0.139738  0.829016  0.239163\n",
      "16  17  0.136054  0.829016  0.233747\n",
      "17  18  0.133168  0.834197  0.229672\n",
      "18  19  0.130576  0.834197  0.225806\n",
      "19  20  0.129290  0.839378  0.224066\n",
      "20  21  0.128627  0.849741  0.223433\n",
      "21  22  0.126154  0.849741  0.219692\n",
      "22  23  0.124341  0.854922  0.217105\n",
      "23  24  0.123420  0.860104  0.215865\n",
      "24  25  0.122344  0.865285  0.214377\n",
      "25  26  0.121037  0.870466  0.212524\n",
      "26  27  0.120285  0.875648  0.211514\n",
      "27  28  0.120141  0.880829  0.211443\n",
      "28  29  0.118798  0.880829  0.209360\n",
      "29  30  0.117403  0.880829  0.207191\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.678571  0.863636  0.760000\n",
      "1    2  0.540541  0.909091  0.677966\n",
      "2    3  0.420000  0.954545  0.583333\n",
      "3    4  0.362069  0.954545  0.525000\n",
      "4    5  0.318182  0.954545  0.477273\n",
      "5    6  0.300000  0.954545  0.456522\n",
      "6    7  0.280000  0.954545  0.432990\n",
      "7    8  0.265823  0.954545  0.415842\n",
      "8    9  0.250000  0.954545  0.396226\n",
      "9   10  0.238636  0.954545  0.381818\n",
      "10  11  0.235955  0.954545  0.378378\n",
      "11  12  0.225806  0.954545  0.365217\n",
      "12  13  0.210000  0.954545  0.344262\n",
      "13  14  0.207921  0.954545  0.341463\n",
      "14  15  0.201923  0.954545  0.333333\n",
      "15  16  0.200000  0.954545  0.330709\n",
      "16  17  0.192661  0.954545  0.320611\n",
      "17  18  0.187500  0.954545  0.313433\n",
      "18  19  0.184211  0.954545  0.308824\n",
      "19  20  0.181034  0.954545  0.304348\n",
      "20  21  0.179487  0.954545  0.302158\n",
      "21  22  0.176471  0.954545  0.297872\n",
      "22  23  0.170732  0.954545  0.289655\n",
      "23  24  0.169355  0.954545  0.287671\n",
      "24  25  0.168000  0.954545  0.285714\n",
      "25  26  0.165354  0.954545  0.281879\n",
      "26  27  0.162791  0.954545  0.278146\n",
      "27  28  0.162791  0.954545  0.278146\n",
      "28  29  0.160305  0.954545  0.274510\n",
      "29  30  0.156716  0.954545  0.269231\n",
      "     k       avg     count       MRR\n",
      "0    1  0.678571  0.863636  0.760000\n",
      "1    2  0.540541  0.909091  0.677966\n",
      "2    3  0.420000  0.954545  0.583333\n",
      "3    4  0.362069  0.954545  0.525000\n",
      "4    5  0.318182  0.954545  0.477273\n",
      "5    6  0.300000  0.954545  0.456522\n",
      "6    7  0.280000  0.954545  0.432990\n",
      "7    8  0.265823  0.954545  0.415842\n",
      "8    9  0.250000  0.954545  0.396226\n",
      "9   10  0.238636  0.954545  0.381818\n",
      "10  11  0.235955  0.954545  0.378378\n",
      "11  12  0.225806  0.954545  0.365217\n",
      "12  13  0.210000  0.954545  0.344262\n",
      "13  14  0.207921  0.954545  0.341463\n",
      "14  15  0.201923  0.954545  0.333333\n",
      "15  16  0.200000  0.954545  0.330709\n",
      "16  17  0.192661  0.954545  0.320611\n",
      "17  18  0.187500  0.954545  0.313433\n",
      "18  19  0.184211  0.954545  0.308824\n",
      "19  20  0.181034  0.954545  0.304348\n",
      "20  21  0.179487  0.954545  0.302158\n",
      "21  22  0.176471  0.954545  0.297872\n",
      "22  23  0.170732  0.954545  0.289655\n",
      "23  24  0.169355  0.954545  0.287671\n",
      "24  25  0.168000  0.954545  0.285714\n",
      "25  26  0.165354  0.954545  0.281879\n",
      "26  27  0.162791  0.954545  0.278146\n",
      "27  28  0.162791  0.954545  0.278146\n",
      "28  29  0.160305  0.954545  0.274510\n",
      "29  30  0.156716  0.954545  0.269231\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.750000  0.444444  0.558140\n",
      "1    2  0.636364  0.518519  0.571429\n",
      "2    3  0.608696  0.518519  0.560000\n",
      "3    4  0.600000  0.555556  0.576923\n",
      "4    5  0.576923  0.555556  0.566038\n",
      "5    6  0.600000  0.666667  0.631579\n",
      "6    7  0.606061  0.740741  0.666667\n",
      "7    8  0.583333  0.777778  0.666667\n",
      "8    9  0.567568  0.777778  0.656250\n",
      "9   10  0.538462  0.777778  0.636364\n",
      "10  11  0.538462  0.777778  0.636364\n",
      "11  12  0.550000  0.814815  0.656716\n",
      "12  13  0.550000  0.814815  0.656716\n",
      "13  14  0.523810  0.814815  0.637681\n",
      "14  15  0.523810  0.814815  0.637681\n",
      "15  16  0.488889  0.814815  0.611111\n",
      "16  17  0.458333  0.814815  0.586667\n",
      "17  18  0.440000  0.814815  0.571429\n",
      "18  19  0.431373  0.814815  0.564103\n",
      "19  20  0.431373  0.814815  0.564103\n",
      "20  21  0.423077  0.814815  0.556962\n",
      "21  22  0.407407  0.814815  0.543210\n",
      "22  23  0.407407  0.814815  0.543210\n",
      "23  24  0.418182  0.851852  0.560976\n",
      "24  25  0.410714  0.851852  0.554217\n",
      "25  26  0.389831  0.851852  0.534884\n",
      "26  27  0.389831  0.851852  0.534884\n",
      "27  28  0.383333  0.851852  0.528736\n",
      "28  29  0.383333  0.851852  0.528736\n",
      "29  30  0.383333  0.851852  0.528736\n",
      "     k       avg     count       MRR\n",
      "0    1  0.750000  0.444444  0.558140\n",
      "1    2  0.636364  0.518519  0.571429\n",
      "2    3  0.608696  0.518519  0.560000\n",
      "3    4  0.600000  0.555556  0.576923\n",
      "4    5  0.576923  0.555556  0.566038\n",
      "5    6  0.600000  0.666667  0.631579\n",
      "6    7  0.606061  0.740741  0.666667\n",
      "7    8  0.583333  0.777778  0.666667\n",
      "8    9  0.567568  0.777778  0.656250\n",
      "9   10  0.538462  0.777778  0.636364\n",
      "10  11  0.538462  0.777778  0.636364\n",
      "11  12  0.550000  0.814815  0.656716\n",
      "12  13  0.550000  0.814815  0.656716\n",
      "13  14  0.523810  0.814815  0.637681\n",
      "14  15  0.523810  0.814815  0.637681\n",
      "15  16  0.488889  0.814815  0.611111\n",
      "16  17  0.458333  0.814815  0.586667\n",
      "17  18  0.440000  0.814815  0.571429\n",
      "18  19  0.431373  0.814815  0.564103\n",
      "19  20  0.431373  0.814815  0.564103\n",
      "20  21  0.423077  0.814815  0.556962\n",
      "21  22  0.407407  0.814815  0.543210\n",
      "22  23  0.407407  0.814815  0.543210\n",
      "23  24  0.418182  0.851852  0.560976\n",
      "24  25  0.410714  0.851852  0.554217\n",
      "25  26  0.389831  0.851852  0.534884\n",
      "26  27  0.389831  0.851852  0.534884\n",
      "27  28  0.383333  0.851852  0.528736\n",
      "28  29  0.383333  0.851852  0.528736\n",
      "29  30  0.383333  0.851852  0.528736\n",
      "\n",
      "deepmatcher\n",
      "pretrained \t /lfs/1/sahaana/enrichment//ember/pretraining/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-pretrained-MLMBM25-1-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.333333  0.264249  0.294798\n",
      "1    2  0.269663  0.373057  0.313043\n",
      "2    3  0.249300  0.461140  0.323636\n",
      "3    4  0.226757  0.518135  0.315457\n",
      "4    5  0.212121  0.544041  0.305233\n",
      "5    6  0.203604  0.585492  0.302139\n",
      "6    7  0.191870  0.611399  0.292079\n",
      "7    8  0.189970  0.647668  0.293772\n",
      "8    9  0.179021  0.663212  0.281938\n",
      "9   10  0.172414  0.673575  0.274551\n",
      "10  11  0.164141  0.673575  0.263959\n",
      "11  12  0.159714  0.694301  0.259690\n",
      "12  13  0.154639  0.699482  0.253283\n",
      "13  14  0.150881  0.709845  0.248865\n",
      "14  15  0.148663  0.720207  0.246454\n",
      "15  16  0.148536  0.735751  0.247171\n",
      "16  17  0.145343  0.735751  0.242735\n",
      "17  18  0.143426  0.746114  0.240602\n",
      "18  19  0.140625  0.746114  0.236647\n",
      "19  20  0.139313  0.756477  0.235294\n",
      "20  21  0.135562  0.756477  0.229921\n",
      "21  22  0.132848  0.756477  0.226006\n",
      "22  23  0.131016  0.761658  0.223574\n",
      "23  24  0.129288  0.761658  0.221053\n",
      "24  25  0.127826  0.761658  0.218913\n",
      "25  26  0.127678  0.772021  0.219118\n",
      "26  27  0.126058  0.772021  0.216727\n",
      "27  28  0.126246  0.787565  0.217609\n",
      "28  29  0.124488  0.787565  0.214993\n",
      "29  30  0.123477  0.787565  0.213483\n",
      "     k       avg     count       MRR\n",
      "0    1  0.333333  0.264249  0.294798\n",
      "1    2  0.269663  0.373057  0.313043\n",
      "2    3  0.249300  0.461140  0.323636\n",
      "3    4  0.226757  0.518135  0.315457\n",
      "4    5  0.212121  0.544041  0.305233\n",
      "5    6  0.203604  0.585492  0.302139\n",
      "6    7  0.191870  0.611399  0.292079\n",
      "7    8  0.189970  0.647668  0.293772\n",
      "8    9  0.179021  0.663212  0.281938\n",
      "9   10  0.172414  0.673575  0.274551\n",
      "10  11  0.164141  0.673575  0.263959\n",
      "11  12  0.159714  0.694301  0.259690\n",
      "12  13  0.154639  0.699482  0.253283\n",
      "13  14  0.150881  0.709845  0.248865\n",
      "14  15  0.148663  0.720207  0.246454\n",
      "15  16  0.148536  0.735751  0.247171\n",
      "16  17  0.145343  0.735751  0.242735\n",
      "17  18  0.143426  0.746114  0.240602\n",
      "18  19  0.140625  0.746114  0.236647\n",
      "19  20  0.139313  0.756477  0.235294\n",
      "20  21  0.135562  0.756477  0.229921\n",
      "21  22  0.132848  0.756477  0.226006\n",
      "22  23  0.131016  0.761658  0.223574\n",
      "23  24  0.129288  0.761658  0.221053\n",
      "24  25  0.127826  0.761658  0.218913\n",
      "25  26  0.127678  0.772021  0.219118\n",
      "26  27  0.126058  0.772021  0.216727\n",
      "27  28  0.126246  0.787565  0.217609\n",
      "28  29  0.124488  0.787565  0.214993\n",
      "29  30  0.123477  0.787565  0.213483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    #if 'deepmatcher' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "    if 'json' in i and 'deepmatcher' not in i:\n",
    "        conf = load_config(i)\n",
    "        if conf['data'] == 'deepmatcher' and conf['arch'] == 'pretrained' and 'distilbert' not in conf['bert_path']:\n",
    "            config_knn = get_config_knn_dir(i)\n",
    "            print(conf['data'])\n",
    "            print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "            print(i)\n",
    "            files = get_sorted_files(config_knn)\n",
    "            for j in files:\n",
    "                if 'knn_results' in j:\n",
    "                    results = pd.read_pickle(j)\n",
    "                    print(results[['k', 'avg', 'count', 'MRR']])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-feeding",
   "metadata": {},
   "source": [
    "## Two Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "mineral-latex",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/abt_buy_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-5743-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.027778  0.004854  0.008264\n",
      "1    2  0.098592  0.033981  0.050542\n",
      "2    3  0.099010  0.048544  0.065147\n",
      "3    4  0.124031  0.077670  0.095522\n",
      "4    5  0.143836  0.101942  0.119318\n",
      "5    6  0.130682  0.111650  0.120419\n",
      "6    7  0.142132  0.135922  0.138958\n",
      "7    8  0.144928  0.145631  0.145278\n",
      "8    9  0.140271  0.150485  0.145199\n",
      "9   10  0.148936  0.169903  0.158730\n",
      "10  11  0.147410  0.179612  0.161926\n",
      "11  12  0.139623  0.179612  0.157113\n",
      "12  13  0.142857  0.194175  0.164609\n",
      "13  14  0.137457  0.194175  0.160966\n",
      "14  15  0.133333  0.194175  0.158103\n",
      "15  16  0.135484  0.203883  0.162791\n",
      "16  17  0.141975  0.223301  0.173585\n",
      "17  18  0.145349  0.242718  0.181818\n",
      "18  19  0.146067  0.252427  0.185053\n",
      "19  20  0.147541  0.262136  0.188811\n",
      "20  21  0.151436  0.281553  0.196944\n",
      "21  22  0.151134  0.291262  0.199005\n",
      "22  23  0.148780  0.296117  0.198052\n",
      "23  24  0.147971  0.300971  0.198400\n",
      "24  25  0.151376  0.320388  0.205607\n",
      "25  26  0.155702  0.344660  0.214502\n",
      "26  27  0.155508  0.349515  0.215247\n",
      "27  28  0.158562  0.364078  0.220913\n",
      "28  29  0.158436  0.373786  0.222543\n",
      "29  30  0.155556  0.373786  0.219686\n",
      "     k       avg     count       MRR\n",
      "0    1  0.027778  0.004854  0.008264\n",
      "1    2  0.098361  0.029126  0.044944\n",
      "2    3  0.109890  0.048544  0.067340\n",
      "3    4  0.111111  0.063107  0.080495\n",
      "4    5  0.120567  0.082524  0.097983\n",
      "5    6  0.136095  0.111650  0.122667\n",
      "6    7  0.133690  0.121359  0.127226\n",
      "7    8  0.132420  0.140777  0.136471\n",
      "8    9  0.143426  0.174757  0.157549\n",
      "9   10  0.144487  0.184466  0.162047\n",
      "10  11  0.145390  0.199029  0.168033\n",
      "11  12  0.152318  0.223301  0.181102\n",
      "12  13  0.150943  0.233010  0.183206\n",
      "13  14  0.153392  0.252427  0.190826\n",
      "14  15  0.150838  0.262136  0.191489\n",
      "15  16  0.152000  0.276699  0.196213\n",
      "16  17  0.154430  0.296117  0.202995\n",
      "17  18  0.148418  0.296117  0.197731\n",
      "18  19  0.149883  0.310680  0.202212\n",
      "19  20  0.148315  0.320388  0.202765\n",
      "20  21  0.151844  0.339806  0.209895\n",
      "21  22  0.148225  0.344660  0.207299\n",
      "22  23  0.150713  0.359223  0.212339\n",
      "23  24  0.148297  0.359223  0.209929\n",
      "24  25  0.146825  0.359223  0.208451\n",
      "25  26  0.150763  0.383495  0.216438\n",
      "26  27  0.149171  0.393204  0.216288\n",
      "27  28  0.151351  0.407767  0.220762\n",
      "28  29  0.151943  0.417476  0.222798\n",
      "29  30  0.152659  0.432039  0.225602\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/amazon_google_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-6874-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.300000  0.025641  0.047244\n",
      "1    2  0.258065  0.034188  0.060377\n",
      "2    3  0.279070  0.051282  0.086643\n",
      "3    4  0.250000  0.068376  0.107383\n",
      "4    5  0.234568  0.081197  0.120635\n",
      "5    6  0.215054  0.085470  0.122324\n",
      "6    7  0.235294  0.102564  0.142857\n",
      "7    8  0.242991  0.111111  0.152493\n",
      "8    9  0.226087  0.111111  0.148997\n",
      "9   10  0.219512  0.115385  0.151261\n",
      "10  11  0.220588  0.128205  0.162162\n",
      "11  12  0.218543  0.141026  0.171429\n",
      "12  13  0.221519  0.149573  0.178571\n",
      "13  14  0.222222  0.153846  0.181818\n",
      "14  15  0.218391  0.162393  0.186275\n",
      "15  16  0.216667  0.166667  0.188406\n",
      "16  17  0.213542  0.175214  0.192488\n",
      "17  18  0.205000  0.175214  0.188940\n",
      "18  19  0.207921  0.179487  0.192661\n",
      "19  20  0.205882  0.179487  0.191781\n",
      "20  21  0.202899  0.179487  0.190476\n",
      "21  22  0.210280  0.192308  0.200893\n",
      "22  23  0.210046  0.196581  0.203091\n",
      "23  24  0.207207  0.196581  0.201754\n",
      "24  25  0.207965  0.200855  0.204348\n",
      "25  26  0.209607  0.205128  0.207343\n",
      "26  27  0.206897  0.205128  0.206009\n",
      "27  28  0.205882  0.209402  0.207627\n",
      "28  29  0.203320  0.209402  0.206316\n",
      "29  30  0.201646  0.209402  0.205451\n",
      "     k       avg     count       MRR\n",
      "0    1  0.260870  0.025641  0.046693\n",
      "1    2  0.232558  0.042735  0.072202\n",
      "2    3  0.265625  0.072650  0.114094\n",
      "3    4  0.289157  0.102564  0.151420\n",
      "4    5  0.302083  0.123932  0.175758\n",
      "5    6  0.294118  0.149573  0.198300\n",
      "6    7  0.268657  0.153846  0.195652\n",
      "7    8  0.265734  0.162393  0.201592\n",
      "8    9  0.256579  0.166667  0.202073\n",
      "9   10  0.245283  0.166667  0.198473\n",
      "10  11  0.245399  0.170940  0.201511\n",
      "11  12  0.241379  0.179487  0.205882\n",
      "12  13  0.248649  0.196581  0.219570\n",
      "13  14  0.244792  0.200855  0.220657\n",
      "14  15  0.247475  0.209402  0.226852\n",
      "15  16  0.243781  0.209402  0.225287\n",
      "16  17  0.244019  0.217949  0.230248\n",
      "17  18  0.245283  0.222222  0.233184\n",
      "18  19  0.248826  0.226496  0.237136\n",
      "19  20  0.250000  0.230769  0.240000\n",
      "20  21  0.251142  0.235043  0.242826\n",
      "21  22  0.246637  0.235043  0.240700\n",
      "22  23  0.247826  0.243590  0.245690\n",
      "23  24  0.245690  0.243590  0.244635\n",
      "24  25  0.246862  0.252137  0.249471\n",
      "25  26  0.246914  0.256410  0.251572\n",
      "26  27  0.241935  0.256410  0.248963\n",
      "27  28  0.245059  0.264957  0.254620\n",
      "28  29  0.242188  0.264957  0.253061\n",
      "29  30  0.246154  0.273504  0.259109\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/beer_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-uncased-masked-ALL-BM25-double-triplet-268-1.json\n",
      "     k  avg     count       MRR\n",
      "0    1  0.0  0.000000  0.000000\n",
      "1    2  0.0  0.000000  0.000000\n",
      "2    3  0.0  0.000000  0.000000\n",
      "3    4  0.0  0.000000  0.000000\n",
      "4    5  0.0  0.000000  0.000000\n",
      "5    6  0.0  0.000000  0.000000\n",
      "6    7  0.0  0.000000  0.000000\n",
      "7    8  1.0  0.071429  0.133333\n",
      "8    9  1.0  0.071429  0.133333\n",
      "9   10  1.0  0.071429  0.133333\n",
      "10  11  1.0  0.071429  0.133333\n",
      "11  12  1.0  0.071429  0.133333\n",
      "12  13  1.0  0.071429  0.133333\n",
      "13  14  1.0  0.071429  0.133333\n",
      "14  15  1.0  0.071429  0.133333\n",
      "15  16  1.0  0.071429  0.133333\n",
      "16  17  1.0  0.071429  0.133333\n",
      "17  18  1.0  0.071429  0.133333\n",
      "18  19  1.0  0.071429  0.133333\n",
      "19  20  1.0  0.071429  0.133333\n",
      "20  21  1.0  0.071429  0.133333\n",
      "21  22  1.0  0.071429  0.133333\n",
      "22  23  1.0  0.071429  0.133333\n",
      "23  24  1.0  0.071429  0.133333\n",
      "24  25  0.5  0.071429  0.125000\n",
      "25  26  0.5  0.071429  0.125000\n",
      "26  27  0.5  0.071429  0.125000\n",
      "27  28  0.5  0.071429  0.125000\n",
      "28  29  0.5  0.071429  0.125000\n",
      "29  30  0.5  0.071429  0.125000\n",
      "     k  avg     count    MRR\n",
      "0    1  0.0  0.000000  0.000\n",
      "1    2  0.0  0.000000  0.000\n",
      "2    3  0.0  0.000000  0.000\n",
      "3    4  0.0  0.000000  0.000\n",
      "4    5  0.0  0.000000  0.000\n",
      "5    6  0.0  0.000000  0.000\n",
      "6    7  0.0  0.000000  0.000\n",
      "7    8  0.0  0.000000  0.000\n",
      "8    9  0.0  0.000000  0.000\n",
      "9   10  0.0  0.000000  0.000\n",
      "10  11  0.0  0.000000  0.000\n",
      "11  12  0.0  0.000000  0.000\n",
      "12  13  0.0  0.000000  0.000\n",
      "13  14  0.0  0.000000  0.000\n",
      "14  15  0.0  0.000000  0.000\n",
      "15  16  0.0  0.000000  0.000\n",
      "16  17  0.0  0.000000  0.000\n",
      "17  18  0.0  0.000000  0.000\n",
      "18  19  0.0  0.000000  0.000\n",
      "19  20  0.0  0.000000  0.000\n",
      "20  21  0.0  0.000000  0.000\n",
      "21  22  0.0  0.000000  0.000\n",
      "22  23  0.0  0.000000  0.000\n",
      "23  24  0.0  0.000000  0.000\n",
      "24  25  0.0  0.000000  0.000\n",
      "25  26  0.0  0.000000  0.000\n",
      "26  27  0.0  0.000000  0.000\n",
      "27  28  0.0  0.000000  0.000\n",
      "28  29  0.5  0.071429  0.125\n",
      "29  30  0.5  0.071429  0.125\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/company_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//company_exp_data-uncased-masked-ALL-BM25-double-triplet-67596-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.973180  0.045035  0.086087\n",
      "1    2  0.977556  0.069504  0.129780\n",
      "2    3  0.975258  0.083865  0.154449\n",
      "3    4  0.970332  0.098582  0.178980\n",
      "4    5  0.967033  0.109220  0.196272\n",
      "5    6  0.963016  0.120035  0.213464\n",
      "6    7  0.964380  0.129610  0.228509\n",
      "7    8  0.962779  0.137589  0.240769\n",
      "8    9  0.963270  0.144149  0.250771\n",
      "9   10  0.960044  0.153369  0.264486\n",
      "10  11  0.957717  0.160638  0.275129\n",
      "11  12  0.953676  0.167908  0.285542\n",
      "12  13  0.952611  0.174645  0.295175\n",
      "13  14  0.948196  0.181738  0.305014\n",
      "14  15  0.946237  0.187234  0.312611\n",
      "15  16  0.943429  0.192199  0.319340\n",
      "16  17  0.941575  0.197163  0.326052\n",
      "17  18  0.940348  0.201241  0.331532\n",
      "18  19  0.938003  0.206560  0.338564\n",
      "19  20  0.935178  0.209752  0.342650\n",
      "20  21  0.933126  0.212766  0.346520\n",
      "21  22  0.932670  0.216135  0.350943\n",
      "22  23  0.931373  0.218972  0.354579\n",
      "23  24  0.929577  0.222340  0.358850\n",
      "24  25  0.929557  0.226950  0.364828\n",
      "25  26  0.930249  0.231738  0.371043\n",
      "26  27  0.928123  0.235816  0.376078\n",
      "27  28  0.927336  0.237589  0.378264\n",
      "28  29  0.928230  0.240780  0.382374\n",
      "29  30  0.927946  0.244326  0.386807\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.945946  0.315315  0.472973\n",
      "1    2  0.913242  0.450450  0.603318\n",
      "2    3  0.893130  0.527027  0.662890\n",
      "3    4  0.884488  0.603604  0.717537\n",
      "4    5  0.875740  0.666667  0.757033\n",
      "5    6  0.857143  0.689189  0.764045\n",
      "6    7  0.850543  0.704955  0.770936\n",
      "7    8  0.846354  0.731982  0.785024\n",
      "8    9  0.835000  0.752252  0.791469\n",
      "9   10  0.832924  0.763514  0.796710\n",
      "10  11  0.832524  0.772523  0.801402\n",
      "11  12  0.832936  0.786036  0.808806\n",
      "12  13  0.826698  0.795045  0.810563\n",
      "13  14  0.821918  0.810811  0.816327\n",
      "14  15  0.821267  0.817568  0.819413\n",
      "15  16  0.815730  0.817568  0.816648\n",
      "16  17  0.809735  0.824324  0.816964\n",
      "17  18  0.805677  0.831081  0.818182\n",
      "18  19  0.807775  0.842342  0.824697\n",
      "19  20  0.799154  0.851351  0.824427\n",
      "20  21  0.794606  0.862613  0.827214\n",
      "21  22  0.791322  0.862613  0.825431\n",
      "22  23  0.784836  0.862613  0.821888\n",
      "23  24  0.780488  0.864865  0.820513\n",
      "24  25  0.778226  0.869369  0.821277\n",
      "25  26  0.778672  0.871622  0.822529\n",
      "26  27  0.771825  0.876126  0.820675\n",
      "27  28  0.765166  0.880631  0.818848\n",
      "28  29  0.763107  0.885135  0.819604\n",
      "29  30  0.761079  0.889640  0.820353\n",
      "     k       avg     count       MRR\n",
      "0    1  0.907609  0.376126  0.531847\n",
      "1    2  0.896296  0.545045  0.677871\n",
      "2    3  0.885993  0.612613  0.724368\n",
      "3    4  0.871345  0.671171  0.758270\n",
      "4    5  0.866485  0.716216  0.784217\n",
      "5    6  0.854220  0.752252  0.800000\n",
      "6    7  0.845209  0.774775  0.808461\n",
      "7    8  0.836830  0.808559  0.822451\n",
      "8    9  0.826879  0.817568  0.822197\n",
      "9   10  0.824444  0.835586  0.829978\n",
      "10  11  0.817787  0.849099  0.833149\n",
      "11  12  0.808017  0.862613  0.834423\n",
      "12  13  0.800830  0.869369  0.833693\n",
      "13  14  0.793878  0.876126  0.832976\n",
      "14  15  0.791165  0.887387  0.836518\n",
      "15  16  0.786693  0.905405  0.841885\n",
      "16  17  0.779923  0.909910  0.839917\n",
      "17  18  0.777351  0.912162  0.839378\n",
      "18  19  0.767925  0.916667  0.835729\n",
      "19  20  0.763060  0.921171  0.834694\n",
      "20  21  0.762523  0.925676  0.836216\n",
      "21  22  0.755963  0.927928  0.833165\n",
      "22  23  0.750455  0.927928  0.829809\n",
      "23  24  0.748188  0.930180  0.829317\n",
      "24  25  0.739750  0.934685  0.825871\n",
      "25  26  0.739750  0.934685  0.825871\n",
      "26  27  0.734513  0.934685  0.822597\n",
      "27  28  0.729350  0.934685  0.819348\n",
      "28  29  0.729825  0.936937  0.820513\n",
      "29  30  0.728546  0.936937  0.819704\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.695652  0.014953  0.029277\n",
      "1    2  0.750000  0.025234  0.048825\n",
      "2    3  0.734694  0.033645  0.064343\n",
      "3    4  0.723077  0.043925  0.082819\n",
      "4    5  0.736842  0.052336  0.097731\n",
      "5    6  0.753086  0.057009  0.105995\n",
      "6    7  0.750000  0.064486  0.118761\n",
      "7    8  0.745455  0.076636  0.138983\n",
      "8    9  0.754098  0.085981  0.154362\n",
      "9   10  0.763359  0.093458  0.166528\n",
      "10  11  0.765957  0.100935  0.178365\n",
      "11  12  0.760000  0.106542  0.186885\n",
      "12  13  0.759494  0.112150  0.195440\n",
      "13  14  0.750000  0.117757  0.203554\n",
      "14  15  0.732240  0.125234  0.213887\n",
      "15  16  0.737968  0.128972  0.219570\n",
      "16  17  0.737113  0.133645  0.226266\n",
      "17  18  0.742574  0.140187  0.235849\n",
      "18  19  0.743842  0.141121  0.237235\n",
      "19  20  0.750000  0.145794  0.244131\n",
      "20  21  0.746479  0.148598  0.247857\n",
      "21  22  0.751152  0.152336  0.253302\n",
      "22  23  0.755556  0.158879  0.262548\n",
      "23  24  0.761905  0.164486  0.270561\n",
      "24  25  0.761702  0.167290  0.274330\n",
      "25  26  0.758333  0.170093  0.277863\n",
      "26  27  0.761317  0.172897  0.281797\n",
      "27  28  0.764228  0.175701  0.285714\n",
      "28  29  0.764706  0.182243  0.294340\n",
      "29  30  0.765385  0.185981  0.299248\n",
      "     k       avg     count       MRR\n",
      "0    1  0.666667  0.007477  0.014787\n",
      "1    2  0.695652  0.014953  0.029277\n",
      "2    3  0.625000  0.018692  0.036298\n",
      "3    4  0.627907  0.025234  0.048518\n",
      "4    5  0.641509  0.031776  0.060552\n",
      "5    6  0.671875  0.040187  0.075838\n",
      "6    7  0.694444  0.046729  0.087566\n",
      "7    8  0.719512  0.055140  0.102431\n",
      "8    9  0.712644  0.057944  0.107174\n",
      "9   10  0.723404  0.063551  0.116838\n",
      "10  11  0.718447  0.069159  0.126172\n",
      "11  12  0.726415  0.071963  0.130952\n",
      "12  13  0.722222  0.072897  0.132428\n",
      "13  14  0.724138  0.078505  0.141653\n",
      "14  15  0.737705  0.084112  0.151007\n",
      "15  16  0.750000  0.089720  0.160267\n",
      "16  17  0.746269  0.093458  0.166113\n",
      "17  18  0.748201  0.097196  0.172043\n",
      "18  19  0.748299  0.102804  0.180772\n",
      "19  20  0.751678  0.104673  0.183757\n",
      "20  21  0.732484  0.107477  0.187449\n",
      "21  22  0.731250  0.109346  0.190244\n",
      "22  23  0.730539  0.114019  0.197251\n",
      "23  24  0.735294  0.116822  0.201613\n",
      "24  25  0.740113  0.122430  0.210104\n",
      "25  26  0.737430  0.123364  0.211369\n",
      "26  27  0.743169  0.127103  0.217079\n",
      "27  28  0.750000  0.131776  0.224165\n",
      "28  29  0.750000  0.134579  0.228209\n",
      "29  30  0.753846  0.137383  0.232411\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.925620  0.504505  0.653061\n",
      "1    2  0.879257  0.639640  0.740548\n",
      "2    3  0.869919  0.722973  0.789668\n",
      "3    4  0.860104  0.747748  0.800000\n",
      "4    5  0.843521  0.777027  0.808910\n",
      "5    6  0.825882  0.790541  0.807825\n",
      "6    7  0.819005  0.815315  0.817156\n",
      "7    8  0.812362  0.828829  0.820513\n",
      "8    9  0.808190  0.844595  0.825991\n",
      "9   10  0.805497  0.858108  0.830971\n",
      "10  11  0.804167  0.869369  0.835498\n",
      "11  12  0.793522  0.882883  0.835821\n",
      "12  13  0.786853  0.889640  0.835095\n",
      "13  14  0.776471  0.891892  0.830189\n",
      "14  15  0.766859  0.896396  0.826584\n",
      "15  16  0.754253  0.898649  0.820144\n",
      "16  17  0.749077  0.914414  0.823529\n",
      "17  18  0.746324  0.914414  0.821862\n",
      "18  19  0.744526  0.918919  0.822581\n",
      "19  20  0.738739  0.923423  0.820821\n",
      "20  21  0.733096  0.927928  0.819085\n",
      "21  22  0.728873  0.932432  0.818182\n",
      "22  23  0.727273  0.936937  0.818898\n",
      "23  24  0.724913  0.943694  0.819961\n",
      "24  25  0.723368  0.948198  0.820663\n",
      "25  26  0.722317  0.954955  0.822502\n",
      "26  27  0.717428  0.954955  0.819324\n",
      "27  28  0.717905  0.957207  0.820463\n",
      "28  29  0.711893  0.957207  0.816523\n",
      "29  30  0.708819  0.959459  0.815311\n",
      "     k       avg     count       MRR\n",
      "0    1  0.915000  0.412162  0.568323\n",
      "1    2  0.888087  0.554054  0.682386\n",
      "2    3  0.864865  0.648649  0.741313\n",
      "3    4  0.859504  0.702703  0.773234\n",
      "4    5  0.848718  0.745495  0.793765\n",
      "5    6  0.839024  0.774775  0.805621\n",
      "6    7  0.823666  0.799550  0.811429\n",
      "7    8  0.817156  0.815315  0.816234\n",
      "8    9  0.811530  0.824324  0.817877\n",
      "9   10  0.806100  0.833333  0.819491\n",
      "10  11  0.800000  0.846847  0.822757\n",
      "11  12  0.801688  0.855856  0.827887\n",
      "12  13  0.797101  0.867117  0.830636\n",
      "13  14  0.794297  0.878378  0.834225\n",
      "14  15  0.783133  0.878378  0.828025\n",
      "15  16  0.774257  0.880631  0.824025\n",
      "16  17  0.770428  0.891892  0.826722\n",
      "17  18  0.762452  0.896396  0.824017\n",
      "18  19  0.757576  0.900901  0.823045\n",
      "19  20  0.749533  0.903153  0.819203\n",
      "20  21  0.742173  0.907658  0.816616\n",
      "21  22  0.741758  0.912162  0.818182\n",
      "22  23  0.735986  0.916667  0.816449\n",
      "23  24  0.733453  0.923423  0.817547\n",
      "24  25  0.730973  0.930180  0.818632\n",
      "25  26  0.725044  0.932432  0.815764\n",
      "26  27  0.723183  0.941441  0.818004\n",
      "27  28  0.715753  0.941441  0.813230\n",
      "28  29  0.713311  0.941441  0.811650\n",
      "29  30  0.710169  0.943694  0.810445\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.875000  0.013084  0.025783\n",
      "1    2  0.777778  0.019626  0.038286\n",
      "2    3  0.692308  0.025234  0.048693\n",
      "3    4  0.740000  0.034579  0.066071\n",
      "4    5  0.754098  0.042991  0.081344\n",
      "5    6  0.757143  0.049533  0.092982\n",
      "6    7  0.753086  0.057009  0.105995\n",
      "7    8  0.770115  0.062617  0.115817\n",
      "8    9  0.768421  0.068224  0.125322\n",
      "9   10  0.778846  0.075701  0.137990\n",
      "10  11  0.778761  0.082243  0.148774\n",
      "11  12  0.786325  0.085981  0.155013\n",
      "12  13  0.796748  0.091589  0.164292\n",
      "13  14  0.803150  0.095327  0.170426\n",
      "14  15  0.810606  0.100000  0.178037\n",
      "15  16  0.808824  0.102804  0.182421\n",
      "16  17  0.802817  0.106542  0.188119\n",
      "17  18  0.801370  0.109346  0.192434\n",
      "18  19  0.797468  0.117757  0.205212\n",
      "19  20  0.796296  0.120561  0.209416\n",
      "20  21  0.798817  0.126168  0.217918\n",
      "21  22  0.786127  0.127103  0.218825\n",
      "22  23  0.790960  0.130841  0.224539\n",
      "23  24  0.794444  0.133645  0.228800\n",
      "24  25  0.796703  0.135514  0.231629\n",
      "25  26  0.803191  0.141121  0.240064\n",
      "26  27  0.795918  0.145794  0.246445\n",
      "27  28  0.788177  0.149533  0.251375\n",
      "28  29  0.792271  0.153271  0.256852\n",
      "29  30  0.792453  0.157009  0.262090\n",
      "     k       avg     count       MRR\n",
      "0    1  0.833333  0.004673  0.009294\n",
      "1    2  0.888889  0.014953  0.029412\n",
      "2    3  0.827586  0.022430  0.043676\n",
      "3    4  0.828571  0.027103  0.052489\n",
      "4    5  0.813953  0.032710  0.062893\n",
      "5    6  0.843137  0.040187  0.076717\n",
      "6    7  0.807018  0.042991  0.081633\n",
      "7    8  0.815385  0.049533  0.093392\n",
      "8    9  0.802817  0.053271  0.099912\n",
      "9   10  0.787500  0.058879  0.109565\n",
      "10  11  0.795181  0.061682  0.114484\n",
      "11  12  0.786517  0.065421  0.120794\n",
      "12  13  0.776596  0.068224  0.125430\n",
      "13  14  0.765306  0.070093  0.128425\n",
      "14  15  0.774510  0.073832  0.134812\n",
      "15  16  0.770642  0.078505  0.142494\n",
      "16  17  0.771930  0.082243  0.148649\n",
      "17  18  0.776860  0.087850  0.157851\n",
      "18  19  0.785714  0.092523  0.165552\n",
      "19  20  0.792308  0.096262  0.171667\n",
      "20  21  0.779412  0.099065  0.175788\n",
      "21  22  0.784173  0.101869  0.180314\n",
      "22  23  0.780142  0.102804  0.181668\n",
      "23  24  0.775510  0.106542  0.187346\n",
      "24  25  0.769737  0.109346  0.191489\n",
      "25  26  0.778481  0.114953  0.200326\n",
      "26  27  0.782609  0.117757  0.204712\n",
      "27  28  0.777108  0.120561  0.208738\n",
      "28  29  0.773256  0.124299  0.214171\n",
      "29  30  0.775862  0.126168  0.217042\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1.json\n",
      "     k  avg  count  MRR\n",
      "0    1  0.0    0.0  0.0\n",
      "1    2  0.0    0.0  0.0\n",
      "2    3  0.0    0.0  0.0\n",
      "3    4  0.0    0.0  0.0\n",
      "4    5  0.0    0.0  0.0\n",
      "5    6  0.0    0.0  0.0\n",
      "6    7  0.0    0.0  0.0\n",
      "7    8  0.0    0.0  0.0\n",
      "8    9  0.0    0.0  0.0\n",
      "9   10  0.0    0.0  0.0\n",
      "10  11  0.0    0.0  0.0\n",
      "11  12  0.0    0.0  0.0\n",
      "12  13  0.0    0.0  0.0\n",
      "13  14  0.0    0.0  0.0\n",
      "14  15  0.0    0.0  0.0\n",
      "15  16  0.0    0.0  0.0\n",
      "16  17  0.0    0.0  0.0\n",
      "17  18  0.0    0.0  0.0\n",
      "18  19  0.0    0.0  0.0\n",
      "19  20  0.0    0.0  0.0\n",
      "20  21  0.0    0.0  0.0\n",
      "21  22  0.0    0.0  0.0\n",
      "22  23  0.0    0.0  0.0\n",
      "23  24  0.0    0.0  0.0\n",
      "24  25  0.0    0.0  0.0\n",
      "25  26  0.0    0.0  0.0\n",
      "26  27  0.0    0.0  0.0\n",
      "27  28  0.0    0.0  0.0\n",
      "28  29  0.0    0.0  0.0\n",
      "29  30  0.0    0.0  0.0\n",
      "     k  avg     count       MRR\n",
      "0    1  0.0  0.000000  0.000000\n",
      "1    2  0.0  0.000000  0.000000\n",
      "2    3  0.0  0.000000  0.000000\n",
      "3    4  0.0  0.000000  0.000000\n",
      "4    5  0.0  0.000000  0.000000\n",
      "5    6  0.0  0.000000  0.000000\n",
      "6    7  0.0  0.000000  0.000000\n",
      "7    8  0.0  0.000000  0.000000\n",
      "8    9  0.0  0.000000  0.000000\n",
      "9   10  0.0  0.000000  0.000000\n",
      "10  11  0.0  0.000000  0.000000\n",
      "11  12  0.0  0.000000  0.000000\n",
      "12  13  0.0  0.000000  0.000000\n",
      "13  14  0.0  0.000000  0.000000\n",
      "14  15  0.0  0.000000  0.000000\n",
      "15  16  0.0  0.000000  0.000000\n",
      "16  17  0.0  0.000000  0.000000\n",
      "17  18  0.0  0.000000  0.000000\n",
      "18  19  0.0  0.000000  0.000000\n",
      "19  20  0.0  0.000000  0.000000\n",
      "20  21  0.0  0.000000  0.000000\n",
      "21  22  0.0  0.000000  0.000000\n",
      "22  23  0.0  0.000000  0.000000\n",
      "23  24  0.0  0.000000  0.000000\n",
      "24  25  0.0  0.000000  0.000000\n",
      "25  26  0.0  0.000000  0.000000\n",
      "26  27  1.0  0.037037  0.071429\n",
      "27  28  1.0  0.037037  0.071429\n",
      "28  29  1.0  0.074074  0.137931\n",
      "29  30  1.0  0.074074  0.137931\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.000000  0.000000  0.000000\n",
      "1    2  0.000000  0.000000  0.000000\n",
      "2    3  0.000000  0.000000  0.000000\n",
      "3    4  0.000000  0.000000  0.000000\n",
      "4    5  0.093750  0.015544  0.026667\n",
      "5    6  0.083333  0.015544  0.026201\n",
      "6    7  0.071429  0.015544  0.025532\n",
      "7    8  0.108696  0.025907  0.041841\n",
      "8    9  0.137255  0.036269  0.057377\n",
      "9   10  0.129630  0.036269  0.056680\n",
      "10  11  0.140351  0.041451  0.064000\n",
      "11  12  0.138462  0.046632  0.069767\n",
      "12  13  0.136364  0.046632  0.069498\n",
      "13  14  0.138889  0.051813  0.075472\n",
      "14  15  0.136986  0.051813  0.075188\n",
      "15  16  0.144737  0.056995  0.081784\n",
      "16  17  0.151899  0.062176  0.088235\n",
      "17  18  0.146341  0.062176  0.087273\n",
      "18  19  0.139535  0.062176  0.086022\n",
      "19  20  0.129032  0.062176  0.083916\n",
      "20  21  0.125000  0.062176  0.083045\n",
      "21  22  0.122449  0.062176  0.082474\n",
      "22  23  0.130000  0.067358  0.088737\n",
      "23  24  0.126214  0.067358  0.087838\n",
      "24  25  0.123810  0.067358  0.087248\n",
      "25  26  0.122642  0.067358  0.086957\n",
      "26  27  0.129630  0.072539  0.093023\n",
      "27  28  0.128440  0.072539  0.092715\n",
      "28  29  0.125000  0.072539  0.091803\n",
      "29  30  0.130435  0.077720  0.097403\n",
      "     k       avg     count       MRR\n",
      "0    1  0.166667  0.010363  0.019512\n",
      "1    2  0.142857  0.010363  0.019324\n",
      "2    3  0.137931  0.020725  0.036036\n",
      "3    4  0.139535  0.031088  0.050847\n",
      "4    5  0.117647  0.031088  0.049180\n",
      "5    6  0.107143  0.031088  0.048193\n",
      "6    7  0.101695  0.031088  0.047619\n",
      "7    8  0.114754  0.036269  0.055118\n",
      "8    9  0.111111  0.036269  0.054688\n",
      "9   10  0.114286  0.041451  0.060837\n",
      "10  11  0.108108  0.041451  0.059925\n",
      "11  12  0.097561  0.041451  0.058182\n",
      "12  13  0.095238  0.041451  0.057762\n",
      "13  14  0.100000  0.046632  0.063604\n",
      "14  15  0.092784  0.046632  0.062069\n",
      "15  16  0.084112  0.046632  0.060000\n",
      "16  17  0.089286  0.051813  0.065574\n",
      "17  18  0.086957  0.051813  0.064935\n",
      "18  19  0.099174  0.062176  0.076433\n",
      "19  20  0.112000  0.072539  0.088050\n",
      "20  21  0.106870  0.072539  0.086420\n",
      "21  22  0.116788  0.082902  0.096970\n",
      "22  23  0.115108  0.082902  0.096386\n",
      "23  24  0.111888  0.082902  0.095238\n",
      "24  25  0.115646  0.088083  0.100000\n",
      "25  26  0.117647  0.093264  0.104046\n",
      "26  27  0.115385  0.093264  0.103152\n",
      "27  28  0.114650  0.093264  0.102857\n",
      "28  29  0.118750  0.098446  0.107649\n",
      "29  30  0.116564  0.098446  0.106742\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-567-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.000000  0.000000  0.000000\n",
      "1    2  0.000000  0.000000  0.000000\n",
      "2    3  0.500000  0.045455  0.083333\n",
      "3    4  0.333333  0.045455  0.080000\n",
      "4    5  0.166667  0.045455  0.071429\n",
      "5    6  0.166667  0.045455  0.071429\n",
      "6    7  0.166667  0.045455  0.071429\n",
      "7    8  0.125000  0.045455  0.066667\n",
      "8    9  0.125000  0.045455  0.066667\n",
      "9   10  0.111111  0.045455  0.064516\n",
      "10  11  0.111111  0.045455  0.064516\n",
      "11  12  0.090909  0.045455  0.060606\n",
      "12  13  0.083333  0.045455  0.058824\n",
      "13  14  0.083333  0.045455  0.058824\n",
      "14  15  0.083333  0.045455  0.058824\n",
      "15  16  0.153846  0.090909  0.114286\n",
      "16  17  0.214286  0.136364  0.166667\n",
      "17  18  0.214286  0.136364  0.166667\n",
      "18  19  0.266667  0.181818  0.216216\n",
      "19  20  0.250000  0.181818  0.210526\n",
      "20  21  0.277778  0.227273  0.250000\n",
      "21  22  0.263158  0.227273  0.243902\n",
      "22  23  0.238095  0.227273  0.232558\n",
      "23  24  0.238095  0.227273  0.232558\n",
      "24  25  0.217391  0.227273  0.222222\n",
      "25  26  0.217391  0.227273  0.222222\n",
      "26  27  0.208333  0.227273  0.217391\n",
      "27  28  0.233333  0.318182  0.269231\n",
      "28  29  0.225806  0.318182  0.264151\n",
      "29  30  0.225806  0.318182  0.264151\n",
      "     k       avg     count       MRR\n",
      "0    1  0.000000  0.000000  0.000000\n",
      "1    2  0.000000  0.000000  0.000000\n",
      "2    3  0.000000  0.000000  0.000000\n",
      "3    4  0.000000  0.000000  0.000000\n",
      "4    5  0.125000  0.045455  0.066667\n",
      "5    6  0.111111  0.045455  0.064516\n",
      "6    7  0.090909  0.045455  0.060606\n",
      "7    8  0.166667  0.090909  0.117647\n",
      "8    9  0.142857  0.090909  0.111111\n",
      "9   10  0.133333  0.090909  0.108108\n",
      "10  11  0.176471  0.136364  0.153846\n",
      "11  12  0.166667  0.136364  0.150000\n",
      "12  13  0.157895  0.136364  0.146341\n",
      "13  14  0.150000  0.136364  0.142857\n",
      "14  15  0.150000  0.136364  0.142857\n",
      "15  16  0.150000  0.136364  0.142857\n",
      "16  17  0.142857  0.136364  0.139535\n",
      "17  18  0.136364  0.136364  0.136364\n",
      "18  19  0.136364  0.136364  0.136364\n",
      "19  20  0.136364  0.136364  0.136364\n",
      "20  21  0.166667  0.181818  0.173913\n",
      "21  22  0.160000  0.181818  0.170213\n",
      "22  23  0.160000  0.181818  0.170213\n",
      "23  24  0.153846  0.181818  0.166667\n",
      "24  25  0.153846  0.181818  0.166667\n",
      "25  26  0.185185  0.227273  0.204082\n",
      "26  27  0.178571  0.227273  0.200000\n",
      "27  28  0.172414  0.227273  0.196078\n",
      "28  29  0.172414  0.227273  0.196078\n",
      "29  30  0.172414  0.227273  0.196078\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1.json\n",
      "     k  avg  count  MRR\n",
      "0    1  0.0    0.0  0.0\n",
      "1    2  0.0    0.0  0.0\n",
      "2    3  0.0    0.0  0.0\n",
      "3    4  0.0    0.0  0.0\n",
      "4    5  0.0    0.0  0.0\n",
      "5    6  0.0    0.0  0.0\n",
      "6    7  0.0    0.0  0.0\n",
      "7    8  0.0    0.0  0.0\n",
      "8    9  0.0    0.0  0.0\n",
      "9   10  0.0    0.0  0.0\n",
      "10  11  0.0    0.0  0.0\n",
      "11  12  0.0    0.0  0.0\n",
      "12  13  0.0    0.0  0.0\n",
      "13  14  0.0    0.0  0.0\n",
      "14  15  0.0    0.0  0.0\n",
      "15  16  0.0    0.0  0.0\n",
      "16  17  0.0    0.0  0.0\n",
      "17  18  0.0    0.0  0.0\n",
      "18  19  0.0    0.0  0.0\n",
      "19  20  0.0    0.0  0.0\n",
      "20  21  0.0    0.0  0.0\n",
      "21  22  0.0    0.0  0.0\n",
      "22  23  0.0    0.0  0.0\n",
      "23  24  0.0    0.0  0.0\n",
      "24  25  0.0    0.0  0.0\n",
      "25  26  0.0    0.0  0.0\n",
      "26  27  0.0    0.0  0.0\n",
      "27  28  0.0    0.0  0.0\n",
      "28  29  0.0    0.0  0.0\n",
      "29  30  0.0    0.0  0.0\n",
      "     k  avg  count  MRR\n",
      "0    1  0.0    0.0  0.0\n",
      "1    2  0.0    0.0  0.0\n",
      "2    3  0.0    0.0  0.0\n",
      "3    4  0.0    0.0  0.0\n",
      "4    5  0.0    0.0  0.0\n",
      "5    6  0.0    0.0  0.0\n",
      "6    7  0.0    0.0  0.0\n",
      "7    8  0.0    0.0  0.0\n",
      "8    9  0.0    0.0  0.0\n",
      "9   10  0.0    0.0  0.0\n",
      "10  11  0.0    0.0  0.0\n",
      "11  12  0.0    0.0  0.0\n",
      "12  13  0.0    0.0  0.0\n",
      "13  14  0.0    0.0  0.0\n",
      "14  15  0.0    0.0  0.0\n",
      "15  16  0.0    0.0  0.0\n",
      "16  17  0.0    0.0  0.0\n",
      "17  18  0.0    0.0  0.0\n",
      "18  19  0.0    0.0  0.0\n",
      "19  20  0.0    0.0  0.0\n",
      "20  21  0.0    0.0  0.0\n",
      "21  22  0.0    0.0  0.0\n",
      "22  23  0.0    0.0  0.0\n",
      "23  24  0.0    0.0  0.0\n",
      "24  25  0.0    0.0  0.0\n",
      "25  26  0.0    0.0  0.0\n",
      "26  27  0.0    0.0  0.0\n",
      "27  28  0.0    0.0  0.0\n",
      "28  29  0.0    0.0  0.0\n",
      "29  30  0.0    0.0  0.0\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1.json\n",
      "     k       avg     count       MRR\n",
      "0    1  0.000000  0.000000  0.000000\n",
      "1    2  0.055556  0.005181  0.009479\n",
      "2    3  0.076923  0.010363  0.018265\n",
      "3    4  0.128205  0.025907  0.043103\n",
      "4    5  0.127660  0.031088  0.050000\n",
      "5    6  0.113208  0.031088  0.048780\n",
      "6    7  0.101695  0.031088  0.047619\n",
      "7    8  0.088235  0.031088  0.045977\n",
      "8    9  0.084507  0.031088  0.045455\n",
      "9   10  0.097222  0.036269  0.052830\n",
      "10  11  0.093333  0.036269  0.052239\n",
      "11  12  0.101266  0.041451  0.058824\n",
      "12  13  0.107143  0.046632  0.064982\n",
      "13  14  0.113636  0.051813  0.071174\n",
      "14  15  0.107527  0.051813  0.069930\n",
      "15  16  0.102041  0.051813  0.068729\n",
      "16  17  0.097087  0.051813  0.067568\n",
      "17  18  0.095238  0.051813  0.067114\n",
      "18  19  0.115044  0.067358  0.084967\n",
      "19  20  0.120690  0.072539  0.090615\n",
      "20  21  0.125000  0.077720  0.095847\n",
      "21  22  0.122951  0.077720  0.095238\n",
      "22  23  0.120968  0.077720  0.094637\n",
      "23  24  0.125984  0.082902  0.100000\n",
      "24  25  0.123077  0.082902  0.099071\n",
      "25  26  0.120301  0.082902  0.098160\n",
      "26  27  0.115108  0.082902  0.096386\n",
      "27  28  0.112676  0.082902  0.095522\n",
      "28  29  0.109589  0.082902  0.094395\n",
      "29  30  0.108108  0.082902  0.093842\n",
      "     k       avg     count       MRR\n",
      "0    1  0.375000  0.015544  0.029851\n",
      "1    2  0.304348  0.036269  0.064815\n",
      "2    3  0.280000  0.036269  0.064220\n",
      "3    4  0.225806  0.036269  0.062500\n",
      "4    5  0.218750  0.036269  0.062222\n",
      "5    6  0.210526  0.041451  0.069264\n",
      "6    7  0.234043  0.056995  0.091667\n",
      "7    8  0.254902  0.067358  0.106557\n",
      "8    9  0.236364  0.067358  0.104839\n",
      "9   10  0.258621  0.077720  0.119522\n",
      "10  11  0.258065  0.082902  0.125490\n",
      "11  12  0.246154  0.082902  0.124031\n",
      "12  13  0.246377  0.088083  0.129771\n",
      "13  14  0.236111  0.088083  0.128302\n",
      "14  15  0.233766  0.093264  0.133333\n",
      "15  16  0.237500  0.098446  0.139194\n",
      "16  17  0.223529  0.098446  0.136691\n",
      "17  18  0.215909  0.098446  0.135231\n",
      "18  19  0.211111  0.098446  0.134276\n",
      "19  20  0.212766  0.103627  0.139373\n",
      "20  21  0.206186  0.103627  0.137931\n",
      "21  22  0.207921  0.108808  0.142857\n",
      "22  23  0.200000  0.108808  0.140940\n",
      "23  24  0.194444  0.108808  0.139535\n",
      "24  25  0.189189  0.108808  0.138158\n",
      "25  26  0.187500  0.108808  0.137705\n",
      "26  27  0.188034  0.113990  0.141935\n",
      "27  28  0.186441  0.113990  0.141479\n",
      "28  29  0.183333  0.113990  0.140575\n",
      "29  30  0.188525  0.119171  0.146032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    #if 'deepmatcher' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "    if 'json' in i and 'deepmatcher' not in i:\n",
    "        conf = load_config(i)\n",
    "        if conf['data'] == 'deepmatcher' and conf['arch'] == 'double-triplet' and 'distilbert' not in conf['bert_path']:\n",
    "            config_knn = get_config_knn_dir(i)\n",
    "            print(conf['data'])\n",
    "            print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "            print(i)\n",
    "            files = get_sorted_files(config_knn)\n",
    "            for j in files:\n",
    "                if 'knn_results' in j:\n",
    "                    results = pd.read_pickle(j)\n",
    "                    print(results[['k', 'avg', 'count', 'MRR']])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    #if 'deepmatcher' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "    if 'json' in i and 'deepmatcher' not in i:\n",
    "        conf = load_config(i)\n",
    "        if conf['data'] == 'deepmatcher' and conf['arch'] == 'double-triplet' and 'distilbert' not in conf['bert_path']:\n",
    "            config_knn = get_config_knn_dir(i)\n",
    "            print(conf['data'])\n",
    "            print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "            print(i)\n",
    "            files = get_sorted_files(config_knn)\n",
    "            for j in files:\n",
    "                if 'knn_results' in j:\n",
    "                    results = pd.read_pickle(j)\n",
    "                    print(results[['k', 'avg', 'count', 'MRR']])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "sustained-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/abt_buy_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-5743-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 1078, 1079, 1080]), 'left_embeddings': array([[-0.41541293,  0.12282223, -0.66462624, ...,  0.44925475,\n",
      "         0.4171951 , -0.5076068 ],\n",
      "       [-0.26252562,  0.03441126, -0.0775456 , ...,  0.75240445,\n",
      "         0.09159085, -0.6814403 ],\n",
      "       [ 0.06494242,  0.10950543,  0.56238526, ..., -0.16467392,\n",
      "         0.28989196, -0.3009965 ],\n",
      "       ...,\n",
      "       [-0.42335004, -0.10694687, -0.40105772, ...,  0.97975874,\n",
      "         0.50607973, -0.03152679],\n",
      "       [-0.57277745, -0.22792205, -0.35964376, ...,  0.78461945,\n",
      "         0.26171792, -0.48309627],\n",
      "       [-0.21033047,  0.06471565,  0.18393987, ...,  0.7797104 ,\n",
      "         0.53571236, -0.4329985 ]], dtype=float32), 'right_index': array([   0,    1,    2, ..., 1089, 1090, 1091]), 'right_embeddings': array([[-0.15856314, -0.17709878,  0.12063873, ...,  0.45251477,\n",
      "         0.24489765, -0.36913273],\n",
      "       [-0.0585952 , -0.2114211 ,  0.06260367, ...,  0.26056114,\n",
      "         0.26507756, -0.30918026],\n",
      "       [-0.00646178, -0.4974101 ,  0.21255851, ...,  0.6281086 ,\n",
      "         0.06322534, -0.38598317],\n",
      "       ...,\n",
      "       [ 0.29492602, -0.13972646, -0.11704548, ...,  0.6066465 ,\n",
      "         0.31812713,  0.19172086],\n",
      "       [ 0.23222077, -0.08813974, -0.07319135, ...,  0.3633213 ,\n",
      "         0.03395841,  0.17622223],\n",
      "       [ 0.18697569, -0.27864903,  0.33089086, ..., -0.20530002,\n",
      "        -0.3229819 , -0.4880467 ]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/amazon_google_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-6874-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 1360, 1361, 1362]), 'left_embeddings': array([[ 0.40075016, -0.00147462,  0.18662003, ..., -0.22354542,\n",
      "        -0.19381195,  0.09100951],\n",
      "       [ 0.4544713 , -0.7522179 ,  0.25291088, ...,  0.02888763,\n",
      "        -0.02401812, -0.43079126],\n",
      "       [-0.04181921,  0.2233569 ,  0.01366786, ..., -0.5276676 ,\n",
      "         0.10268862, -0.41684517],\n",
      "       ...,\n",
      "       [-0.14387274, -0.43236062,  0.06853032, ...,  0.40141228,\n",
      "         0.0513415 , -0.3501694 ],\n",
      "       [ 0.21726643,  0.10698709,  0.0815351 , ...,  0.1432285 ,\n",
      "         0.41166577, -0.64264977],\n",
      "       [ 0.25457078,  0.07225308,  0.4329246 , ...,  0.137354  ,\n",
      "         0.6145756 , -0.8783899 ]], dtype=float32), 'right_index': array([   0,    1,    2, ..., 3223, 3224, 3225]), 'right_embeddings': array([[-0.45089206,  0.36918113, -0.9233499 , ..., -0.07597572,\n",
      "        -0.2861896 ,  0.39869314],\n",
      "       [-0.37151965,  0.78514695, -0.32218042, ..., -0.16658032,\n",
      "        -0.20620143,  0.01571488],\n",
      "       [-0.3868971 ,  0.06574674, -0.50979847, ...,  0.5250497 ,\n",
      "        -0.06948783,  0.37098834],\n",
      "       ...,\n",
      "       [ 0.4317916 , -0.1583439 ,  0.16382834, ...,  0.15921754,\n",
      "         0.9840642 , -0.5403247 ],\n",
      "       [-0.01265333,  0.05491988, -0.05501269, ...,  0.48292166,\n",
      "         0.5099247 , -0.4634112 ],\n",
      "       [-0.3155555 , -0.11657564,  0.24876234, ...,  0.11539176,\n",
      "         0.05203466,  0.62967   ]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/beer_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//beer_exp_data-uncased-masked-ALL-BM25-double-triplet-268-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 4342, 4343, 4344]), 'left_embeddings': array([[-0.08932149,  0.33937332, -0.05681357, ...,  0.22058816,\n",
      "         0.11531995, -0.19270329],\n",
      "       [ 0.06158531,  0.21085757, -0.23943928, ...,  0.5675715 ,\n",
      "        -0.26550683,  0.1577603 ],\n",
      "       [ 0.03753944,  0.10413287, -0.28183785, ...,  0.019361  ,\n",
      "         0.07360023, -0.30306548],\n",
      "       ...,\n",
      "       [-0.2480093 , -0.24355921, -0.09278256, ...,  0.37080553,\n",
      "        -0.07238348, -0.141641  ],\n",
      "       [-0.11508858,  0.13861324, -0.17605655, ...,  0.19040778,\n",
      "         0.27511606,  0.18728986],\n",
      "       [ 0.11361245, -0.10591498,  0.10006557, ...,  0.25435892,\n",
      "        -0.44244972,  0.03102168]], dtype=float32), 'right_index': array([   0,    1,    2, ..., 2997, 2998, 2999]), 'right_embeddings': array([[-0.27563953,  0.07478014,  0.8284503 , ...,  0.07244521,\n",
      "         0.00689491,  0.41913706],\n",
      "       [-0.17620668,  0.02647746,  0.40620244, ...,  0.03812689,\n",
      "         0.18149266,  0.54706144],\n",
      "       [ 0.17241164,  0.17382106,  0.3849207 , ..., -0.2665655 ,\n",
      "        -0.08143374,  0.4073022 ],\n",
      "       ...,\n",
      "       [-0.06587362,  0.06906748,  0.6421674 , ..., -0.0215945 ,\n",
      "        -0.18223499,  0.6625797 ],\n",
      "       [-0.28190976,  0.49487653,  0.34665743, ...,  0.2511925 ,\n",
      "         0.19262154,  0.72584933],\n",
      "       [-0.07997017, -0.10367337,  0.46464577, ...,  0.38728762,\n",
      "         0.12209526,  0.50093806]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/company_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//company_exp_data-uncased-masked-ALL-BM25-double-triplet-67596-1.json\n",
      "{'left_index': array(['http://www.wikidata.org/entity/Q6843249_wiki',\n",
      "       'http://www.wikidata.org/entity/Q7243708_wiki',\n",
      "       'http://www.wikidata.org/entity/Q4047803_wiki', ...,\n",
      "       'http://www.wikidata.org/entity/Q20644661_wiki',\n",
      "       'http://www.wikidata.org/entity/Q7394750_wiki',\n",
      "       'http://www.wikidata.org/entity/Q7955443_wiki'], dtype='<U45'), 'left_embeddings': array([[ 0.7216577 ,  0.6557105 ,  0.13060181, ..., -0.22474319,\n",
      "        -0.34485325,  1.0353717 ],\n",
      "       [-0.03022139, -1.2308614 ,  0.16350771, ..., -0.10706049,\n",
      "         1.0492469 ,  0.71173227],\n",
      "       [-0.0691687 , -0.19595373,  0.21025679, ..., -0.4458957 ,\n",
      "         0.5568904 ,  1.0570445 ],\n",
      "       ...,\n",
      "       [-0.48204133, -0.11802142,  0.6191992 , ...,  0.5746348 ,\n",
      "        -0.35065323,  0.5280966 ],\n",
      "       [ 0.31919125, -0.1091207 , -0.0782904 , ..., -0.7890598 ,\n",
      "        -0.76317763,  1.0112088 ],\n",
      "       [ 0.5550501 , -0.58343756, -0.17562757, ...,  0.1864976 ,\n",
      "         0.834077  ,  0.4177698 ]], dtype=float32), 'right_index': array(['http://www.wikidata.org/entity/Q991188_official',\n",
      "       'http://www.wikidata.org/entity/Q19880587_official',\n",
      "       'http://www.wikidata.org/entity/Q6333706_official', ...,\n",
      "       'http://www.wikidata.org/entity/Q7390286_official',\n",
      "       'http://www.wikidata.org/entity/Q3326326_official',\n",
      "       'http://www.wikidata.org/entity/Q2373202_official'], dtype='<U49'), 'right_embeddings': array([[ 0.7745636 ,  0.52224356,  0.32780525, ..., -0.19074947,\n",
      "        -0.03565972,  0.62222445],\n",
      "       [-0.38184106, -0.29671568,  0.47553095, ..., -0.2916753 ,\n",
      "         0.45806482, -0.91096556],\n",
      "       [-0.32893208,  0.6907058 ,  0.6569493 , ..., -1.176181  ,\n",
      "         0.43274006,  0.51249355],\n",
      "       ...,\n",
      "       [-0.32654524,  0.03364054,  0.23026916, ...,  0.5500957 ,\n",
      "        -0.23876455, -0.88706046],\n",
      "       [-0.08962546, -0.4037594 ,  0.1641252 , ..., -0.04471073,\n",
      "         0.08723558,  0.24741387],\n",
      "       [-0.8702292 ,  0.16636896, -0.43049216, ...,  0.01833752,\n",
      "        -0.04169403,  0.34488997]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 2613, 2614, 2615]), 'left_embeddings': array([[ 0.9503171 , -0.95982105,  0.25491175, ..., -0.01588532,\n",
      "         0.11522641,  0.90968907],\n",
      "       [-0.2564376 ,  0.25431788,  0.44878545, ...,  0.57789016,\n",
      "         0.4034465 , -0.01584764],\n",
      "       [-0.28538918,  0.66669977,  0.6920469 , ...,  0.20657083,\n",
      "        -0.59823465, -0.40681803],\n",
      "       ...,\n",
      "       [-0.13316661,  0.32655326,  0.49813044, ...,  0.3312298 ,\n",
      "        -0.20015976, -0.9497016 ],\n",
      "       [ 1.2656353 , -1.0091995 ,  0.30246806, ..., -0.1659587 ,\n",
      "         0.04663648,  1.1921619 ],\n",
      "       [ 0.22072387,  0.1413475 , -0.2703168 , ..., -0.11902649,\n",
      "        -0.25280365, -0.75883174]], dtype=float32), 'right_index': array([   0,    1,    2, ..., 2291, 2292, 2293]), 'right_embeddings': array([[ 1.0110598 ,  0.26782313,  0.42661592, ..., -0.1736953 ,\n",
      "        -0.23650928,  0.22007748],\n",
      "       [ 0.4648973 ,  0.30357137,  0.12116716, ..., -0.30733284,\n",
      "        -0.29677615, -0.34280214],\n",
      "       [-0.16904831,  0.10475737,  0.04739504, ..., -0.31114137,\n",
      "        -0.33728674, -0.60157055],\n",
      "       ...,\n",
      "       [ 0.70748985,  0.1864353 ,  0.46846026, ..., -0.35599074,\n",
      "         0.18309762,  0.5948109 ],\n",
      "       [ 0.738347  , -0.29672804,  0.28469276, ..., -0.6579363 ,\n",
      "        -0.5371074 ,  0.12544152],\n",
      "       [ 0.54421383,  0.2360979 , -0.4769511 , ...,  0.08525125,\n",
      "        -0.20226465, -0.24820621]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 2613, 2614, 2615]), 'left_embeddings': array([[ 0.36849144, -0.20668201, -0.92047864, ..., -0.2228748 ,\n",
      "         0.01542285,  0.23539183],\n",
      "       [-0.16294225,  0.5124374 , -0.13234939, ..., -0.36433357,\n",
      "        -0.1609087 ,  0.24692473],\n",
      "       [ 0.20700443, -0.4132791 , -0.5080627 , ..., -0.35099715,\n",
      "        -1.0481931 , -0.4958061 ],\n",
      "       ...,\n",
      "       [ 0.07263899, -0.3382575 , -0.00297237, ..., -0.55057645,\n",
      "        -1.070103  , -0.2997653 ],\n",
      "       [ 0.0633288 ,  0.00838716, -0.47065684, ..., -0.76676345,\n",
      "        -1.4024662 ,  0.12253402],\n",
      "       [ 0.1999147 , -0.02907841,  0.18600398, ..., -0.38842222,\n",
      "        -0.32760015, -0.3955533 ]], dtype=float32), 'right_index': array([    0,     1,     2, ..., 64260, 64261, 64262]), 'right_embeddings': array([[-0.36018193,  0.5563452 ,  0.01362058, ..., -0.2980094 ,\n",
      "         0.05340258,  0.08182473],\n",
      "       [-0.08837593, -0.09745508, -0.46321747, ...,  0.5322634 ,\n",
      "        -0.00851938,  0.2969214 ],\n",
      "       [ 0.266056  , -0.33239087, -0.04068865, ...,  0.02931243,\n",
      "         0.2454016 ,  0.06363348],\n",
      "       ...,\n",
      "       [-0.0236398 , -0.3731857 , -0.67158866, ..., -0.21023265,\n",
      "         0.3937204 ,  0.4280939 ],\n",
      "       [ 0.28616995,  0.28803033, -0.05249237, ...,  0.07904327,\n",
      "         0.06284368, -0.29028776],\n",
      "       [ 0.01650827, -0.18127449,  0.17784421, ..., -0.1217778 ,\n",
      "        -0.22201946, -0.07243185]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-7417-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 2613, 2614, 2615]), 'left_embeddings': array([[-0.17428175, -0.00665715, -0.46393624, ..., -0.250921  ,\n",
      "         0.6671334 ,  0.08948024],\n",
      "       [-0.578464  ,  0.8035032 ,  0.28473875, ...,  0.5206914 ,\n",
      "         0.20571916,  0.64494   ],\n",
      "       [-0.12396514,  0.7538699 , -0.40805352, ...,  0.6694508 ,\n",
      "         0.0603843 ,  0.5942202 ],\n",
      "       ...,\n",
      "       [ 0.35053313,  0.72460115, -0.6470184 , ...,  0.6061574 ,\n",
      "         0.13613786,  0.54768735],\n",
      "       [-0.18907924,  0.3733219 ,  0.07927094, ...,  0.10886756,\n",
      "        -0.5071754 ,  0.5200595 ],\n",
      "       [ 0.8890881 ,  0.07724038,  0.1268524 , ...,  0.9639553 ,\n",
      "        -0.10431746,  0.11053463]], dtype=float32), 'right_index': array([   0,    1,    2, ..., 2291, 2292, 2293]), 'right_embeddings': array([[-2.7433956e-01,  3.9170319e-01, -1.7956665e-01, ...,\n",
      "        -2.2593437e-01,  3.6535275e-01, -5.8197868e-01],\n",
      "       [ 6.5515079e-02, -4.3838984e-01, -8.4592158e-01, ...,\n",
      "        -5.0788522e-01,  2.7675399e-01,  3.9235502e-04],\n",
      "       [ 4.6109119e-01, -4.8650697e-01, -1.1815654e+00, ...,\n",
      "        -4.7200301e-01,  6.0752779e-01, -7.9636581e-02],\n",
      "       ...,\n",
      "       [-4.3958279e-01,  8.4989005e-01,  3.9145386e-01, ...,\n",
      "         2.8980488e-01,  3.6901852e-01, -2.2504756e-01],\n",
      "       [ 5.7125437e-01,  2.1338943e-01, -2.0995344e-01, ...,\n",
      "        -2.6450020e-01,  2.1513556e-01, -5.1464140e-04],\n",
      "       [-3.7769547e-01,  7.1276236e-01,  7.5050747e-01, ...,\n",
      "         7.0935071e-01, -2.8867507e-01, -1.0820448e-02]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-17223-1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left_index': array([   0,    1,    2, ..., 2613, 2614, 2615]), 'left_embeddings': array([[ 0.32831055, -0.06227094,  0.12053487, ...,  0.21568522,\n",
      "         0.65667605,  0.11210628],\n",
      "       [ 0.5380415 , -0.35136583, -0.5025487 , ..., -0.9426876 ,\n",
      "        -0.48626193, -0.4973865 ],\n",
      "       [ 0.00138199, -0.39236802, -0.12430289, ...,  0.09256605,\n",
      "         0.3602555 ,  0.1204064 ],\n",
      "       ...,\n",
      "       [-0.17987898, -0.5563971 , -0.08750468, ...,  0.31752124,\n",
      "        -0.06219345, -0.12712863],\n",
      "       [-0.66831964, -0.3742892 ,  0.02533377, ...,  0.29426193,\n",
      "         0.32731622, -0.0961063 ],\n",
      "       [ 0.5411406 , -0.1985184 , -0.4588251 , ..., -0.74636346,\n",
      "         0.13724852, -0.302559  ]], dtype=float32), 'right_index': array([    0,     1,     2, ..., 64260, 64261, 64262]), 'right_embeddings': array([[ 0.20835362,  0.28687203, -0.08506528, ..., -0.33124217,\n",
      "         0.05857167, -0.21066241],\n",
      "       [ 0.32132718,  0.24069601,  0.07280379, ..., -0.10212466,\n",
      "        -0.61871773, -0.05357078],\n",
      "       [ 0.16940427, -0.36658478,  0.73708206, ...,  0.14534251,\n",
      "        -0.1628688 ,  0.18762226],\n",
      "       ...,\n",
      "       [-0.21598028, -0.5624365 , -0.00427627, ..., -0.27346495,\n",
      "         0.08257421,  0.77326375],\n",
      "       [ 0.09942649,  0.03100087,  0.11360238, ...,  0.2309558 ,\n",
      "        -0.7414711 ,  0.20769076],\n",
      "       [ 0.46821097,  0.34189612,  0.32735494, ..., -0.2679471 ,\n",
      "        -0.34099206,  0.29518315]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 6904, 6905, 6906]), 'left_embeddings': array([[-0.11366877, -0.06683675,  0.4536083 , ...,  0.876347  ,\n",
      "        -0.1719039 , -0.21285185],\n",
      "       [ 0.0557472 , -0.13409306,  0.0257481 , ...,  0.7352528 ,\n",
      "        -0.07451717, -0.10331705],\n",
      "       [ 0.3126041 ,  0.09849746, -0.18712105, ...,  0.5798831 ,\n",
      "        -0.11559798, -0.02365984],\n",
      "       ...,\n",
      "       [-0.11309853, -0.4626653 ,  0.3438601 , ...,  0.77268696,\n",
      "         0.00607145, -0.15307944],\n",
      "       [-0.19855969, -0.37604195,  0.29592943, ...,  0.7993472 ,\n",
      "         0.09495462, -0.32947665],\n",
      "       [-0.03272322, -0.40132055,  0.28698424, ...,  0.749482  ,\n",
      "        -0.08377416, -0.17588669]], dtype=float32), 'right_index': array([    0,     1,     2, ..., 55920, 55921, 55922]), 'right_embeddings': array([[ 0.0770826 , -0.19055998,  0.24904469, ..., -0.2018626 ,\n",
      "         0.34636518,  0.520609  ],\n",
      "       [-0.08959378, -0.09589572,  0.20876318, ..., -0.31178442,\n",
      "         0.36562097,  0.44856018],\n",
      "       [ 0.05304482, -0.1173867 ,  0.23239571, ..., -0.12105367,\n",
      "         0.38191178,  0.52115566],\n",
      "       ...,\n",
      "       [ 0.31758144,  0.10742642, -0.13622394, ..., -0.16639948,\n",
      "         0.46277958,  0.17327228],\n",
      "       [ 0.2823726 ,  0.00665096, -0.10799505, ..., -0.19770262,\n",
      "         0.27383575,  0.2431911 ],\n",
      "       [ 0.34401074,  0.06440996, -0.0358269 , ..., -0.2600821 ,\n",
      "         0.29714563,  0.22422485]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 2551, 2552, 2553]), 'left_embeddings': array([[-0.15161248, -0.008026  ,  0.0945274 , ..., -0.26559934,\n",
      "         0.3773813 , -0.28786078],\n",
      "       [ 0.09160995, -0.5594243 , -0.12801188, ..., -0.25885093,\n",
      "        -0.23458794, -0.1434182 ],\n",
      "       [ 0.27717894, -0.27513313,  0.00304051, ..., -0.4988126 ,\n",
      "        -0.11512345, -0.22018397],\n",
      "       ...,\n",
      "       [ 0.3209647 ,  0.05346528,  1.2349473 , ...,  0.05960497,\n",
      "         0.18248428, -1.1657108 ],\n",
      "       [ 0.33908156, -0.401471  , -0.44421744, ..., -0.53425294,\n",
      "         0.04358843,  0.3045709 ],\n",
      "       [-0.4582258 , -0.01216623, -0.3167538 , ..., -0.4684125 ,\n",
      "         0.08615406,  0.08414433]], dtype=float32), 'right_index': array([    0,     1,     2, ..., 22071, 22072, 22073]), 'right_embeddings': array([[-0.40795258,  0.19605929,  0.0417791 , ..., -0.07072897,\n",
      "        -0.08381786, -0.10863229],\n",
      "       [ 0.6120766 ,  0.34004202,  0.6921758 , ..., -0.630819  ,\n",
      "         0.04558847, -0.32876772],\n",
      "       [ 0.3681773 ,  0.11725736,  0.7024789 , ..., -0.8566801 ,\n",
      "        -0.2321829 , -0.41258997],\n",
      "       ...,\n",
      "       [ 0.7590311 , -0.45790657, -0.27005932, ..., -0.35826558,\n",
      "         0.18095906,  0.43064252],\n",
      "       [ 0.23280545, -0.48521993,  0.3097175 , ..., -0.4770885 ,\n",
      "        -0.47598678, -0.09052078],\n",
      "       [-0.60538256,  0.7688094 ,  0.00560399, ...,  0.09215837,\n",
      "        -0.00267004, -0.08098438]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/fodors_zagat_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-567-1.json\n",
      "{'left_index': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532]), 'left_embeddings': array([[ 0.6376824 ,  0.47611833, -0.4269344 , ..., -0.00146175,\n",
      "        -0.07881661,  0.52064735],\n",
      "       [ 0.5950527 ,  0.2780022 , -0.37721992, ...,  0.2740307 ,\n",
      "         0.21660067,  0.36049002],\n",
      "       [ 0.55571973,  0.07441165, -0.52109706, ...,  0.21132335,\n",
      "        -0.20145847,  0.73381126],\n",
      "       ...,\n",
      "       [ 0.8170096 ,  0.2869962 , -0.43647838, ...,  0.41294864,\n",
      "        -0.29928374,  0.6429336 ],\n",
      "       [ 0.6406144 ,  0.2671317 , -0.2960918 , ...,  0.18553796,\n",
      "        -0.37353075,  0.7043205 ],\n",
      "       [ 0.6612886 ,  0.3669027 , -0.3754948 , ...,  0.37269324,\n",
      "        -0.419091  ,  0.5637722 ]], dtype=float32), 'right_index': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330]), 'right_embeddings': array([[-0.66358644, -0.05640173, -0.15315373, ..., -0.01320952,\n",
      "         0.03676574,  0.5245164 ],\n",
      "       [-0.49157974, -0.02275555,  0.03037459, ..., -0.0560651 ,\n",
      "         0.15668581,  0.5325567 ],\n",
      "       [-0.58945996, -0.10757414,  0.12817049, ..., -0.42304343,\n",
      "         0.09438968,  0.4317866 ],\n",
      "       ...,\n",
      "       [ 0.21333708,  0.12275933, -0.03343704, ..., -0.10938652,\n",
      "         0.35117102,  0.38608184],\n",
      "       [-0.03510641,  0.20286666, -0.05982153, ..., -0.11769444,\n",
      "         0.3006989 ,  0.56306314],\n",
      "       [-0.33960354,  0.02153208,  0.07982042, ..., -0.2468275 ,\n",
      "         0.28064525,  0.44149745]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/itunes_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-321-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 6904, 6905, 6906]), 'left_embeddings': array([[-0.06503812, -0.97928846,  0.101797  , ..., -0.17298362,\n",
      "         0.00312755, -0.15590292],\n",
      "       [ 0.39992017, -0.41467455,  0.21104167, ..., -0.17649025,\n",
      "         0.2476685 , -0.07984631],\n",
      "       [ 0.16344376, -0.484274  ,  0.21110284, ...,  0.0023636 ,\n",
      "        -0.15950888, -0.12378205],\n",
      "       ...,\n",
      "       [ 0.12012821, -0.57512146,  0.76455516, ..., -0.5016225 ,\n",
      "        -0.02132185, -0.13047272],\n",
      "       [ 0.27049515, -0.60247684,  0.70705605, ..., -0.43981743,\n",
      "         0.2467588 , -0.09853127],\n",
      "       [ 0.19970675, -0.53603566,  0.6805933 , ..., -0.4642961 ,\n",
      "        -0.01529341, -0.07026825]], dtype=float32), 'right_index': array([    0,     1,     2, ..., 55920, 55921, 55922]), 'right_embeddings': array([[-0.3061002 ,  0.36693403,  0.1729787 , ...,  0.33874762,\n",
      "        -0.25775093,  0.5155314 ],\n",
      "       [-0.27148467,  0.39093786,  0.1359779 , ...,  0.23978344,\n",
      "        -0.2469144 ,  0.5703517 ],\n",
      "       [-0.2133058 ,  0.3888043 ,  0.23519674, ...,  0.25154325,\n",
      "        -0.27878714,  0.50880927],\n",
      "       ...,\n",
      "       [ 0.1566037 , -0.38597718,  0.56458616, ...,  0.0869103 ,\n",
      "         0.3355743 ,  0.27969778],\n",
      "       [ 0.23926316, -0.3014726 ,  0.52989817, ...,  0.11959746,\n",
      "         0.32806078,  0.2626478 ],\n",
      "       [ 0.17933734, -0.4024582 ,  0.5485548 , ...,  0.1192878 ,\n",
      "         0.3307543 ,  0.15656924]], dtype=float32)}\n",
      "\n",
      "deepmatcher\n",
      "double-triplet \t /lfs/1/sahaana/enrichment//ember/pretraining/models/walmart_amazon_exp_data-uncased-masked-ALL-BM25\n",
      "/lfs/1/sahaana/enrichment/ember/embedding/configs//walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-6144-1.json\n",
      "{'left_index': array([   0,    1,    2, ..., 2551, 2552, 2553]), 'left_embeddings': array([[ 0.56349754, -0.2806536 , -0.41103634, ...,  0.7669336 ,\n",
      "        -0.3329454 ,  0.8328368 ],\n",
      "       [ 0.65586877, -0.02091213, -0.5012521 , ...,  0.36389637,\n",
      "         0.09838148, -0.23170997],\n",
      "       [ 0.29040545, -0.32225898, -0.29446724, ..., -0.13994987,\n",
      "         0.41025683,  0.37255576],\n",
      "       ...,\n",
      "       [ 0.16212596,  0.04461711, -0.23923087, ...,  0.1480363 ,\n",
      "         0.17460515,  0.06817381],\n",
      "       [ 0.7347086 , -0.7690222 , -0.16675529, ..., -0.11851658,\n",
      "        -0.02327073, -0.08311963],\n",
      "       [ 0.17584649,  0.04274397, -0.15457433, ...,  0.15393844,\n",
      "         0.06931753,  0.38915113]], dtype=float32), 'right_index': array([    0,     1,     2, ..., 22071, 22072, 22073]), 'right_embeddings': array([[-0.15191565,  0.01327012,  0.26906434, ..., -0.36028898,\n",
      "        -0.07281196, -0.03029573],\n",
      "       [ 0.27274367,  0.19715275, -0.27732998, ...,  0.30379608,\n",
      "        -0.00924516,  0.29008913],\n",
      "       [-0.3840042 ,  0.03619209,  0.1508816 , ...,  0.00998271,\n",
      "         0.23702414,  0.45195913],\n",
      "       ...,\n",
      "       [-0.32277203, -0.0739807 ,  0.09897702, ...,  0.09122065,\n",
      "        -0.6208603 ,  0.23118304],\n",
      "       [ 0.3759398 ,  0.09276462, -0.41792488, ...,  0.0774301 ,\n",
      "        -0.32215995,  0.5065889 ],\n",
      "       [ 0.14727208,  0.02830486,  0.4135297 , ...,  0.5730649 ,\n",
      "         0.09425177,  0.19779658]], dtype=float32)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in get_alpha_sorted_files(config_base):\n",
    "    #if 'deepmatcher' in i:# or 'imdb' in i and 'OLD' not in i:\n",
    "    if 'json' in i and 'deepmatcher' not in i:\n",
    "        conf = load_config(i)\n",
    "        if conf['data'] == 'deepmatcher' and conf['arch'] == 'double-triplet' and 'distilbert' not in conf['bert_path']:\n",
    "            config_knn = get_config_knn_dir(i)\n",
    "            print(conf['data'])\n",
    "            print(conf['arch'], \"\\t\", conf['bert_path'])\n",
    "            print(i)\n",
    "            files = get_sorted_files(config_knn)\n",
    "            for j in files:\n",
    "                if 'embeddings.pkl' in j:\n",
    "                    results = pd.read_pickle(j)\n",
    "                    print(results)\n",
    "                    print()\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-ranking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember_pip",
   "language": "python",
   "name": "ember_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
