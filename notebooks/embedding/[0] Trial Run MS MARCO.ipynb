{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahaana\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/lfs/1/sahaana/enrichment/enrich/utils')\n",
    "sys.path.append('/lfs/1/sahaana/enrichment/ember/utils')\n",
    " \n",
    "    \n",
    "from embedding_datasets import MARCODataset, EmberEvalDataset\n",
    "from embedding_models import TripletSingleBERTModel\n",
    "from embedding_utils import param_header, tokenize_batch  \n",
    "from embedding_runner import train_model, eval_model\n",
    "#from model_utils import MatchedDatasetTriplets, param_header_bert, tokenize_batch   \n",
    "#from models import BatchedTripletSingleTowerModel, BatchedTripletSingleBERTModel\n",
    "#from model_runner import train_model, eval_model\n",
    "from knn_utils import FaissKNeighbors, knn_MARCO_recall #, knn_matching_accuracy, find_perfect_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Processed (cleaned, aligned) Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = '/lfs/1/sahaana/enrichment/data/MSMARCO/tableA_processed.pkl'\n",
    "right = '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl'\n",
    "\n",
    "left = pd.read_pickle(left).set_index('QID')\n",
    "right = pd.read_pickle(right).set_index('PID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping Data Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.read_csv(val_df, sep='\\t',\\n                     header=None, \\n                     usecols=[0,2], \\n                     names=['QID', 'PID'])\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = '/lfs/1/sahaana/enrichment/data/MSMARCO/qidpidtriples.train.full.2.pkl'\n",
    "train_df = pd.read_pickle(train_df)#pd.read_csv(train_df, sep=\"\\t\", names = ['QID_a', 'PID_p', 'PID_n'])\n",
    "\n",
    "val_df = '/lfs/1/sahaana/enrichment/data/MSMARCO/qrels.dev.small.pkl'\n",
    "val_df = pd.read_pickle(val_df)\n",
    "\n",
    "\"\"\"pd.read_csv(val_df, sep='\\t',\n",
    "                     header=None, \n",
    "                     usecols=[0,2], \n",
    "                     names=['QID', 'PID'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle('/lfs/1/sahaana/enrichment/data/MSMARCO/qidpidtriples.train.full.2.pkl')\n",
    "val_df.to_pickle('/lfs/1/sahaana/enrichment/data/MSMARCO/qrels.dev.small.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model H Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 8\n",
    "final_size = 200\n",
    "lr = .00001\n",
    "tl_margin = 1.0\n",
    "tl_p = 2\n",
    "pool_type = \"CLS\"\n",
    "column = \"merged_all\"\n",
    "shuffle = True\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer_max_length = 512\n",
    "compute_val = False\n",
    "train_size = int(len(train_df)/8)\n",
    "    \n",
    "\n",
    "bert_path='/lfs/1/sahaana/enrichment/ember/pretraining/models/MARCO-uncased-masked-ALL-BM25'\n",
    "bert_model = DistilBertModel.from_pretrained(bert_path, return_dict=True)\n",
    "\n",
    "model_name = f'MARCO-uncased-masked-ALL-BM25'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DataLoader(SQuADDataset(left, right, len(val_df), column, val_df), \\n                       batch_size=batch_size,\\n                       shuffle = False\\n                      )'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = DataLoader(MARCODataset(left, right, len(train_df), column, train_df), \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle = shuffle\n",
    "                        )\n",
    "\n",
    "val_data = None \n",
    "\"\"\"DataLoader(SQuADDataset(left, right, len(val_df), column, val_df), \n",
    "                       batch_size=batch_size,\n",
    "                       shuffle = False\n",
    "                      )\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_loss = nn.TripletMarginLoss(margin=tl_margin, p=tl_p)\n",
    "losses = []\n",
    "val_losses = []\n",
    "model = TripletSingleBERTModel(final_size, pool_type, bert_path)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)#optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = param_header(batch_size, final_size, lr, pool_type, epochs, train_size)\n",
    "save_dir = f'models/{model_name}/{save_dir}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vibrant-armadillo-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/MARCO-uncased-masked-ALL-BM25\" target=\"_blank\">https://wandb.ai/sahaana/MARCO-uncased-masked-ALL-BM25</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/MARCO-uncased-masked-ALL-BM25/runs/325ffas9\" target=\"_blank\">https://wandb.ai/sahaana/MARCO-uncased-masked-ALL-BM25/runs/325ffas9</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210220_153028-325ffas9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(325ffas9)</h1><iframe src=\"https://wandb.ai/sahaana/MARCO-uncased-masked-ALL-BM25/runs/325ffas9\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb0020ac580>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8d36ffbaa46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_model(model, \n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mtokenize_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/sahaana/enrichment/ember/utils/embedding_runner.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, tokenizer, batch_tokenizer, train_data, val_data, loss_func, optimizer, epochs, losses, val_losses, save_dir, compute_val, tokenizer_max_length)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0moa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ember_pip/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ember_pip/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, \n",
    "            tokenizer, \n",
    "            tokenize_batch, \n",
    "            train_data, \n",
    "            val_data, \n",
    "            triplet_loss, \n",
    "            optimizer, \n",
    "            epochs, \n",
    "            losses, \n",
    "            val_losses, \n",
    "            save_dir, \n",
    "            compute_val, \n",
    "            tokenizer_max_length = tokenizer_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eval = '/lfs/1/sahaana/enrichment/data/MSMARCO/dev_tableA_processed.pkl'\n",
    "right_eval = '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl'\n",
    "test = '/lfs/1/sahaana/enrichment/data/MSMARCO/qrels.dev.small.pkl'\n",
    "\n",
    "left_eval = pd.read_pickle(left_eval).set_index('QID')\n",
    "right_eval = right#pd.read_pickle(right_eval)\n",
    "test_df = val_df#pd.read_pickle(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"models/single-tower-BERT-triplet-model/batch_size-8-final_size-50-opt_lr-0.0001-tloss_margin-1.0-tloss_p-2-pooling-CLS-shuffle-True00-35-05-01-21\"\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "left_eval_data = DataLoader(EmberEvalDataset(left_eval, column, indexed=True), \n",
    "                       batch_size=batch_size,\n",
    "                       shuffle = False\n",
    "                      )\n",
    "right_eval_data = DataLoader(EmberEvalDataset(right_eval, column, indexed=True), \n",
    "                       batch_size=batch_size,\n",
    "                       shuffle = False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_index, left_embeddings = eval_model(model, tokenizer, left_eval_data, tokenizer_max_length=512)\n",
    "right_index, right_embeddings = eval_model(model, tokenizer, right_eval_data, tokenizer_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = FaissKNeighbors(k=30)\n",
    "knn.fit(right_embeddings)\n",
    "neib = knn.kneighbors(left_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_results = defaultdict(list)\n",
    "for k in range(1,31):\n",
    "    avg, count, MRR, results, MRR_results = knn_MARCO_recall(neib[0], neib[1], test_df, left_index, right_index, k=k)\n",
    "    knn_results['k'].append(k)\n",
    "    knn_results['avg'].append(avg)\n",
    "    knn_results['count'].append(count)\n",
    "    knn_results['MRR'].append(MRR)\n",
    "    knn_results['results'].append(results)\n",
    "    knn_results['MRR_results'].append(MRR_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>avg</th>\n",
       "      <th>count</th>\n",
       "      <th>MRR</th>\n",
       "      <th>results</th>\n",
       "      <th>MRR_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.149140</td>\n",
       "      <td>1041</td>\n",
       "      <td>0.149140</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.227221</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.188181</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.277650</td>\n",
       "      <td>1938</td>\n",
       "      <td>0.204990</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.314470</td>\n",
       "      <td>2195</td>\n",
       "      <td>0.214195</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.340831</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.219468</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.366476</td>\n",
       "      <td>2558</td>\n",
       "      <td>0.223742</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.382665</td>\n",
       "      <td>2671</td>\n",
       "      <td>0.226054</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.397421</td>\n",
       "      <td>2774</td>\n",
       "      <td>0.227899</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.411318</td>\n",
       "      <td>2871</td>\n",
       "      <td>0.229443</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.423926</td>\n",
       "      <td>2959</td>\n",
       "      <td>0.230704</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.436963</td>\n",
       "      <td>3050</td>\n",
       "      <td>0.231889</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.447994</td>\n",
       "      <td>3127</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.458309</td>\n",
       "      <td>3199</td>\n",
       "      <td>0.233602</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.465473</td>\n",
       "      <td>3249</td>\n",
       "      <td>0.234113</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.472493</td>\n",
       "      <td>3298</td>\n",
       "      <td>0.234581</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.480516</td>\n",
       "      <td>3354</td>\n",
       "      <td>0.235083</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.486963</td>\n",
       "      <td>3399</td>\n",
       "      <td>0.235462</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.491977</td>\n",
       "      <td>3434</td>\n",
       "      <td>0.235741</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>3474</td>\n",
       "      <td>0.236042</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.502865</td>\n",
       "      <td>3510</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.508023</td>\n",
       "      <td>3546</td>\n",
       "      <td>0.236546</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.512321</td>\n",
       "      <td>3576</td>\n",
       "      <td>0.236741</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.516189</td>\n",
       "      <td>3603</td>\n",
       "      <td>0.236909</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.521347</td>\n",
       "      <td>3639</td>\n",
       "      <td>0.237124</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.525645</td>\n",
       "      <td>3669</td>\n",
       "      <td>0.237296</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.530372</td>\n",
       "      <td>3702</td>\n",
       "      <td>0.237478</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.533524</td>\n",
       "      <td>3724</td>\n",
       "      <td>0.237595</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.537822</td>\n",
       "      <td>3754</td>\n",
       "      <td>0.237748</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.542120</td>\n",
       "      <td>3784</td>\n",
       "      <td>0.237896</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.544986</td>\n",
       "      <td>3804</td>\n",
       "      <td>0.237992</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k       avg  count       MRR  \\\n",
       "0    1  0.149140   1041  0.149140   \n",
       "1    2  0.227221   1586  0.188181   \n",
       "2    3  0.277650   1938  0.204990   \n",
       "3    4  0.314470   2195  0.214195   \n",
       "4    5  0.340831   2379  0.219468   \n",
       "5    6  0.366476   2558  0.223742   \n",
       "6    7  0.382665   2671  0.226054   \n",
       "7    8  0.397421   2774  0.227899   \n",
       "8    9  0.411318   2871  0.229443   \n",
       "9   10  0.423926   2959  0.230704   \n",
       "10  11  0.436963   3050  0.231889   \n",
       "11  12  0.447994   3127  0.232808   \n",
       "12  13  0.458309   3199  0.233602   \n",
       "13  14  0.465473   3249  0.234113   \n",
       "14  15  0.472493   3298  0.234581   \n",
       "15  16  0.480516   3354  0.235083   \n",
       "16  17  0.486963   3399  0.235462   \n",
       "17  18  0.491977   3434  0.235741   \n",
       "18  19  0.497708   3474  0.236042   \n",
       "19  20  0.502865   3510  0.236300   \n",
       "20  21  0.508023   3546  0.236546   \n",
       "21  22  0.512321   3576  0.236741   \n",
       "22  23  0.516189   3603  0.236909   \n",
       "23  24  0.521347   3639  0.237124   \n",
       "24  25  0.525645   3669  0.237296   \n",
       "25  26  0.530372   3702  0.237478   \n",
       "26  27  0.533524   3724  0.237595   \n",
       "27  28  0.537822   3754  0.237748   \n",
       "28  29  0.542120   3784  0.237896   \n",
       "29  30  0.544986   3804  0.237992   \n",
       "\n",
       "                                              results  \\\n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...   \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...   \n",
       "3   [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...   \n",
       "4   [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...   \n",
       "5   [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...   \n",
       "6   [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "7   [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "8   [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "9   [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "10  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "11  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "12  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "13  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "14  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "15  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "16  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "17  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "18  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "19  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "20  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "21  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "22  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "23  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "24  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "25  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "26  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "27  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "28  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "29  [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, ...   \n",
       "\n",
       "                                          MRR_results  \n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "9   [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "10  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "12  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "13  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "14  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "15  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "16  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "18  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "19  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "20  [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0,...  \n",
       "21  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "22  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "23  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "24  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "25  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "26  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "27  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "28  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  \n",
       "29  [0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.2...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember_pip",
   "language": "python",
   "name": "ember_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
