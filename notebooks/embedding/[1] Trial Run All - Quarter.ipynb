{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msahaana\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/lfs/1/sahaana/enrichment/enrich/utils')\n",
    "sys.path.append('/lfs/1/sahaana/enrichment/ember/utils')\n",
    " \n",
    "    \n",
    "from embedding_datasets import DeepMatcherDataset, EmberEvalDataset\n",
    "from embedding_models import TripletSingleBERTModel\n",
    "from embedding_utils import param_header, tokenize_batch  \n",
    "from embedding_runner import train_model, eval_model\n",
    "#from model_utils import MatchedDatasetTriplets, param_header_bert, tokenize_batch   \n",
    "#from models import BatchedTripletSingleTowerModel, BatchedTripletSingleBERTModel\n",
    "#from model_runner import train_model, eval_model\n",
    "from knn_utils import FaissKNeighbors, knn_top_1_PRFS, knn_deepmatcher_recall #, knn_matching_accuracy, find_perfect_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUMBUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {0:\"abt_buy_exp_data\", \n",
    "            1:\"amazon_google_exp_data\", \n",
    "            2:\"beer_exp_data\", \n",
    "            3:\"company_exp_data\", \n",
    "            4:\"dblp_acm_exp_data\", \n",
    "            5:\"dblp_scholar_exp_data\", \n",
    "            6:\"dirty_dblp_acm_exp_data\", \n",
    "            7:\"dirty_dblp_scholar_exp_data\", \n",
    "            8:\"dirty_itunes_amazon_exp_data\", \n",
    "            9:\"dirty_walmart_amazon_exp_data\", \n",
    "            10:\"fodors_zagat_exp_data\", \n",
    "            11:\"itunes_amazon_exp_data\", \n",
    "            12:\"walmart_amazon_exp_data\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abt_buy_exp_data\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(datasets[d])\n",
    "    left = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/tableA_processed.pkl'\n",
    "    right = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/tableB_processed.pkl'\n",
    "\n",
    "    left = pd.read_pickle(left)\n",
    "    right = pd.read_pickle(right)\n",
    "\n",
    "    train_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/train_updated.csv'\n",
    "    train_df = pd.read_csv(train_df)\n",
    "\n",
    "    val_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/val_updated.csv'\n",
    "    val_df = pd.read_csv(val_df)\n",
    "\n",
    "    test_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/test_updated.csv'\n",
    "    test_df = pd.read_csv(test_df)\n",
    "\n",
    "    epochs = 1\n",
    "    batch_size = 8\n",
    "    final_size = 200\n",
    "    lr = .00001\n",
    "    tl_margin = 1.0\n",
    "    tl_p = 2\n",
    "    pool_type = \"CLS\"\n",
    "    column = \"merged_all\"\n",
    "    shuffle = True\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    tokenizer_max_length = 512\n",
    "    compute_val = False\n",
    "    train_size = int(len(train_df)/4)\n",
    "\n",
    "    bert_path=f'/lfs/1/sahaana/enrichment/ember/pretraining/models/{datasets[d]}-uncased-masked-ALL-BM25'\n",
    "    bert_model = DistilBertModel.from_pretrained(bert_path, return_dict=True)\n",
    "\n",
    "    model_name = f'{datasets[d]}-uncased-masked-ALL-BM25-{train_size}'\n",
    "\n",
    "    train_data = DataLoader(DeepMatcherDataset(left, right, train_size, column, train_df), \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle = shuffle\n",
    "                            )\n",
    "\n",
    "    val_data = DataLoader(DeepMatcherDataset(left, right, len(val_df), column, val_df), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "\n",
    "    triplet_loss = nn.TripletMarginLoss(margin=tl_margin, p=tl_p)\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    model = TripletSingleBERTModel(final_size, pool_type, bert_path)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)#optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    save_dir = param_header(batch_size, final_size, lr, pool_type, epochs, train_size)\n",
    "    save_dir = f'models/{model_name}/{save_dir}/'\n",
    "\n",
    "    wandb.init(project=model_name)\n",
    "\n",
    "    train_model(model, \n",
    "                tokenizer, \n",
    "                tokenize_batch, \n",
    "                train_data, \n",
    "                val_data, \n",
    "                triplet_loss, \n",
    "                optimizer, \n",
    "                epochs, \n",
    "                losses, \n",
    "                val_losses, \n",
    "                save_dir, \n",
    "                compute_val, \n",
    "                tokenizer_max_length = tokenizer_max_length)\n",
    "\n",
    "\n",
    "    left_data = DataLoader(EmberEvalDataset(left, column), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "    right_data = DataLoader(EmberEvalDataset(right, column), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "\n",
    "    left_embeddings = eval_model(model, tokenizer, left_data, tokenizer_max_length=512)\n",
    "    right_embeddings = eval_model(model, tokenizer, right_data, tokenizer_max_length=512)\n",
    "\n",
    "    knn = FaissKNeighbors(k=30)\n",
    "    knn.fit(right_embeddings)\n",
    "    neib = knn.kneighbors(left_embeddings)\n",
    "    print(datasets[d])\n",
    "    print(f\"precision, recall, F1, support: {knn_top_1_PRFS(neib[0], neib[1], test_df)}\")\n",
    "    print()\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abt_buy_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2fs1szlx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 53328<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210220_195241-2fs1szlx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210220_195241-2fs1szlx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>180</td></tr><tr><td>_runtime</td><td>32</td></tr><tr><td>_timestamp</td><td>1613879593</td></tr><tr><td>train batch loss</td><td>0.52706</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>▇██▅▆▄▄▆▅▆▅▃▂▃▅▆▃▄▅▄▂▃▄▂▅▂▄▂▃▂▂▁▂▂▁▂▂▂▁▅</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fearless-flower-4</strong>: <a href=\"https://wandb.ai/sahaana/abt_buy_exp_data-uncased-masked-ALL-BM25-1435/runs/2fs1szlx\" target=\"_blank\">https://wandb.ai/sahaana/abt_buy_exp_data-uncased-masked-ALL-BM25-1435/runs/2fs1szlx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2fs1szlx). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">driven-spaceship-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/abt_buy_exp_data-uncased-masked-ALL-BM25-1435\" target=\"_blank\">https://wandb.ai/sahaana/abt_buy_exp_data-uncased-masked-ALL-BM25-1435</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/abt_buy_exp_data-uncased-masked-ALL-BM25-1435/runs/1ny8yu7y\" target=\"_blank\">https://wandb.ai/sahaana/abt_buy_exp_data-uncased-masked-ALL-BM25-1435/runs/1ny8yu7y</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210220_195348-1ny8yu7y</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model: models/abt_buy_exp_data-uncased-masked-ALL-BM25-1435/batch_size-8-final_size-200-opt_lr-1e-05-pooling-CLS-epochs-1-train-1435/19-54-20-02-21\n",
      "abt_buy_exp_data\n",
      "precision, recall, F1, support: ((0.9285714285714286, 0.8203883495145631, 0.8711340206185566, None), [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing for the script\n",
    "for d in datasets:\n",
    "    print(datasets[d])\n",
    "    left = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/tableA_processed.pkl'\n",
    "    right = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/tableB_processed.pkl'\n",
    "\n",
    "    left = pd.read_pickle(left)\n",
    "    right = pd.read_pickle(right)\n",
    "\n",
    "    train_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/supervision_train.pkl'\n",
    "    train_df = pd.read_pickle(train_df)\n",
    "\n",
    "    test_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/supervision_test.pkl'\n",
    "    test_df = pd.read_pickle(test_df)\n",
    "\n",
    "    epochs = 1\n",
    "    batch_size = 8\n",
    "    final_size = 200\n",
    "    lr = .00001\n",
    "    tl_margin = 1.0\n",
    "    tl_p = 2\n",
    "    pool_type = \"CLS\"\n",
    "    column = \"merged_all\"\n",
    "    shuffle = True\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    tokenizer_max_length = 512\n",
    "    compute_val = False\n",
    "    train_size = int(len(train_df)/4)\n",
    "\n",
    "    bert_path=f'/lfs/1/sahaana/enrichment/ember/pretraining/models/{datasets[d]}-uncased-masked-ALL-BM25'\n",
    "    bert_model = DistilBertModel.from_pretrained(bert_path, return_dict=True)\n",
    "\n",
    "    model_name = f'{datasets[d]}-uncased-masked-ALL-BM25-{train_size}'\n",
    "\n",
    "    train_data = DataLoader(DeepMatcherDataset(left, right, train_size, column, train_df), \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle = shuffle\n",
    "                            )\n",
    "\n",
    "    val_data = None\n",
    "\n",
    "    triplet_loss = nn.TripletMarginLoss(margin=tl_margin, p=tl_p)\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    model = TripletSingleBERTModel(final_size, pool_type, bert_path)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)#optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    save_dir = param_header(batch_size, final_size, lr, pool_type, epochs, train_size)\n",
    "    save_dir = f'models/{model_name}/{save_dir}/'\n",
    "\n",
    "    wandb.init(project=model_name)\n",
    "\n",
    "    train_model(model, \n",
    "                tokenizer, \n",
    "                tokenize_batch, \n",
    "                train_data, \n",
    "                val_data, \n",
    "                triplet_loss, \n",
    "                optimizer, \n",
    "                epochs, \n",
    "                losses, \n",
    "                val_losses, \n",
    "                save_dir, \n",
    "                compute_val, \n",
    "                tokenizer_max_length = tokenizer_max_length)\n",
    "\n",
    "\n",
    "    left_data = DataLoader(EmberEvalDataset(left, column, indexed=True), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "    right_data = DataLoader(EmberEvalDataset(right, column, indexed=True), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "\n",
    "    left_embeddings = eval_model(model, tokenizer, left_data, tokenizer_max_length=512)\n",
    "    right_embeddings = eval_model(model, tokenizer, right_data, tokenizer_max_length=512)\n",
    "\n",
    "    knn = FaissKNeighbors(k=30)\n",
    "    knn.fit(right_embeddings)\n",
    "    neib = knn.kneighbors(left_embeddings)\n",
    "    print(datasets[d])\n",
    "    print(f\"precision, recall, F1, support: {knn_top_1_PRFS(neib[0], neib[1], test_df)}\")\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    left_data = DataLoader(EmberEvalDataset(left, column, indexed=True), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "    right_data = DataLoader(EmberEvalDataset(right, column, indexed=True), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "\n",
    "    left_index, left_embeddings = eval_model(model, tokenizer, left_data, tokenizer_max_length=512)\n",
    "    right_index, right_embeddings = eval_model(model, tokenizer, right_data, tokenizer_max_length=512)\n",
    "\n",
    "    knn = FaissKNeighbors(k=30)\n",
    "    knn.fit(right_embeddings)\n",
    "    neib = knn.kneighbors(left_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2700619 ,  0.05895563, -0.48198986, ...,  0.26641858,\n",
       "        -0.19231737, -0.6018808 ],\n",
       "       [ 1.0032096 ,  0.28362516, -0.6229593 , ..., -0.17669171,\n",
       "         0.05642968, -0.29127803],\n",
       "       [-0.147342  , -0.30044255, -0.32882872, ..., -0.08050206,\n",
       "         0.32331964, -0.45460165],\n",
       "       ...,\n",
       "       [-0.12334809, -0.13174953,  0.10212716, ..., -0.1475614 ,\n",
       "         0.17826308, -0.02833558],\n",
       "       [ 0.16046405, -0.00719314, -0.3470052 , ..., -0.22556528,\n",
       "         0.1236966 , -0.36079985],\n",
       "       [-0.31106687,  0.34422   , -0.8377285 , ...,  0.16381264,\n",
       "         0.34641707, -0.47452974]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1089, 1090, 1091])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_recall_fscore_support' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-85496b426a6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknn_top_1_TEST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-100330797ebf>\u001b[0m in \u001b[0;36mknn_top_1_TEST\u001b[0;34m(dists, neibs, supervision, left_indexing, right_indexing)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_recall_fscore_support' is not defined"
     ]
    }
   ],
   "source": [
    "knn_top_1_TEST(neib[0], neib[1], test_df, left_index, right_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.7910423, 17.559998 ,  7.18272  , ...,  7.7182236, 11.385677 ,\n",
       "        5.847275 ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(neib[0][:,:1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.7910423, 11.013393 , 14.370218 , ..., 20.057037 , 20.16292  ,\n",
       "        20.249737 ],\n",
       "       [17.559998 , 17.996239 , 19.441633 , ..., 22.850372 , 22.924067 ,\n",
       "        22.931057 ],\n",
       "       [ 7.18272  , 11.802906 , 16.052406 , ..., 20.770567 , 20.799702 ,\n",
       "        20.914497 ],\n",
       "       ...,\n",
       "       [ 7.7182236, 17.346403 , 18.087666 , ..., 22.572784 , 22.642424 ,\n",
       "        22.656689 ],\n",
       "       [11.385677 , 14.969315 , 15.236919 , ..., 20.900738 , 21.362034 ,\n",
       "        22.040407 ],\n",
       "       [ 5.847275 ,  7.9882774,  8.280563 , ..., 23.93537  , 24.098015 ,\n",
       "        24.328302 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neib[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9285714285714286, 0.8203883495145631, 0.8711340206185566, None),\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_top_1_PRFS(neib[0], neib[1], test_df, left_index, right_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.640495867768595,\n",
       " 0.7524271844660194,\n",
       " 0.6919642857142857,\n",
       " None,\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_deepmatcher_recall(neib[0], neib[1], test_df, left_index, right_index, thresh = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9285714285714286, 0.8203883495145631, 0.8711340206185566, None),\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_top_1_PRFS(neib[0], neib[1], test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {0: {53, 710},\n",
       "             1: {138, 154},\n",
       "             2: {33, 121},\n",
       "             3: {58, 195},\n",
       "             4: {114, 153},\n",
       "             5: {191, 389},\n",
       "             6: {213, 223},\n",
       "             7: {161, 1056},\n",
       "             8: {37, 338},\n",
       "             9: {57, 179},\n",
       "             10: {34, 35},\n",
       "             11: {34, 35},\n",
       "             12: {58, 197},\n",
       "             13: {58, 197},\n",
       "             14: {44, 595},\n",
       "             15: {56, 640},\n",
       "             16: {376, 378},\n",
       "             17: {223, 845},\n",
       "             18: {104, 211},\n",
       "             19: {39, 40},\n",
       "             20: {39, 40},\n",
       "             21: {196, 208},\n",
       "             22: {62, 221},\n",
       "             23: {483, 491},\n",
       "             24: {42, 453},\n",
       "             25: {20, 21},\n",
       "             26: {201, 755},\n",
       "             27: {47, 71},\n",
       "             28: {47, 48},\n",
       "             29: {41, 43},\n",
       "             30: {41, 43},\n",
       "             31: {643, 886},\n",
       "             32: {50, 177},\n",
       "             33: {198, 361},\n",
       "             34: {169, 324},\n",
       "             35: {199, 1064},\n",
       "             36: {228, 281},\n",
       "             37: {179, 845},\n",
       "             38: {152, 192},\n",
       "             39: {984, 985},\n",
       "             40: {28, 54},\n",
       "             41: {212, 811},\n",
       "             42: {349, 811},\n",
       "             43: {170, 178},\n",
       "             44: {194, 210},\n",
       "             45: {985, 1085},\n",
       "             46: {212, 316},\n",
       "             47: {63, 79},\n",
       "             48: {59, 63},\n",
       "             49: {102, 225},\n",
       "             50: {48, 55},\n",
       "             51: {218, 354},\n",
       "             52: {61, 312},\n",
       "             53: {126, 666},\n",
       "             54: {60, 336},\n",
       "             55: {35, 102},\n",
       "             56: {107, 356},\n",
       "             57: {106, 551},\n",
       "             58: {65, 268},\n",
       "             59: {16, 984},\n",
       "             60: {39, 46},\n",
       "             61: {76, 77},\n",
       "             62: {59, 75},\n",
       "             63: {673, 711},\n",
       "             64: {72, 74},\n",
       "             65: {72, 74},\n",
       "             66: {212, 316},\n",
       "             67: {86, 583},\n",
       "             68: {222, 1073},\n",
       "             69: {236, 1059},\n",
       "             70: {405, 952},\n",
       "             71: {108, 109},\n",
       "             72: {76, 77},\n",
       "             73: {870, 918},\n",
       "             74: {870, 918},\n",
       "             75: {170, 227},\n",
       "             76: {364, 1048},\n",
       "             77: {108, 109},\n",
       "             78: {80, 446},\n",
       "             79: {149, 386},\n",
       "             80: {59, 75},\n",
       "             81: {257, 659},\n",
       "             82: {68, 69},\n",
       "             83: {200, 373},\n",
       "             84: {129, 148},\n",
       "             85: {113, 283},\n",
       "             86: {210, 564},\n",
       "             87: {47, 71},\n",
       "             88: {49, 381},\n",
       "             89: {20, 446},\n",
       "             90: {99, 101},\n",
       "             91: {86, 97},\n",
       "             92: {83, 272},\n",
       "             93: {86, 97},\n",
       "             94: {83, 98},\n",
       "             95: {271, 272},\n",
       "             96: {232, 366},\n",
       "             97: {3, 14},\n",
       "             98: {193, 608},\n",
       "             99: {18, 113},\n",
       "             100: {26, 341},\n",
       "             101: {135, 301},\n",
       "             102: {209, 395},\n",
       "             103: {169, 1082},\n",
       "             104: {113, 672},\n",
       "             105: {478, 615},\n",
       "             106: {4, 91},\n",
       "             107: {317, 640},\n",
       "             108: {122, 123},\n",
       "             109: {99, 101},\n",
       "             110: {101, 576},\n",
       "             111: {260, 355},\n",
       "             112: {51, 69},\n",
       "             113: {393, 514},\n",
       "             114: {59, 124},\n",
       "             115: {52, 894},\n",
       "             116: {25, 439},\n",
       "             117: {144, 325},\n",
       "             118: {131, 615},\n",
       "             119: {46, 120},\n",
       "             120: {179, 268},\n",
       "             121: {128, 956},\n",
       "             122: {137, 146},\n",
       "             123: {78, 372},\n",
       "             124: {82, 136},\n",
       "             125: {129, 370},\n",
       "             126: {28, 926},\n",
       "             127: {113, 672},\n",
       "             128: {28, 907},\n",
       "             129: {353, 868},\n",
       "             130: {203, 386},\n",
       "             131: {329, 608},\n",
       "             132: {33, 151},\n",
       "             133: {135, 202},\n",
       "             134: {8, 9},\n",
       "             135: {145, 1048},\n",
       "             136: {121, 360},\n",
       "             137: {238, 392},\n",
       "             138: {28, 30},\n",
       "             139: {565, 919},\n",
       "             140: {353, 868},\n",
       "             141: {173, 948},\n",
       "             142: {173, 948},\n",
       "             143: {64, 245},\n",
       "             144: {213, 278},\n",
       "             145: {50, 177},\n",
       "             146: {140, 335},\n",
       "             147: {140, 141},\n",
       "             148: {246, 358},\n",
       "             149: {478, 615},\n",
       "             150: {208, 710},\n",
       "             151: {189, 190},\n",
       "             152: {99, 176},\n",
       "             153: {80, 247},\n",
       "             154: {40, 240},\n",
       "             155: {82, 136},\n",
       "             156: {189, 190},\n",
       "             157: {239, 713},\n",
       "             158: {207, 603},\n",
       "             159: {239, 448},\n",
       "             160: {4, 91},\n",
       "             161: {237, 256},\n",
       "             162: {111, 1035},\n",
       "             163: {235, 248},\n",
       "             164: {59, 73},\n",
       "             165: {32, 580},\n",
       "             166: {150, 829},\n",
       "             167: {159, 696},\n",
       "             168: {258, 1021},\n",
       "             169: {248, 295},\n",
       "             170: {160, 688},\n",
       "             171: {45, 90},\n",
       "             172: {260, 355},\n",
       "             173: {168, 324},\n",
       "             174: {182, 840},\n",
       "             175: {183, 279},\n",
       "             176: {158, 307},\n",
       "             177: {324, 539},\n",
       "             178: {168, 324},\n",
       "             179: {169, 204},\n",
       "             180: {132, 531},\n",
       "             181: {134, 1071},\n",
       "             182: {163, 1082},\n",
       "             183: {281, 314},\n",
       "             184: {275, 539},\n",
       "             185: {318, 353},\n",
       "             186: {356, 436},\n",
       "             187: {315, 596},\n",
       "             188: {869, 872},\n",
       "             189: {267, 429},\n",
       "             190: {138, 139},\n",
       "             191: {138, 139},\n",
       "             192: {263, 997},\n",
       "             193: {263, 382},\n",
       "             194: {81, 110},\n",
       "             195: {283, 467},\n",
       "             196: {117, 630},\n",
       "             197: {243, 502},\n",
       "             198: {89, 152},\n",
       "             199: {236, 259},\n",
       "             200: {133, 189},\n",
       "             201: {183, 279},\n",
       "             202: {237, 256},\n",
       "             203: {303, 539},\n",
       "             204: {288, 629},\n",
       "             205: {266, 282},\n",
       "             206: {0, 35},\n",
       "             207: {185, 253},\n",
       "             208: {294, 357},\n",
       "             209: {481, 738},\n",
       "             210: {327, 875},\n",
       "             211: {325, 327},\n",
       "             212: {325, 327},\n",
       "             213: {325, 327},\n",
       "             214: {3, 14},\n",
       "             215: {284, 373},\n",
       "             216: {374, 514},\n",
       "             217: {181, 286},\n",
       "             218: {12, 340},\n",
       "             219: {285, 490},\n",
       "             220: {314, 861},\n",
       "             221: {251, 252},\n",
       "             222: {254, 378},\n",
       "             223: {361, 956},\n",
       "             224: {142, 565},\n",
       "             225: {445, 446},\n",
       "             226: {415, 446},\n",
       "             227: {125, 608},\n",
       "             228: {325, 326},\n",
       "             229: {326, 327},\n",
       "             230: {313, 351},\n",
       "             231: {185, 253},\n",
       "             232: {184, 776},\n",
       "             233: {291, 833},\n",
       "             234: {211, 495},\n",
       "             235: {218, 354},\n",
       "             236: {218, 771},\n",
       "             237: {14, 310},\n",
       "             238: {288, 368},\n",
       "             239: {365, 393},\n",
       "             240: {337, 681},\n",
       "             241: {414, 444},\n",
       "             242: {284, 373},\n",
       "             243: {312, 907},\n",
       "             244: {328, 506},\n",
       "             245: {218, 354},\n",
       "             246: {218, 354},\n",
       "             247: {326, 327},\n",
       "             248: {180, 452},\n",
       "             249: {325, 327},\n",
       "             250: {140, 335},\n",
       "             251: {415, 444},\n",
       "             252: {350, 881},\n",
       "             253: {446, 459},\n",
       "             254: {261, 262},\n",
       "             255: {353, 868},\n",
       "             256: {300, 638},\n",
       "             257: {313, 351},\n",
       "             258: {206, 487},\n",
       "             259: {220, 1034},\n",
       "             260: {265, 435},\n",
       "             261: {336, 496},\n",
       "             262: {216, 391},\n",
       "             263: {492, 1044},\n",
       "             264: {116, 143},\n",
       "             265: {364, 434},\n",
       "             266: {340, 345},\n",
       "             267: {348, 349},\n",
       "             268: {345, 347},\n",
       "             269: {348, 349},\n",
       "             270: {344, 345},\n",
       "             271: {376, 377},\n",
       "             272: {376, 378},\n",
       "             273: {363, 964},\n",
       "             274: {399, 554},\n",
       "             275: {203, 867},\n",
       "             276: {305, 470},\n",
       "             277: {520, 914},\n",
       "             278: {337, 379},\n",
       "             279: {301, 637},\n",
       "             280: {302, 608},\n",
       "             281: {280, 700},\n",
       "             282: {114, 458},\n",
       "             283: {532, 533},\n",
       "             284: {121, 528},\n",
       "             285: {277, 302},\n",
       "             286: {323, 761},\n",
       "             287: {380, 429},\n",
       "             288: {9, 341},\n",
       "             289: {344, 345},\n",
       "             290: {142, 984},\n",
       "             291: {200, 387},\n",
       "             292: {99, 100},\n",
       "             293: {147, 489},\n",
       "             294: {468, 862},\n",
       "             295: {171, 172},\n",
       "             296: {376, 377},\n",
       "             297: {424, 426},\n",
       "             298: {423, 424},\n",
       "             299: {423, 424},\n",
       "             300: {251, 375},\n",
       "             301: {765, 1065},\n",
       "             302: {424, 426},\n",
       "             303: {498, 722},\n",
       "             304: {917, 985},\n",
       "             305: {398, 427},\n",
       "             306: {118, 751},\n",
       "             307: {119, 389},\n",
       "             308: {345, 346},\n",
       "             309: {434, 956},\n",
       "             310: {210, 401},\n",
       "             311: {474, 1015},\n",
       "             312: {369, 388},\n",
       "             313: {739, 1035},\n",
       "             314: {416, 417},\n",
       "             315: {416, 417},\n",
       "             316: {711, 796},\n",
       "             317: {40, 306},\n",
       "             318: {712, 995},\n",
       "             319: {201, 476},\n",
       "             320: {244, 396},\n",
       "             321: {381, 479},\n",
       "             322: {156, 474},\n",
       "             323: {339, 528},\n",
       "             324: {567, 1076},\n",
       "             325: {401, 564},\n",
       "             326: {431, 1016},\n",
       "             327: {984, 985},\n",
       "             328: {299, 571},\n",
       "             329: {57, 179},\n",
       "             330: {385, 389},\n",
       "             331: {149, 386},\n",
       "             332: {119, 389},\n",
       "             333: {460, 757},\n",
       "             334: {756, 757},\n",
       "             335: {570, 1036},\n",
       "             336: {25, 392},\n",
       "             337: {617, 700},\n",
       "             338: {329, 332},\n",
       "             339: {40, 406},\n",
       "             340: {407, 671},\n",
       "             341: {410, 961},\n",
       "             342: {418, 419},\n",
       "             343: {381, 448},\n",
       "             344: {81, 110},\n",
       "             345: {418, 419},\n",
       "             346: {436, 834},\n",
       "             347: {441, 531},\n",
       "             348: {408, 980},\n",
       "             349: {740, 1046},\n",
       "             350: {444, 851},\n",
       "             351: {205, 408},\n",
       "             352: {63, 293},\n",
       "             353: {433, 671},\n",
       "             354: {276, 384},\n",
       "             355: {860, 861},\n",
       "             356: {860, 861},\n",
       "             357: {432, 677},\n",
       "             358: {169, 1082},\n",
       "             359: {308, 310},\n",
       "             360: {355, 358},\n",
       "             361: {477, 531},\n",
       "             362: {620, 749},\n",
       "             363: {409, 831},\n",
       "             364: {336, 443},\n",
       "             365: {11, 273},\n",
       "             366: {225, 488},\n",
       "             367: {466, 467},\n",
       "             368: {465, 467},\n",
       "             369: {256, 464},\n",
       "             370: {586, 846},\n",
       "             371: {289, 833},\n",
       "             372: {75, 174},\n",
       "             373: {181, 1037},\n",
       "             374: {331, 338},\n",
       "             375: {48, 1079},\n",
       "             376: {331, 338},\n",
       "             377: {7, 95},\n",
       "             378: {532, 533},\n",
       "             379: {1024, 1038},\n",
       "             380: {282, 397},\n",
       "             381: {465, 467},\n",
       "             382: {299, 571},\n",
       "             383: {483, 1027},\n",
       "             384: {49, 438},\n",
       "             385: {104, 251},\n",
       "             386: {104, 353},\n",
       "             387: {251, 376},\n",
       "             388: {353, 782, 783, 784, 785, 786},\n",
       "             389: {104, 613},\n",
       "             390: {284, 393},\n",
       "             391: {261, 262},\n",
       "             392: {964, 1050},\n",
       "             393: {364, 434},\n",
       "             394: {595, 848},\n",
       "             395: {188, 802},\n",
       "             396: {423, 426},\n",
       "             397: {288, 518},\n",
       "             398: {281, 420},\n",
       "             399: {92, 157},\n",
       "             400: {461, 515},\n",
       "             401: {242, 384},\n",
       "             402: {400, 682},\n",
       "             403: {104, 645},\n",
       "             404: {552, 628},\n",
       "             405: {552, 628},\n",
       "             406: {487, 503},\n",
       "             407: {24, 25},\n",
       "             408: {462, 887},\n",
       "             409: {95, 96},\n",
       "             410: {431, 645},\n",
       "             411: {645, 1016},\n",
       "             412: {180, 452},\n",
       "             413: {855, 1035},\n",
       "             414: {741, 755},\n",
       "             415: {276, 384},\n",
       "             416: {168, 324},\n",
       "             417: {324, 1082},\n",
       "             418: {168, 324},\n",
       "             419: {324, 1082},\n",
       "             420: {209, 303},\n",
       "             421: {209, 395},\n",
       "             422: {352, 1063},\n",
       "             423: {749, 751},\n",
       "             424: {579, 751},\n",
       "             425: {242, 384},\n",
       "             426: {42, 287},\n",
       "             427: {460, 757},\n",
       "             428: {513, 546},\n",
       "             429: {226, 1084},\n",
       "             430: {31, 443},\n",
       "             431: {159, 310},\n",
       "             432: {272, 583},\n",
       "             433: {86, 271},\n",
       "             434: {86, 97},\n",
       "             435: {2, 13},\n",
       "             436: {740, 755},\n",
       "             437: {750, 755},\n",
       "             438: {740, 755},\n",
       "             439: {579, 674},\n",
       "             440: {510, 554},\n",
       "             441: {227, 493},\n",
       "             442: {117, 580},\n",
       "             443: {581, 1025},\n",
       "             444: {573, 630},\n",
       "             445: {573, 630},\n",
       "             446: {312, 907},\n",
       "             447: {411, 412},\n",
       "             448: {908, 1000},\n",
       "             449: {479, 754},\n",
       "             450: {506, 1071},\n",
       "             451: {408, 980},\n",
       "             452: {475, 507},\n",
       "             453: {448, 505},\n",
       "             454: {437, 449},\n",
       "             455: {506, 511},\n",
       "             456: {510, 542},\n",
       "             457: {508, 509},\n",
       "             458: {508, 509},\n",
       "             459: {276, 482},\n",
       "             460: {575, 970},\n",
       "             461: {327, 876},\n",
       "             462: {11, 273},\n",
       "             463: {684, 711},\n",
       "             464: {576, 721},\n",
       "             465: {602, 603},\n",
       "             466: {197, 577},\n",
       "             467: {602, 603},\n",
       "             468: {603, 604},\n",
       "             469: {578, 1022},\n",
       "             470: {579, 674},\n",
       "             471: {673, 684},\n",
       "             472: {673, 684},\n",
       "             473: {603, 742},\n",
       "             474: {1007, 1066},\n",
       "             475: {1045, 1084},\n",
       "             476: {631, 992},\n",
       "             477: {791, 844},\n",
       "             478: {437, 449},\n",
       "             479: {792, 880},\n",
       "             480: {792, 880},\n",
       "             481: {791, 844},\n",
       "             482: {793, 926},\n",
       "             483: {793, 926},\n",
       "             484: {609, 935},\n",
       "             485: {409, 551},\n",
       "             486: {542, 544},\n",
       "             487: {542, 544},\n",
       "             488: {228, 494},\n",
       "             489: {541, 961},\n",
       "             490: {20, 403},\n",
       "             491: {192, 655},\n",
       "             492: {296, 343},\n",
       "             493: {529, 530},\n",
       "             494: {529, 530},\n",
       "             495: {629, 849},\n",
       "             496: {560, 563},\n",
       "             497: {350, 881},\n",
       "             498: {556, 561},\n",
       "             499: {560, 563},\n",
       "             500: {562, 843},\n",
       "             501: {556, 561},\n",
       "             502: {553, 840},\n",
       "             503: {557, 560},\n",
       "             504: {559, 843},\n",
       "             505: {558, 878},\n",
       "             506: {296, 343},\n",
       "             507: {557, 610},\n",
       "             508: {558, 612},\n",
       "             509: {593, 665},\n",
       "             510: {591, 592},\n",
       "             511: {664, 665},\n",
       "             512: {924, 1071},\n",
       "             513: {548, 832},\n",
       "             514: {547, 579},\n",
       "             515: {548, 549},\n",
       "             516: {591, 592},\n",
       "             517: {405, 468},\n",
       "             518: {404, 962},\n",
       "             519: {535, 538},\n",
       "             520: {535, 536},\n",
       "             521: {535, 536},\n",
       "             522: {367, 537},\n",
       "             523: {592, 600},\n",
       "             524: {512, 663},\n",
       "             525: {513, 546},\n",
       "             526: {468, 862},\n",
       "             527: {738, 806},\n",
       "             528: {709, 879},\n",
       "             529: {709, 879},\n",
       "             530: {709, 879},\n",
       "             531: {709, 879},\n",
       "             532: {709, 879},\n",
       "             533: {515, 626},\n",
       "             534: {461, 515},\n",
       "             535: {635, 639},\n",
       "             536: {439, 1048},\n",
       "             537: {642, 756},\n",
       "             538: {483, 1027},\n",
       "             539: {258, 644},\n",
       "             540: {590, 923},\n",
       "             541: {725, 737},\n",
       "             542: {738, 806},\n",
       "             543: {758, 864},\n",
       "             544: {549, 716},\n",
       "             545: {717, 759},\n",
       "             546: {717, 759},\n",
       "             547: {593, 665},\n",
       "             548: {44, 595},\n",
       "             549: {327, 875},\n",
       "             550: {21, 594},\n",
       "             551: {872, 873},\n",
       "             552: {279, 599},\n",
       "             553: {350, 598},\n",
       "             554: {243, 502},\n",
       "             555: {411, 412},\n",
       "             556: {597, 1012},\n",
       "             557: {315, 596},\n",
       "             558: {566, 969},\n",
       "             559: {683, 878},\n",
       "             560: {512, 589},\n",
       "             561: {760, 761},\n",
       "             562: {764, 907},\n",
       "             563: {723, 764},\n",
       "             564: {764, 982},\n",
       "             565: {753, 982},\n",
       "             566: {647, 666},\n",
       "             567: {649, 657},\n",
       "             568: {666, 728},\n",
       "             569: {646, 714},\n",
       "             570: {649, 657},\n",
       "             571: {512, 743},\n",
       "             572: {646, 658},\n",
       "             573: {374, 710},\n",
       "             574: {462, 582},\n",
       "             575: {498, 585},\n",
       "             576: {653, 654},\n",
       "             577: {653, 654},\n",
       "             578: {730, 1060},\n",
       "             579: {693, 694},\n",
       "             580: {680, 698},\n",
       "             581: {675, 1083},\n",
       "             582: {668, 746},\n",
       "             583: {660, 971},\n",
       "             584: {651, 668},\n",
       "             585: {263, 264},\n",
       "             586: {617, 618},\n",
       "             587: {229, 230},\n",
       "             588: {230, 231},\n",
       "             589: {229, 230},\n",
       "             590: {656, 692},\n",
       "             591: {690, 971},\n",
       "             592: {691, 920},\n",
       "             593: {131, 615},\n",
       "             594: {515, 516},\n",
       "             595: {584, 606},\n",
       "             596: {584, 606},\n",
       "             597: {289, 833},\n",
       "             598: {121, 528},\n",
       "             599: {114, 518},\n",
       "             600: {440, 498},\n",
       "             601: {836, 895},\n",
       "             602: {1020, 1065},\n",
       "             603: {1045, 1084},\n",
       "             604: {320, 325},\n",
       "             605: {144, 876},\n",
       "             606: {212, 524},\n",
       "             607: {572, 1057},\n",
       "             608: {686, 695},\n",
       "             609: {680, 698},\n",
       "             610: {576, 721},\n",
       "             611: {686, 695},\n",
       "             612: {448, 616},\n",
       "             613: {491, 729},\n",
       "             614: {636, 637},\n",
       "             615: {636, 637},\n",
       "             616: {486, 487},\n",
       "             617: {697, 719},\n",
       "             618: {697, 719},\n",
       "             619: {351, 863},\n",
       "             620: {663, 667},\n",
       "             621: {195, 652},\n",
       "             622: {527, 824},\n",
       "             623: {574, 586},\n",
       "             624: {628, 1069},\n",
       "             625: {760, 761},\n",
       "             626: {471, 472},\n",
       "             627: {471, 472},\n",
       "             628: {471, 473},\n",
       "             629: {872, 873},\n",
       "             630: {141, 568},\n",
       "             631: {758, 864},\n",
       "             632: {565, 977},\n",
       "             633: {1024, 1038},\n",
       "             634: {525, 877},\n",
       "             635: {663, 667},\n",
       "             636: {734, 849},\n",
       "             637: {706, 708},\n",
       "             638: {840, 882},\n",
       "             639: {381, 479},\n",
       "             640: {706, 708},\n",
       "             641: {706, 708},\n",
       "             642: {234, 360},\n",
       "             643: {634, 635},\n",
       "             644: {635, 637},\n",
       "             645: {722, 888},\n",
       "             646: {1033, 1034},\n",
       "             647: {1033, 1034},\n",
       "             648: {434, 458},\n",
       "             649: {714, 999},\n",
       "             650: {666, 728},\n",
       "             651: {838, 884},\n",
       "             652: {838, 901},\n",
       "             653: {838, 842},\n",
       "             654: {561, 683},\n",
       "             655: {487, 504},\n",
       "             656: {643, 809},\n",
       "             657: {632, 637},\n",
       "             658: {670, 672},\n",
       "             659: {435, 672},\n",
       "             660: {433, 671},\n",
       "             661: {669, 1015},\n",
       "             662: {621, 669},\n",
       "             663: {87, 255},\n",
       "             664: {632, 633},\n",
       "             665: {638, 640},\n",
       "             666: {649, 731},\n",
       "             667: {232, 366},\n",
       "             668: {831, 950},\n",
       "             669: {587, 588},\n",
       "             670: {545, 677},\n",
       "             671: {676, 816},\n",
       "             672: {210, 909},\n",
       "             673: {782, 783, 784, 785, 786},\n",
       "             674: {694, 983},\n",
       "             675: {680, 834},\n",
       "             676: {757, 776},\n",
       "             677: {839, 890},\n",
       "             678: {679, 685},\n",
       "             679: {720, 930},\n",
       "             680: {840, 891},\n",
       "             681: {720, 930},\n",
       "             682: {890, 892},\n",
       "             683: {893, 900},\n",
       "             684: {893, 900},\n",
       "             685: {651, 732},\n",
       "             686: {837, 1061},\n",
       "             687: {574, 846},\n",
       "             688: {617, 618},\n",
       "             689: {347, 614},\n",
       "             690: {345, 347},\n",
       "             691: {252, 782, 783, 784, 785, 786},\n",
       "             692: {252, 782, 783, 784, 785, 786},\n",
       "             693: {772, 774},\n",
       "             694: {722, 888},\n",
       "             695: {744, 805},\n",
       "             696: {771, 774},\n",
       "             697: {141, 950},\n",
       "             698: {771, 950},\n",
       "             699: {771, 774},\n",
       "             700: {434, 555},\n",
       "             701: {253, 865},\n",
       "             702: {347, 780},\n",
       "             703: {347, 645},\n",
       "             704: {345, 347},\n",
       "             705: {282, 733},\n",
       "             706: {865, 981},\n",
       "             707: {841, 896},\n",
       "             708: {730, 886},\n",
       "             709: {840, 891},\n",
       "             710: {668, 746},\n",
       "             711: {787, 788, 789},\n",
       "             712: {614, 787, 788, 789},\n",
       "             713: {650, 699},\n",
       "             714: {782, 783, 784, 785, 786},\n",
       "             715: {650, 699},\n",
       "             716: {378, 799},\n",
       "             717: {376, 378},\n",
       "             718: {799, 800, 801},\n",
       "             719: {799, 800, 801},\n",
       "             720: {217, 774},\n",
       "             721: {649, 894},\n",
       "             722: {774, 799},\n",
       "             723: {836, 895},\n",
       "             724: {725, 737},\n",
       "             725: {377, 687},\n",
       "             726: {94, 150},\n",
       "             727: {257, 659},\n",
       "             728: {90, 92},\n",
       "             729: {327, 876},\n",
       "             730: {251, 1020},\n",
       "             731: {159, 626},\n",
       "             732: {775, 776},\n",
       "             733: {462, 887},\n",
       "             734: {775, 776},\n",
       "             735: {775, 776},\n",
       "             736: {885, 1076},\n",
       "             737: {666, 889},\n",
       "             738: {441, 835},\n",
       "             739: {624, 625},\n",
       "             740: {839, 890},\n",
       "             741: {893, 1021},\n",
       "             742: {76, 213},\n",
       "             743: {157, 343},\n",
       "             744: {899, 1041},\n",
       "             745: {747, 752},\n",
       "             746: {747, 752},\n",
       "             747: {727, 1022},\n",
       "             748: {609, 648},\n",
       "             749: {638, 640},\n",
       "             750: {72, 828},\n",
       "             751: {841, 896},\n",
       "             752: {838, 901},\n",
       "             753: {898, 901},\n",
       "             754: {548, 832},\n",
       "             755: {559, 843},\n",
       "             756: {514, 741},\n",
       "             757: {611, 891},\n",
       "             758: {45, 90},\n",
       "             759: {350, 912},\n",
       "             760: {469, 534},\n",
       "             761: {531, 1019},\n",
       "             762: {51, 69},\n",
       "             763: {830, 958},\n",
       "             764: {301, 641},\n",
       "             765: {1044, 1047},\n",
       "             766: {275, 539},\n",
       "             767: {691, 805},\n",
       "             768: {614, 841},\n",
       "             769: {622, 625},\n",
       "             770: {624, 625},\n",
       "             771: {764, 831},\n",
       "             772: {401, 797},\n",
       "             773: {807, 808},\n",
       "             774: {807, 808},\n",
       "             775: {805, 914},\n",
       "             776: {985, 1073},\n",
       "             777: {580, 883},\n",
       "             778: {6, 541},\n",
       "             779: {105, 655},\n",
       "             780: {8, 480},\n",
       "             781: {391, 748},\n",
       "             782: {328, 956},\n",
       "             783: {290, 884},\n",
       "             784: {255, 810},\n",
       "             785: {435, 672},\n",
       "             786: {830, 958},\n",
       "             787: {143, 390},\n",
       "             788: {582, 627},\n",
       "             789: {514, 517},\n",
       "             790: {574, 605},\n",
       "             791: {292, 364},\n",
       "             792: {722, 902},\n",
       "             793: {130, 1049},\n",
       "             794: {821, 823},\n",
       "             795: {821, 823},\n",
       "             796: {259, 336},\n",
       "             797: {236, 259},\n",
       "             798: {64, 152},\n",
       "             799: {166, 1049},\n",
       "             800: {67, 926},\n",
       "             801: {66, 259},\n",
       "             802: {591, 925},\n",
       "             803: {693, 694},\n",
       "             804: {695, 696},\n",
       "             805: {964, 1049},\n",
       "             806: {421, 1049},\n",
       "             807: {236, 790},\n",
       "             808: {60, 336},\n",
       "             809: {469, 534},\n",
       "             810: {221, 469},\n",
       "             811: {904, 1025},\n",
       "             812: {417, 903},\n",
       "             813: {200, 1070},\n",
       "             814: {702, 704},\n",
       "             815: {32, 704},\n",
       "             816: {703, 840},\n",
       "             817: {703, 840},\n",
       "             818: {803, 804},\n",
       "             819: {803, 804},\n",
       "             820: {578, 702},\n",
       "             821: {701, 732},\n",
       "             822: {469, 718},\n",
       "             823: {15, 95},\n",
       "             824: {490, 529},\n",
       "             825: {831, 907},\n",
       "             826: {19, 962},\n",
       "             827: {5, 315},\n",
       "             828: {403, 950},\n",
       "             829: {691, 920},\n",
       "             830: {519, 833},\n",
       "             831: {730, 924},\n",
       "             832: {49, 381},\n",
       "             833: {850, 851},\n",
       "             834: {171, 172},\n",
       "             835: {682, 951},\n",
       "             836: {855, 1069},\n",
       "             837: {333, 519},\n",
       "             838: {814, 821},\n",
       "             839: {814, 824},\n",
       "             840: {816, 820},\n",
       "             841: {913, 933},\n",
       "             842: {819, 821},\n",
       "             843: {814, 823},\n",
       "             844: {821, 823},\n",
       "             845: {825, 826},\n",
       "             846: {825, 826},\n",
       "             847: {915, 999},\n",
       "             848: {825, 826},\n",
       "             849: {649, 916},\n",
       "             850: {825, 826},\n",
       "             851: {816, 820},\n",
       "             852: {826, 827},\n",
       "             853: {668, 971},\n",
       "             854: {369, 388},\n",
       "             855: {989, 1061},\n",
       "             856: {1060, 1061},\n",
       "             857: {597, 1012},\n",
       "             858: {843, 1026},\n",
       "             859: {904, 1025},\n",
       "             860: {857, 913},\n",
       "             861: {857, 858},\n",
       "             862: {732, 1040},\n",
       "             863: {430, 503},\n",
       "             864: {430, 503},\n",
       "             865: {935, 937},\n",
       "             866: {936, 938},\n",
       "             867: {1001, 1068},\n",
       "             868: {936, 938},\n",
       "             869: {859, 990},\n",
       "             870: {104, 109},\n",
       "             871: {309, 794},\n",
       "             872: {496, 608},\n",
       "             873: {989, 1060},\n",
       "             874: {935, 937},\n",
       "             875: {989, 1061},\n",
       "             876: {908, 931},\n",
       "             877: {646, 988},\n",
       "             878: {1035, 1062},\n",
       "             879: {885, 1076},\n",
       "             880: {850, 851},\n",
       "             881: {576, 1077},\n",
       "             882: {910, 1006},\n",
       "             883: {736, 911},\n",
       "             884: {853, 1091},\n",
       "             885: {587, 588},\n",
       "             886: {117, 883},\n",
       "             887: {269, 604},\n",
       "             888: {537, 979},\n",
       "             889: {585, 978},\n",
       "             890: {540, 968},\n",
       "             891: {501, 534},\n",
       "             892: {730, 1063},\n",
       "             893: {434, 906},\n",
       "             894: {590, 923},\n",
       "             895: {944, 945},\n",
       "             896: {943, 945},\n",
       "             897: {944, 945},\n",
       "             898: {1020, 1065},\n",
       "             899: {946, 1082},\n",
       "             900: {732, 1070},\n",
       "             901: {542, 960},\n",
       "             902: {544, 960},\n",
       "             903: {544, 961},\n",
       "             904: {491, 932},\n",
       "             905: {966, 967},\n",
       "             906: {966, 967},\n",
       "             907: {946, 1082},\n",
       "             908: {592, 922},\n",
       "             909: {585, 973},\n",
       "             910: {129, 972},\n",
       "             911: {1002, 1015},\n",
       "             912: {1002, 1016},\n",
       "             913: {1002, 1015},\n",
       "             914: {1004, 1015},\n",
       "             915: {1005, 1015},\n",
       "             916: {1004, 1006},\n",
       "             917: {1005, 1007},\n",
       "             918: {1002, 1011},\n",
       "             919: {1008, 1010},\n",
       "             920: {1002, 1010},\n",
       "             921: {1003, 1009},\n",
       "             922: {1003, 1009},\n",
       "             923: {995, 1011},\n",
       "             924: {174, 959},\n",
       "             925: {579, 1051},\n",
       "             926: {540, 968},\n",
       "             927: {974, 992},\n",
       "             928: {840, 940},\n",
       "             929: {565, 977},\n",
       "             930: {977, 987},\n",
       "             931: {1029, 1031},\n",
       "             932: {1029, 1030},\n",
       "             933: {1029, 1030},\n",
       "             934: {1029, 1030},\n",
       "             935: {990, 1031},\n",
       "             936: {159, 681},\n",
       "             937: {758, 929},\n",
       "             938: {566, 969},\n",
       "             939: {151, 889},\n",
       "             940: {1017, 1018},\n",
       "             941: {1017, 1018},\n",
       "             942: {732, 949},\n",
       "             943: {628, 1028},\n",
       "             944: {954, 955},\n",
       "             945: {657, 955},\n",
       "             946: {991, 994},\n",
       "             947: {991, 994},\n",
       "             948: {993, 1000},\n",
       "             949: {993, 1000},\n",
       "             950: {428, 500},\n",
       "             951: {187, 500},\n",
       "             952: {187, 500},\n",
       "             953: {428, 745},\n",
       "             954: {309, 794},\n",
       "             955: {913, 971},\n",
       "             956: {428, 500},\n",
       "             957: {830, 958},\n",
       "             958: {2, 13},\n",
       "             959: {312, 927},\n",
       "             960: {84, 1050},\n",
       "             961: {84, 87},\n",
       "             962: {87, 965},\n",
       "             963: {64, 84},\n",
       "             964: {537, 934},\n",
       "             965: {160, 688},\n",
       "             966: {1004, 1068},\n",
       "             967: {835, 1056},\n",
       "             968: {4, 359},\n",
       "             969: {492, 1044},\n",
       "             970: {400, 682},\n",
       "             971: {808, 957},\n",
       "             972: {400, 678},\n",
       "             973: {367, 696},\n",
       "             974: {976, 1080},\n",
       "             975: {975, 976},\n",
       "             976: {975, 976},\n",
       "             977: {96, 402},\n",
       "             978: {421, 1049},\n",
       "             979: {881, 1057},\n",
       "             980: {1037, 1067},\n",
       "             981: {1052, 1067},\n",
       "             982: {1052, 1067},\n",
       "             983: {940, 941},\n",
       "             984: {337, 1039},\n",
       "             985: {607, 619},\n",
       "             986: {649, 916},\n",
       "             987: {654, 992},\n",
       "             988: {1015, 1022},\n",
       "             989: {506, 1071},\n",
       "             990: {970, 1041},\n",
       "             991: {590, 601},\n",
       "             992: {953, 954},\n",
       "             993: {105, 249},\n",
       "             994: {933, 1009},\n",
       "             995: {531, 1019},\n",
       "             996: {836, 1040},\n",
       "             997: {543, 544},\n",
       "             998: {487, 1013},\n",
       "             999: {637, 1075},\n",
       "             ...})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_top_1_TEST(neib[0], neib[1], test_df, left_index, right_index, k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_top_1_TEST(dists: np.array, \n",
    "                   neibs: np.array, \n",
    "                   supervision: pd.DataFrame,\n",
    "                   left_indexing: np.array,\n",
    "                   right_indexing: np.array, k):\n",
    "    neibs = right_indexing[neibs]\n",
    "    if k is not None:\n",
    "        l, r = np.where(dists <= np.max(dists[:,:k], axis=1)[:,None]) ## to get all equidistant mins\n",
    "    else:\n",
    "        l, r = np.where(dists <= thresh) \n",
    "    \n",
    "    top_index = defaultdict(set)\n",
    "    for i,j in zip(l,r):\n",
    "        top_index[i].add(neibs[i,j])\n",
    "    \n",
    "    predicted = []\n",
    "    supervision = supervision.to_numpy()\n",
    "    true = supervision[:,2]\n",
    "    for left, right, label in supervision:\n",
    "        if right in top_index[left]:\n",
    "            predicted += [1]\n",
    "        else:\n",
    "            predicted += [0]\n",
    "    return top_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_IMDB_wiki_recall(dists: np.array,\n",
    "                         neibs: np.array,\n",
    "                         supervision: pd.DataFrame,\n",
    "                         left_indexing: np.array,\n",
    "                         right_indexing: np.array,\n",
    "                         k: int = None,\n",
    "                         thresh: float = None):\n",
    "    supervision = supervision.set_index('IMDB_ID')\n",
    "    mode = \"QID\"\n",
    "    if k is not None:\n",
    "        neibs = right_indexing[neibs[:,:k]]\n",
    "    else:\n",
    "        pass # TODO\n",
    "    results = []\n",
    "    MRR_results = []\n",
    "    for idx, row in enumerate(neibs):\n",
    "        match = 0\n",
    "        mrr = 0\n",
    "        \n",
    "        qid = left_indexing[idx]\n",
    "        true_match = supervision.loc[qid][mode]\n",
    "        for entry in row: \n",
    "            mrr += 1.\n",
    "            if entry == true_match:\n",
    "                match = 1\n",
    "                break\n",
    "        results.append(match)\n",
    "        MRR_results.append(match/mrr)\n",
    "    return np.mean(results), np.sum(results), np.mean(MRR_results), results, MRR_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_exp_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">swept-morning-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/company_exp_data-uncased-masked-ALL-BM25-67596\" target=\"_blank\">https://wandb.ai/sahaana/company_exp_data-uncased-masked-ALL-BM25-67596</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/company_exp_data-uncased-masked-ALL-BM25-67596/runs/1yjncs31\" target=\"_blank\">https://wandb.ai/sahaana/company_exp_data-uncased-masked-ALL-BM25-67596/runs/1yjncs31</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_134224-1yjncs31</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_exp_data\n",
      "precision, recall, F1, support: (0.9941223617419183, 0.6597517730496454, 0.7931365234999467, None)\n",
      "\n",
      "\n",
      "\n",
      "dblp_acm_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1yjncs31) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3285<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_134224-1yjncs31/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_134224-1yjncs31/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>8450</td></tr><tr><td>_runtime</td><td>4337</td></tr><tr><td>_timestamp</td><td>1612997681</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>▂█▂▃▁▂▃▁▁▄▄▁▁▁▂▁▄▁▂▂▁▃▃▁▁▂▁▁▁▃▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">swept-morning-4</strong>: <a href=\"https://wandb.ai/sahaana/company_exp_data-uncased-masked-ALL-BM25-67596/runs/1yjncs31\" target=\"_blank\">https://wandb.ai/sahaana/company_exp_data-uncased-masked-ALL-BM25-67596/runs/1yjncs31</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1yjncs31). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wandering-galaxy-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/dblp_acm_exp_data-uncased-masked-ALL-BM25-7417\" target=\"_blank\">https://wandb.ai/sahaana/dblp_acm_exp_data-uncased-masked-ALL-BM25-7417</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/vzqqykss\" target=\"_blank\">https://wandb.ai/sahaana/dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/vzqqykss</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_150226-vzqqykss</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dblp_acm_exp_data\n",
      "precision, recall, F1, support: (0.9608695652173913, 0.9954954954954955, 0.9778761061946903, None)\n",
      "\n",
      "\n",
      "\n",
      "dblp_scholar_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:vzqqykss) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5127<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_150226-vzqqykss/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_150226-vzqqykss/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>928</td></tr><tr><td>_runtime</td><td>111</td></tr><tr><td>_timestamp</td><td>1612998260</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>█▁▁▁▁▁▃▁▁▁▁▁▂▄▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wandering-galaxy-2</strong>: <a href=\"https://wandb.ai/sahaana/dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/vzqqykss\" target=\"_blank\">https://wandb.ai/sahaana/dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/vzqqykss</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:vzqqykss). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">pleasant-pyramid-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223\" target=\"_blank\">https://wandb.ai/sahaana/dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/s0l4n9as\" target=\"_blank\">https://wandb.ai/sahaana/dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/s0l4n9as</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_150436-s0l4n9as</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dblp_scholar_exp_data\n",
      "precision, recall, F1, support: (0.9459459459459459, 0.4252336448598131, 0.5867182462927143, None)\n",
      "\n",
      "\n",
      "\n",
      "dirty_dblp_acm_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:s0l4n9as) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5450<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_150436-s0l4n9as/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_150436-s0l4n9as/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>2153</td></tr><tr><td>_runtime</td><td>246</td></tr><tr><td>_timestamp</td><td>1612998525</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>█▅█▂▁▁▅▁▃▂▁▁▁▁▁▁▁▁▇▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▅▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">pleasant-pyramid-2</strong>: <a href=\"https://wandb.ai/sahaana/dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/s0l4n9as\" target=\"_blank\">https://wandb.ai/sahaana/dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/s0l4n9as</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:s0l4n9as). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lucky-forest-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-7417\" target=\"_blank\">https://wandb.ai/sahaana/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-7417</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/3qspxhmn\" target=\"_blank\">https://wandb.ai/sahaana/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/3qspxhmn</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_151107-3qspxhmn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirty_dblp_acm_exp_data\n",
      "precision, recall, F1, support: (0.9648351648351648, 0.9887387387387387, 0.9766407119021134, None)\n",
      "\n",
      "\n",
      "\n",
      "dirty_dblp_scholar_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3qspxhmn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5866<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_151107-3qspxhmn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_151107-3qspxhmn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>928</td></tr><tr><td>_runtime</td><td>115</td></tr><tr><td>_timestamp</td><td>1612998786</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>█▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lucky-forest-2</strong>: <a href=\"https://wandb.ai/sahaana/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/3qspxhmn\" target=\"_blank\">https://wandb.ai/sahaana/dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-7417/runs/3qspxhmn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3qspxhmn). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fresh-hill-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223\" target=\"_blank\">https://wandb.ai/sahaana/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/1sbchq8w\" target=\"_blank\">https://wandb.ai/sahaana/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/1sbchq8w</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_151322-1sbchq8w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirty_dblp_scholar_exp_data\n",
      "precision, recall, F1, support: (0.9481327800829875, 0.42710280373831777, 0.5889175257731959, None)\n",
      "\n",
      "\n",
      "\n",
      "dirty_itunes_amazon_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1sbchq8w) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6013<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_151322-1sbchq8w/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_151322-1sbchq8w/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>2153</td></tr><tr><td>_runtime</td><td>252</td></tr><tr><td>_timestamp</td><td>1612999058</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>▇▃█▃▁█▅▂▂▂▂▃▅▁▁▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▆▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fresh-hill-2</strong>: <a href=\"https://wandb.ai/sahaana/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/1sbchq8w\" target=\"_blank\">https://wandb.ai/sahaana/dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-17223/runs/1sbchq8w</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1sbchq8w). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">comic-dream-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-321\" target=\"_blank\">https://wandb.ai/sahaana/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-321</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/1nex5u3l\" target=\"_blank\">https://wandb.ai/sahaana/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/1nex5u3l</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152006-1nex5u3l</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirty_itunes_amazon_exp_data\n",
      "precision, recall, F1, support: (1.0, 0.2222222222222222, 0.3636363636363636, None)\n",
      "\n",
      "\n",
      "\n",
      "dirty_walmart_amazon_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1nex5u3l) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6193<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152006-1nex5u3l/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152006-1nex5u3l/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>41</td></tr><tr><td>_runtime</td><td>13</td></tr><tr><td>_timestamp</td><td>1612999223</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>█▇▆▇▅▇▁▁▁▂▁▁▂▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▃▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">comic-dream-2</strong>: <a href=\"https://wandb.ai/sahaana/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/1nex5u3l\" target=\"_blank\">https://wandb.ai/sahaana/dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/1nex5u3l</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1nex5u3l). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">clean-paper-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144\" target=\"_blank\">https://wandb.ai/sahaana/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144/runs/8q44zp8e\" target=\"_blank\">https://wandb.ai/sahaana/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144/runs/8q44zp8e</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152246-8q44zp8e</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirty_walmart_amazon_exp_data\n",
      "precision, recall, F1, support: (0.6, 0.7461139896373057, 0.6651270207852193, None)\n",
      "\n",
      "\n",
      "\n",
      "fodors_zagat_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8q44zp8e) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6233<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152246-8q44zp8e/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152246-8q44zp8e/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>768</td></tr><tr><td>_runtime</td><td>95</td></tr><tr><td>_timestamp</td><td>1612999465</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train batch loss</td><td>█▂▃▃▁▅▄▃▅▃▆▃▁▁▃▂▁▁▄▃▁▁▁▁▁▁▂▂▁▁▁▂▂▁▁▁▁▂▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">clean-paper-2</strong>: <a href=\"https://wandb.ai/sahaana/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144/runs/8q44zp8e\" target=\"_blank\">https://wandb.ai/sahaana/dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144/runs/8q44zp8e</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:8q44zp8e). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cerulean-forest-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/fodors_zagat_exp_data-uncased-masked-ALL-BM25-567\" target=\"_blank\">https://wandb.ai/sahaana/fodors_zagat_exp_data-uncased-masked-ALL-BM25-567</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/fodors_zagat_exp_data-uncased-masked-ALL-BM25-567/runs/3db87qla\" target=\"_blank\">https://wandb.ai/sahaana/fodors_zagat_exp_data-uncased-masked-ALL-BM25-567/runs/3db87qla</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152521-3db87qla</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fodors_zagat_exp_data\n",
      "precision, recall, F1, support: (0.7777777777777778, 0.9545454545454546, 0.8571428571428572, None)\n",
      "\n",
      "\n",
      "\n",
      "itunes_amazon_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3db87qla) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6293<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152521-3db87qla/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152521-3db87qla/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>71</td></tr><tr><td>_runtime</td><td>15</td></tr><tr><td>_timestamp</td><td>1612999540</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train batch loss</td><td>█▇▆▃▅▄▃▄▄▅▃▂▂▆▁▅▃▂▃▃▂▃▁▁▁▃▂▁▁▂▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cerulean-forest-2</strong>: <a href=\"https://wandb.ai/sahaana/fodors_zagat_exp_data-uncased-masked-ALL-BM25-567/runs/3db87qla\" target=\"_blank\">https://wandb.ai/sahaana/fodors_zagat_exp_data-uncased-masked-ALL-BM25-567/runs/3db87qla</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3db87qla). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">graceful-fog-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/itunes_amazon_exp_data-uncased-masked-ALL-BM25-321\" target=\"_blank\">https://wandb.ai/sahaana/itunes_amazon_exp_data-uncased-masked-ALL-BM25-321</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/23wm60d2\" target=\"_blank\">https://wandb.ai/sahaana/itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/23wm60d2</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152546-23wm60d2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itunes_amazon_exp_data\n",
      "precision, recall, F1, support: (0.8888888888888888, 0.5925925925925926, 0.711111111111111, None)\n",
      "\n",
      "\n",
      "\n",
      "walmart_amazon_exp_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:23wm60d2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6390<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152546-23wm60d2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152546-23wm60d2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>0</td></tr><tr><td>_step</td><td>41</td></tr><tr><td>_runtime</td><td>12</td></tr><tr><td>_timestamp</td><td>1612999562</td></tr><tr><td>train batch loss</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇███</td></tr><tr><td>train batch loss</td><td>█▁▃▃▂▁▃▁▁▁▂▃▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">graceful-fog-2</strong>: <a href=\"https://wandb.ai/sahaana/itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/23wm60d2\" target=\"_blank\">https://wandb.ai/sahaana/itunes_amazon_exp_data-uncased-masked-ALL-BM25-321/runs/23wm60d2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:23wm60d2). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">curious-mountain-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sahaana/walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144\" target=\"_blank\">https://wandb.ai/sahaana/walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sahaana/walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144/runs/34uyq6zy\" target=\"_blank\">https://wandb.ai/sahaana/walmart_amazon_exp_data-uncased-masked-ALL-BM25-6144/runs/34uyq6zy</a><br/>\n",
       "                Run data is saved locally in <code>/lfs/1/sahaana/enrichment/ember/notebooks/embedding/wandb/run-20210210_152824-34uyq6zy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walmart_amazon_exp_data\n",
      "precision, recall, F1, support: (0.7089201877934272, 0.7823834196891192, 0.7438423645320198, None)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in range(3,13):\n",
    "    print(datasets[d])\n",
    "    left = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/tableA_processed.pkl'\n",
    "    right = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/tableB_processed.pkl'\n",
    "\n",
    "    left = pd.read_pickle(left)\n",
    "    right = pd.read_pickle(right)\n",
    "\n",
    "    train_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/train_updated.csv'\n",
    "    train_df = pd.read_csv(train_df)\n",
    "\n",
    "    val_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/val_updated.csv'\n",
    "    val_df = pd.read_csv(val_df)\n",
    "\n",
    "    test_df = f'/lfs/1/sahaana/enrichment/data/deepmatcher/{datasets[d]}/test_updated.csv'\n",
    "    test_df = pd.read_csv(test_df)\n",
    "\n",
    "    epochs = 1\n",
    "    batch_size = 8\n",
    "    final_size = 200\n",
    "    lr = .00001\n",
    "    tl_margin = 1.0\n",
    "    tl_p = 2\n",
    "    pool_type = \"CLS\"\n",
    "    column = \"merged_all\"\n",
    "    shuffle = True\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    tokenizer_max_length = 512\n",
    "    compute_val = False\n",
    "    train_size = len(train_df)\n",
    "\n",
    "    bert_path=f'/lfs/1/sahaana/enrichment/ember/pretraining/models/{datasets[d]}-uncased-masked-ALL-BM25'\n",
    "    bert_model = DistilBertModel.from_pretrained(bert_path, return_dict=True)\n",
    "\n",
    "    model_name = f'{datasets[d]}-uncased-masked-ALL-BM25-{train_size}'\n",
    "\n",
    "    train_data = DataLoader(DeepMatcherDataset(left, right, train_size, column, train_df), \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle = shuffle\n",
    "                            )\n",
    "\n",
    "    val_data = DataLoader(DeepMatcherDataset(left, right, len(val_df), column, val_df), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "\n",
    "    triplet_loss = nn.TripletMarginLoss(margin=tl_margin, p=tl_p)\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    model = TripletSingleBERTModel(final_size, pool_type, bert_path)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)#optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    save_dir = param_header(batch_size, final_size, lr, pool_type, epochs, train_size)\n",
    "    save_dir = f'models/{model_name}/{save_dir}/'\n",
    "\n",
    "    wandb.init(project=model_name)\n",
    "\n",
    "    train_model(model, \n",
    "                tokenizer, \n",
    "                tokenize_batch, \n",
    "                train_data, \n",
    "                val_data, \n",
    "                triplet_loss, \n",
    "                optimizer, \n",
    "                epochs, \n",
    "                losses, \n",
    "                val_losses, \n",
    "                save_dir, \n",
    "                compute_val, \n",
    "                tokenizer_max_length = tokenizer_max_length)\n",
    "\n",
    "\n",
    "    left_data = DataLoader(EmberEvalDataset(left, column), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "    right_data = DataLoader(EmberEvalDataset(right, column), \n",
    "                           batch_size=batch_size,\n",
    "                           shuffle = False\n",
    "                          )\n",
    "\n",
    "    left_embeddings = eval_model(model, tokenizer, left_data, tokenizer_max_length=512)\n",
    "    right_embeddings = eval_model(model, tokenizer, right_data, tokenizer_max_length=512)\n",
    "\n",
    "    knn = FaissKNeighbors(k=30)\n",
    "    knn.fit(right_embeddings)\n",
    "    neib = knn.kneighbors(left_embeddings)\n",
    "    print(datasets[d])\n",
    "    print(f\"precision, recall, F1, support: {knn_top_1_PRFS(neib[0], neib[1], test_df)}\")\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember_pip",
   "language": "python",
   "name": "ember_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
