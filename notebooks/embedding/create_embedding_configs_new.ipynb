{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = '/lfs/1/sahaana/enrichment/'\n",
    "\n",
    "def save_config(config_path):\n",
    "    with open(config_path, 'w') as fp:\n",
    "        json.dump(config, fp, indent=4)\n",
    "        \n",
    "def load_config(config_path):\n",
    "    with open(config_path) as fp:\n",
    "        config = json.load(fp)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBER all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS MARCO (running with BM25 over the already 25-ed 1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/MSMARCO-uncased-masked-ALL-BM25-single-triplet-{}-1.json\n",
      "python scripts/train_embedding.py -c configs/MSMARCO-uncased-masked-ALL-BM25-single-triplet-{}-1.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/lfs/1/sahaana/enrichment/ember/embedding/configs/MSMARCO-uncased-masked-ALL-BM25-single-triplet-{}-1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-8a468a38fe91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#save_config(config_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-d95f70826683>\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/lfs/1/sahaana/enrichment/ember/embedding/configs/MSMARCO-uncased-masked-ALL-BM25-single-triplet-{}-1.json'"
     ]
    }
   ],
   "source": [
    "data = 'MSMARCO'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/{data}/qidpidtriples.train.full.2.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/MARCO-uncased-masked-ALL-BM25' # change manuaallyyy~\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/100)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508213"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_l'])) + len(pd.read_pickle(config['eval_datapath_l']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17668214"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_r'])) + len(pd.read_pickle(config['eval_datapath_r']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8834107.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17668214/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n",
      "python scripts/train_embedding.py -c configs/SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/train_sent_triplets.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 260004,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/train_sent_triplets.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92695"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_l'])) + len(pd.read_pickle(config['eval_datapath_l']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64549"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_r'])) + len(pd.read_pickle(config['eval_datapath_r']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB_Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n",
      "python scripts/train_embedding.py -c configs/imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 38250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47813"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_l'])) + len(pd.read_pickle(config['eval_datapath_l']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47813"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_r'])) + len(pd.read_pickle(config['eval_datapath_r']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/imdb_wiki-uncased-masked-ALL-BM25-single-triplet-191250-1.json\n",
      "python scripts/train_embedding.py -c configs/imdb_wiki-uncased-masked-ALL-BM25-single-triplet-191250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 191250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'imdb_wiki-uncased-masked-ALL-BM25-single-triplet-191250-1'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_l'])) + len(pd.read_pickle(config['eval_datapath_l']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle(config['datapath_r'])) + len(pd.read_pickle(config['eval_datapath_r']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM_Joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-611-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-631-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-uncased-masked-ALL-BM25-single-triplet-40-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-uncased-masked-ALL-BM25-single-triplet-16859-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-1332-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-1860-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-1332-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-1860-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-78-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-540-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-66-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-78-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-540-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 30\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-9165-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-9465-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-uncased-masked-ALL-BM25-single-triplet-600-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-uncased-masked-ALL-BM25-single-triplet-252885-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-8100-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-990-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-8100-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*15)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-18330-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-18930-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-uncased-masked-ALL-BM25-single-triplet-1200-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-uncased-masked-ALL-BM25-single-triplet-505770-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-39960-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-55800-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-39960-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-55800-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-2340-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-16200-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-1980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-2340-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-16200-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*30)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DM Joined with stratified positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/stratified-joined_abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-9165-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-9465-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_beer_exp_data-uncased-masked-ALL-BM25-single-triplet-600-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_company_exp_data-uncased-masked-ALL-BM25-single-triplet-252885-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-8100-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-990-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-8100-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/stratified_supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*15)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"stratified-{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/stratified-joined_abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-18330-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-18930-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_beer_exp_data-uncased-masked-ALL-BM25-single-triplet-1200-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_company_exp_data-uncased-masked-ALL-BM25-single-triplet-505770-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-39960-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-55800-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-39960-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-55800-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-2340-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-16200-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-1980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-2340-1.json ;\n",
      "python scripts/train_embedding.py -c configs/stratified-joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-16200-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/stratified_supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*30)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"stratified-{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard negatives EMBER (and squad random)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DM Joined with hard negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-9165-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-9465-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_beer_exp_data-uncased-masked-ALL-BM25-single-triplet-600-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_company_exp_data-uncased-masked-ALL-BM25-single-triplet-252885-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-8100-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-990-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-8100-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "    config['negatives'] = path_base + f'data/{data}/{dm_data[i]}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*15)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"hard-negatives-{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_abt_buy_exp_data-uncased-masked-ALL-BM25-single-triplet-18330-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_amazon_google_exp_data-uncased-masked-ALL-BM25-single-triplet-18930-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_beer_exp_data-uncased-masked-ALL-BM25-single-triplet-1200-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_company_exp_data-uncased-masked-ALL-BM25-single-triplet-505770-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-39960-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-55800-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-single-triplet-39960-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-single-triplet-55800-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-2340-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-16200-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-single-triplet-1980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-2340-1.json ;\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-single-triplet-16200-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "    config['negatives'] = path_base + f'data/{data}/{dm_data[i]}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*30)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"hard-negatives-{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squad Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/random-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-86668-1.json\n",
      "python scripts/train_embedding.py -c configs/random-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-86668-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/random_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 86668,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'random-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-86668-1'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/random_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"random-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/random-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n",
      "python scripts/train_embedding.py -c configs/random-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/random_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 260004,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'random-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/random_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*3)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"random-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squad BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-86668-1.json\n",
      "python scripts/train_embedding.py -c configs/bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-86668-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/random_supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/SQuAD/hard_negatives_supervision_train_sent.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 86668,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-86668-1'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/random_supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/SQuAD/hard_negatives_supervision_train_sent.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"bm25-hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-433340-1.json\n",
      "python scripts/train_embedding.py -c configs/bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-433340-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/random_supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/SQuAD/hard_negatives_supervision_train_sent.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 433340,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-433340-1'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/random_supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/SQuAD/hard_negatives_supervision_train_sent.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"bm25-hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n",
      "python scripts/train_embedding.py -c configs/bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/random_supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/SQuAD/hard_negatives_supervision_train_sent.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 260004,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'bm25-hard-negatives-SQuAD_sent-uncased-masked-ALL-BM25-single-triplet-260004-1'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/random_supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/SQuAD/hard_negatives_supervision_train_sent.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*3)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"bm25-hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/imdb_wiki/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 38250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDB_ID</th>\n",
       "      <th>QID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41098</th>\n",
       "      <td>tt2825120</td>\n",
       "      <td>[Q17112644, Q498218, Q18538354, Q3498669, Q463...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28950</th>\n",
       "      <td>tt0403455</td>\n",
       "      <td>[Q7750926, Q895137, Q21428189, Q28496667, Q171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29297</th>\n",
       "      <td>tt0418460</td>\n",
       "      <td>[Q7750926, Q17112644, Q498218, Q4633000, Q4241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30720</th>\n",
       "      <td>tt0477139</td>\n",
       "      <td>[Q7750926, Q18538354, Q165685, Q33520346, Q171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24124</th>\n",
       "      <td>tt0189630</td>\n",
       "      <td>[Q17112644, Q498218, Q4633000, Q7750926, Q1624...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23176</th>\n",
       "      <td>tt0154420</td>\n",
       "      <td>[Q498218, Q1103638, Q7059878, Q7750926, Q17112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47758</th>\n",
       "      <td>tt9358106</td>\n",
       "      <td>[Q7750926, Q498218, Q18538354, Q17112644, Q396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>tt6284256</td>\n",
       "      <td>[Q7750926, Q17112644, Q4633000, Q18538354, Q49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>tt0997274</td>\n",
       "      <td>[Q498218, Q7750926, Q21428189, Q4633000, Q1853...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23808</th>\n",
       "      <td>tt0175996</td>\n",
       "      <td>[Q498218, Q18538354, Q7059878, Q16249578, Q357...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IMDB_ID                                                QID\n",
       "idx                                                                \n",
       "41098  tt2825120  [Q17112644, Q498218, Q18538354, Q3498669, Q463...\n",
       "28950  tt0403455  [Q7750926, Q895137, Q21428189, Q28496667, Q171...\n",
       "29297  tt0418460  [Q7750926, Q17112644, Q498218, Q4633000, Q4241...\n",
       "30720  tt0477139  [Q7750926, Q18538354, Q165685, Q33520346, Q171...\n",
       "24124  tt0189630  [Q17112644, Q498218, Q4633000, Q7750926, Q1624...\n",
       "...          ...                                                ...\n",
       "23176  tt0154420  [Q498218, Q1103638, Q7059878, Q7750926, Q17112...\n",
       "47758  tt9358106  [Q7750926, Q498218, Q18538354, Q17112644, Q396...\n",
       "46228  tt6284256  [Q7750926, Q17112644, Q4633000, Q18538354, Q49...\n",
       "32823  tt0997274  [Q498218, Q7750926, Q21428189, Q4633000, Q1853...\n",
       "23808  tt0175996  [Q498218, Q18538354, Q7059878, Q16249578, Q357...\n",
       "\n",
       "[38250 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(path_base + f'data/{data}/hard_negatives_supervision_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-JWS-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-JWS-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/imdb_wiki/hard_negatives_JWS_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 38250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-JWS-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-38250-1'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_JWS_supervision_train.pkl'\n",
    "\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-JWS-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-191250-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-191250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/imdb_wiki/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 191250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-imdb_wiki-uncased-masked-ALL-BM25-single-triplet-191250-1'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/main_fuzzy/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/main_fuzzy/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision) * 5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J2G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-J2G-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-J2G-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/main_fuzzy/hard_negatives_J2G_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-J2G-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_J2G_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-J2G-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-J2G-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-J2G-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/main_fuzzy/hard_negatives_J2G_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-J2G-main_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_J2G_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision) * 5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-J2G-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision) * 5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J2G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-J2G-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-J2G-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/hard_negatives_J2G_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-J2G-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_J2G_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-J2G-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-J2G-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-J2G-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/hard_negatives_J2G_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-J2G-hard_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_J2G_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision) * 5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-J2G-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/hard_negatives_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J2G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-J2G-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-J2G-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/hard_negatives_J2G_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-J2G-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_J2G_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-J2G-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard-negatives-J2G-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard-negatives-J2G-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'negatives': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/hard_negatives_J2G_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard-negatives-J2G-easy_fuzzy-uncased-masked-ALL-BM25-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "config['negatives'] = path_base + f'data/{data}/hard_negatives_J2G_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"hard-negatives-J2G-{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained BERT (no fine tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS MARCO (running with BM25 over the already 25-ed 1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/MSMARCO-pretrained-1-1.json\n",
      "python scripts/train_embedding.py -c configs/MSMARCO-pretrained-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'MSMARCO',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/qidpidtriples.train.full.2.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'MSMARCO-pretrained-1-1'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'MSMARCO'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/{data}/qidpidtriples.train.full.2.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/SQuAD_sent-pretrained-1-1.json\n",
      "python scripts/train_embedding.py -c configs/SQuAD_sent-pretrained-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/train_sent_triplets.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'SQuAD_sent-pretrained-1-1'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/train_sent_triplets.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB_Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/imdb_wiki-pretrained-1-1.json\n",
      "python scripts/train_embedding.py -c configs/imdb_wiki-pretrained-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'imdb_wiki-pretrained-1-1'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/main_fuzzy-pretrained-1-1.json\n",
      "python scripts/train_embedding.py -c configs/main_fuzzy-pretrained-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'main_fuzzy-pretrained-1-1'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard_fuzzy-pretrained-1-1.json\n",
      "python scripts/train_embedding.py -c configs/hard_fuzzy-pretrained-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard_fuzzy-pretrained-1-1'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/easy_fuzzy-pretrained-1-1.json\n",
      "python scripts/train_embedding.py -c configs/easy_fuzzy-pretrained-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'easy_fuzzy-pretrained-1-1'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-pretrained-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-pretrained-1-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'pretrained'\n",
    "    config['bert_path']= 'distilbert-base-uncased' \n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    config['train_size'] = 1\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200 #useless\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Tower "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS MARCO (running with BM25 over the already 25-ed 1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/MSMARCO-uncased-masked-ALL-BM25-double-triplet-3977686-1.json\n",
      "python scripts/train_embedding.py -c configs/MSMARCO-uncased-masked-ALL-BM25-double-triplet-3977686-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'MSMARCO',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/qidpidtriples.train.full.2.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/supervision_test.pkl',\n",
       " 'arch': 'double-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/MARCO-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 3977686,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'MSMARCO-uncased-masked-ALL-BM25-double-triplet-3977686-1'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'MSMARCO'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/{data}/qidpidtriples.train.full.2.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'double-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/MARCO-uncased-masked-ALL-BM25' # change manuaallyyy~\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/100)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/SQuAD_sent-uncased-masked-ALL-BM25-double-triplet-260004-1.json\n",
      "python scripts/train_embedding.py -c configs/SQuAD_sent-uncased-masked-ALL-BM25-double-triplet-260004-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/train_sent_triplets.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'double-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 260004,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'SQuAD_sent-uncased-masked-ALL-BM25-double-triplet-260004-1'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/train_sent_triplets.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'double-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB_Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1.json\n",
      "python scripts/train_embedding.py -c configs/imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'double-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 38250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 4,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'imdb_wiki-uncased-masked-ALL-BM25-double-triplet-38250-1'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'double-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 4\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/main_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/main_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'double-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'main_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'double-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'double-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'double-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/easy_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/easy_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'double-triplet',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'easy_fuzzy-uncased-masked-ALL-BM25-double-triplet-40000-1'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'double-triplet'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DM_joined MANUALLY CHANGE COMPANY TO BATCH SIZE OF 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-611-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-631-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-uncased-masked-ALL-BM25-double-triplet-40-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-uncased-masked-ALL-BM25-double-triplet-16859-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-1332-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-1860-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-1332-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-1860-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-78-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-540-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-66-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-78-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-540-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'double-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    if 'company' in dm_data[i]:\n",
    "        config['batch_size'] = 4\n",
    "    else:\n",
    "        config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 30\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-uncased-masked-ALL-BM25-double-triplet-9165-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-uncased-masked-ALL-BM25-double-triplet-9465-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-uncased-masked-ALL-BM25-double-triplet-600-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-uncased-masked-ALL-BM25-double-triplet-252885-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-uncased-masked-ALL-BM25-double-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-uncased-masked-ALL-BM25-double-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-8100-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-uncased-masked-ALL-BM25-double-triplet-990-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-uncased-masked-ALL-BM25-double-triplet-8100-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'double-triplet'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*15)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    if 'company' in dm_data[i]:\n",
    "        config['batch_size'] = 4\n",
    "    else:\n",
    "        config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-uncased-masked-ALL-BM25-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained BERT + Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS MARCO (running with BM25 over the already 25-ed 1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/MSMARCO-distilbert-base-uncased-single-triplet-3977686-1.json\n",
      "python scripts/train_embedding.py -c configs/MSMARCO-distilbert-base-uncased-single-triplet-3977686-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'MSMARCO',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/qidpidtriples.train.full.2.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 3977686,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'MSMARCO-distilbert-base-uncased-single-triplet-3977686-1'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'MSMARCO'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/{data}/qidpidtriples.train.full.2.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']='distilbert-base-uncased' \n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/100)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1.json\n",
      "python scripts/train_embedding.py -c configs/SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/train_sent_triplets.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 260004,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/train_sent_triplets.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/random-SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1.json\n",
      "python scripts/train_embedding.py -c configs/random-SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/random_supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 260004,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'random-SQuAD_sent-distilbert-base-uncased-single-triplet-260004-1'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/random_supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision) * 3)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"random-{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB_Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/imdb_wiki-distilbert-base-uncased-single-triplet-38250-1.json\n",
      "python scripts/train_embedding.py -c configs/imdb_wiki-distilbert-base-uncased-single-triplet-38250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 38250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'imdb_wiki-distilbert-base-uncased-single-triplet-38250-1'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/imdb_wiki-distilbert-base-uncased-single-triplet-191250-1.json\n",
      "python scripts/train_embedding.py -c configs/imdb_wiki-distilbert-base-uncased-single-triplet-191250-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 191250,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'imdb_wiki-distilbert-base-uncased-single-triplet-191250-1'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/main_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/main_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'main_fuzzy-distilbert-base-uncased-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/main_fuzzy-distilbert-base-uncased-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/main_fuzzy-distilbert-base-uncased-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'main_fuzzy-distilbert-base-uncased-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/hard_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard_fuzzy-distilbert-base-uncased-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/easy_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n",
      "python scripts/train_embedding.py -c configs/easy_fuzzy-distilbert-base-uncased-single-triplet-40000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 40000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'easy_fuzzy-distilbert-base-uncased-single-triplet-40000-1'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/easy_fuzzy-distilbert-base-uncased-single-triplet-200000-1.json\n",
      "python scripts/train_embedding.py -c configs/easy_fuzzy-distilbert-base-uncased-single-triplet-200000-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'single-triplet',\n",
       " 'bert_path': 'distilbert-base-uncased',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 200000,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'easy_fuzzy-distilbert-base-uncased-single-triplet-200000-1'}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'single-triplet'\n",
    "config['bert_path']= 'distilbert-base-uncased'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "config['train_size'] = int(len(train_supervision)*5)\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-distilbert-base-uncased-single-triplet-611-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-distilbert-base-uncased-single-triplet-631-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-distilbert-base-uncased-single-triplet-40-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-distilbert-base-uncased-single-triplet-16859-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-1332-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-1860-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-1332-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-1860-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-78-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-540-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-66-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-78-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-540-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= 'distilbert-base-uncased'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)/1)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 30\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-distilbert-base-uncased-single-triplet-9165-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-distilbert-base-uncased-single-triplet-9465-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-distilbert-base-uncased-single-triplet-600-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-distilbert-base-uncased-single-triplet-252885-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-distilbert-base-uncased-single-triplet-19980-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-distilbert-base-uncased-single-triplet-27900-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-8100-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-distilbert-base-uncased-single-triplet-990-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-distilbert-base-uncased-single-triplet-1170-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-distilbert-base-uncased-single-triplet-8100-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'single-triplet'\n",
    "    config['bert_path']= 'distilbert-base-uncased'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    train_supervision = pd.read_pickle(config['train_supervision'])\n",
    "    config['train_size'] = int(len(train_supervision)*15)\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-distilbert-base-uncased-{config['arch']}-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25-MLM BERT (no fine tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS MARCO (running with BM25 over the already 25-ed 1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/MSMARCO-pretrained-MLMBM25-1-1.json\n",
      "python scripts/train_embedding.py -c configs/MSMARCO-pretrained-MLMBM25-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'MSMARCO',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/qidpidtriples.train.full.2.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/MSMARCO/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/MSMARCO/tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/MSMARCO/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/MARCO-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'MSMARCO-pretrained-MLMBM25-1-1'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'MSMARCO'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/{data}/qidpidtriples.train.full.2.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/MARCO-uncased-masked-ALL-BM25' # change manuaallyyy~\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-MLMBM25-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/SQuAD_sent-pretrained-MLMBM25-1-1.json\n",
      "python scripts/train_embedding.py -c configs/SQuAD_sent-pretrained-MLMBM25-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'SQuAD_sent',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/train_tableB_sent_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/train_sent_triplets.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_tableB_sent_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment/data/SQuAD/dev_sent_labels.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/SQuAD_sent-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'SQuAD_sent-pretrained-MLMBM25-1-1'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'SQuAD_sent'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/SQuAD/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/SQuAD/train_tableB_sent_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'data/SQuAD/train_sent_triplets.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/SQuAD/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/SQuAD/dev_tableB_sent_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'data/SQuAD/dev_sent_labels.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-MLMBM25-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB_Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/imdb_wiki-pretrained-MLMBM25-1-1.json\n",
      "python scripts/train_embedding.py -c configs/imdb_wiki-pretrained-MLMBM25-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'imdb_wiki',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/imdb_wiki/dev_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/imdb_wiki/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/imdb_wiki-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'imdb_wiki-pretrained-MLMBM25-1-1'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'imdb_wiki'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/imdb_wiki/dev_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/imdb_wiki/dev_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-MLMBM25-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/main_fuzzy-pretrained-MLMBM25-1-1.json\n",
      "python scripts/train_embedding.py -c configs/main_fuzzy-pretrained-MLMBM25-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'main_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/main_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/main_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/main_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'main_fuzzy-pretrained-MLMBM25-1-1'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'main_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-MLMBM25-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/hard_fuzzy-pretrained-MLMBM25-1-1.json\n",
      "python scripts/train_embedding.py -c configs/hard_fuzzy-pretrained-MLMBM25-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'hard_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/hard_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/hard_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/hard_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'hard_fuzzy-pretrained-MLMBM25-1-1'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'hard_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-MLMBM25-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/1/sahaana/enrichment/ember/embedding/configs/easy_fuzzy-pretrained-MLMBM25-1-1.json\n",
      "python scripts/train_embedding.py -c configs/easy_fuzzy-pretrained-MLMBM25-1-1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': 'easy_fuzzy',\n",
       " 'datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableA_processed.pkl',\n",
       " 'datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/train_tableB_processed.pkl',\n",
       " 'train_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_train.pkl',\n",
       " 'eval_datapath_l': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableA_processed.pkl',\n",
       " 'eval_datapath_r': '/lfs/1/sahaana/enrichment/data/easy_fuzzy/test_tableB_processed.pkl',\n",
       " 'test_supervision': '/lfs/1/sahaana/enrichment//data/easy_fuzzy/supervision_test.pkl',\n",
       " 'arch': 'pretrained',\n",
       " 'bert_path': '/lfs/1/sahaana/enrichment//ember/pretraining/models/easy_fuzzy-uncased-masked-ALL-BM25',\n",
       " 'column': 'merged_all',\n",
       " 'tokenizer': 'distilbert-base-uncased',\n",
       " 'train_size': 1,\n",
       " 'epochs': 1,\n",
       " 'batch_size': 8,\n",
       " 'final_size': 200,\n",
       " 'lr': 1e-05,\n",
       " 'loss': 'triplet',\n",
       " 'tl_margin': 1.0,\n",
       " 'tl_p': 2,\n",
       " 'pool_type': 'CLS',\n",
       " 'tokenizer_max_length': 512,\n",
       " 'knn_k': 300,\n",
       " 'model_name': 'easy_fuzzy-pretrained-MLMBM25-1-1'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'easy_fuzzy'\n",
    "\n",
    "config = defaultdict(dict) \n",
    "\n",
    "config['data'] = data\n",
    "config['datapath_l'] = path_base + f'data/{data}/train_tableA_processed.pkl'\n",
    "config['datapath_r'] = path_base + f'data/{data}/train_tableB_processed.pkl'\n",
    "config['train_supervision'] = path_base + f'/data/{data}/supervision_train.pkl'\n",
    "\n",
    "config['eval_datapath_l'] = path_base + f'data/{data}/test_tableA_processed.pkl'\n",
    "config['eval_datapath_r'] = path_base + f'data/{data}/test_tableB_processed.pkl'\n",
    "config['test_supervision'] = path_base + f'/data/{data}/supervision_test.pkl'\n",
    "\n",
    "config['arch'] = 'pretrained'\n",
    "config['bert_path']= path_base + f'/ember/pretraining/models/{data}-uncased-masked-ALL-BM25'\n",
    "config['column'] = \"merged_all\"\n",
    "config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "config['train_size'] = 1\n",
    "\n",
    "config['epochs'] = 1\n",
    "config['batch_size'] = 8\n",
    "config['final_size'] = 200\n",
    "config['lr'] = .00001\n",
    "config['loss'] = 'triplet'\n",
    "config['tl_margin'] = 1.0\n",
    "config['tl_p'] = 2\n",
    "config['pool_type'] = \"CLS\"\n",
    "config['tokenizer_max_length'] = 512\n",
    "\n",
    "config['knn_k'] = 300\n",
    "\n",
    "config['model_name'] = f\"{data}-{config['arch']}-MLMBM25-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "print(config_path)\n",
    "print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json\")\n",
    "save_config(config_path)\n",
    "load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/train_embedding.py -c configs/joined_abt_buy_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_amazon_google_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_beer_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_company_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_acm_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dblp_scholar_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_acm_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_dblp_scholar_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_itunes_amazon_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_dirty_walmart_amazon_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_fodors_zagat_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_itunes_amazon_exp_data-pretrained-MLMBM25-1-1.json ;\n",
      "python scripts/train_embedding.py -c configs/joined_walmart_amazon_exp_data-pretrained-MLMBM25-1-1.json ;\n"
     ]
    }
   ],
   "source": [
    "dm_data  = {0:\"joined_abt_buy_exp_data\", \n",
    "            1:\"joined_amazon_google_exp_data\", \n",
    "            2:\"joined_beer_exp_data\", \n",
    "            3:\"joined_company_exp_data\", \n",
    "            4:\"joined_dblp_acm_exp_data\", \n",
    "            5:\"joined_dblp_scholar_exp_data\", \n",
    "            6:\"joined_dirty_dblp_acm_exp_data\", \n",
    "            7:\"joined_dirty_dblp_scholar_exp_data\", \n",
    "            8:\"joined_dirty_itunes_amazon_exp_data\", \n",
    "            9:\"joined_dirty_walmart_amazon_exp_data\", \n",
    "            10:\"joined_fodors_zagat_exp_data\", \n",
    "            11:\"joined_itunes_amazon_exp_data\", \n",
    "            12:\"joined_walmart_amazon_exp_data\"}\n",
    "data = 'dm_blocked'\n",
    "\n",
    "for i in dm_data:\n",
    "    config = defaultdict(dict) \n",
    "\n",
    "    config['data'] = data\n",
    "    config['datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['train_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_train.pkl'\n",
    "\n",
    "    config['eval_datapath_l'] = path_base + f'data/{data}/{dm_data[i]}/tableA_processed.pkl'\n",
    "    config['eval_datapath_r'] = path_base + f'data/{data}/{dm_data[i]}/tableB_processed.pkl'\n",
    "    config['test_supervision'] = path_base + f'data/{data}/{dm_data[i]}/supervision_test.pkl'\n",
    "\n",
    "    config['arch'] = 'pretrained'\n",
    "    config['bert_path']= path_base + f'/ember/pretraining/models/{dm_data[i]}-uncased-masked-ALL-BM25'\n",
    "    config['column'] = \"merged_all\"\n",
    "    config['tokenizer'] = 'distilbert-base-uncased'\n",
    "\n",
    "    config['train_size'] = 1\n",
    "\n",
    "    config['epochs'] = 1\n",
    "    config['batch_size'] = 8\n",
    "    config['final_size'] = 200 #useless\n",
    "    config['lr'] = .00001\n",
    "    config['loss'] = 'triplet'\n",
    "    config['tl_margin'] = 1.0\n",
    "    config['tl_p'] = 2\n",
    "    config['pool_type'] = \"CLS\"\n",
    "    config['tokenizer_max_length'] = 512\n",
    "\n",
    "    config['knn_k'] = 300\n",
    "\n",
    "    config['model_name'] = f\"{dm_data[i]}-{config['arch']}-MLMBM25-{config['train_size']}-{config['epochs']}\"\n",
    "\n",
    "    config_path = path_base + f\"ember/embedding/configs/{config['model_name']}.json\"\n",
    "    #print(config_path)\n",
    "    print(f\"python scripts/train_embedding.py -c configs/{config['model_name']}.json ;\")\n",
    "    save_config(config_path)\n",
    "    load_config(config_path)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
