{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "related-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "passive-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/lfs/1/sahaana/enrichment/ember/utils')\n",
    "from preprocessing_utils import compute_BM25, merge_columns, reindex_deepmatcher\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-checklist",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# deepmatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "palestinian-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/lfs/1/sahaana/enrichment/data/deepmatcher\"\n",
    "merged_col = \"merged_all\"\n",
    "separator = \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informal-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {0:\"abt_buy_exp_data\", \n",
    "            1:\"amazon_google_exp_data\", \n",
    "            2:\"beer_exp_data\", \n",
    "            3:\"company_exp_data\", \n",
    "            4:\"dblp_acm_exp_data\", \n",
    "            5:\"dblp_scholar_exp_data\", \n",
    "            6:\"dirty_dblp_acm_exp_data\", \n",
    "            7:\"dirty_dblp_scholar_exp_data\", \n",
    "            8:\"dirty_itunes_amazon_exp_data\", \n",
    "            9:\"dirty_walmart_amazon_exp_data\", \n",
    "            10:\"fodors_zagat_exp_data\", \n",
    "            11:\"itunes_amazon_exp_data\", \n",
    "            12:\"walmart_amazon_exp_data\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-howard",
   "metadata": {},
   "source": [
    "## Merge and BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "marked-uzbekistan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved abt_buy_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved amazon_google_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved beer_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved company_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved dblp_acm_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved dblp_scholar_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved dirty_dblp_acm_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved dirty_dblp_scholar_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved dirty_itunes_amazon_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved dirty_walmart_amazon_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved fodors_zagat_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved itunes_amazon_exp_data\n",
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Saved walmart_amazon_exp_data\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    query_path = f\"{path}/{datasets[d]}/tableA_processed.pkl\"\n",
    "    corpus_path = f\"{path}/{datasets[d]}/tableB_processed.pkl\"\n",
    "    \n",
    "    query_df = pd.read_csv(f\"{path}/{datasets[d]}/tableA.csv\")\n",
    "    corpus_df = pd.read_csv(f\"{path}/{datasets[d]}/tableB.csv\")\n",
    "    \n",
    "    query_columns = list(query_df.columns)\n",
    "    corpus_columns = list(corpus_df.columns)\n",
    "    \n",
    "    query_columns.remove('id')\n",
    "    corpus_columns.remove('id')\n",
    "    \n",
    "    query_df = merge_columns(query_df, query_columns, merged_col, query_path, separator)\n",
    "    corpus_df = merge_columns(corpus_df, corpus_columns, merged_col, corpus_path, separator)\n",
    "    \n",
    "    compute_BM25(corpus_df, query_df, \"merged_all\", datasets[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-marsh",
   "metadata": {},
   "source": [
    "## Reindex Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "optimum-canadian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in datasets:\n",
    "    l_df = pd.read_csv(f\"{path}/{datasets[d]}/tableA.csv\")\n",
    "    r_df = pd.read_csv(f\"{path}/{datasets[d]}/tableB.csv\")\n",
    "    \n",
    "    train = pd.read_csv(f\"{path}/{datasets[d]}/train.csv\")\n",
    "    test = pd.read_csv(f\"{path}/{datasets[d]}/test.csv\")\n",
    "    val = pd.read_csv(f\"{path}/{datasets[d]}/valid.csv\")\n",
    "    \n",
    "    train_updated = reindex_deepmatcher(l_df, r_df, train)\n",
    "    test_updated = reindex_deepmatcher(l_df, r_df, test)\n",
    "    val_updated = reindex_deepmatcher(l_df, r_df, val)\n",
    "    \n",
    "    train_updated.to_csv(f\"{path}/{datasets[d]}/train_updated.csv\", index=False)\n",
    "    test_updated.to_csv(f\"{path}/{datasets[d]}/test_updated.csv\", index=False)\n",
    "    val_updated.to_csv(f\"{path}/{datasets[d]}/val_updated.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-corruption",
   "metadata": {},
   "source": [
    "## Count the num keys in train/test/val, and overlap in train-test train-val val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "activated-forwarding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abt_buy_exp_data\n",
      "1081 \t lsize\n",
      "1092 \t rsize\n",
      "5743 \t train size\n",
      "1916 \t val size\n",
      "1916 \t test size\n",
      "\n",
      "973 \t uniques in train ltable\n",
      "956 \t uniques in train rtable\n",
      "728 \t uniques in val ltable\n",
      "702 \t uniques in val rtable\n",
      "737 \t uniques in test ltable\n",
      "700 \t uniques in test rtable\n",
      "\n",
      "676 \t train/val ltable overlap\n",
      "649 \t train/val rtable overlap\n",
      "674 \t train/test ltable overlap\n",
      "650 \t train/test rtable overlap\n",
      "547 \t test/val ltable overlap\n",
      "516 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "amazon_google_exp_data\n",
      "1363 \t lsize\n",
      "3226 \t rsize\n",
      "6874 \t train size\n",
      "2293 \t val size\n",
      "2293 \t test size\n",
      "\n",
      "1126 \t uniques in train ltable\n",
      "1788 \t uniques in train rtable\n",
      "772 \t uniques in val ltable\n",
      "1107 \t uniques in val rtable\n",
      "771 \t uniques in test ltable\n",
      "1090 \t uniques in test rtable\n",
      "\n",
      "673 \t train/val ltable overlap\n",
      "903 \t train/val rtable overlap\n",
      "674 \t train/test ltable overlap\n",
      "888 \t train/test rtable overlap\n",
      "531 \t test/val ltable overlap\n",
      "641 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "beer_exp_data\n",
      "4345 \t lsize\n",
      "3000 \t rsize\n",
      "268 \t train size\n",
      "91 \t val size\n",
      "91 \t test size\n",
      "\n",
      "176 \t uniques in train ltable\n",
      "174 \t uniques in train rtable\n",
      "83 \t uniques in val ltable\n",
      "82 \t uniques in val rtable\n",
      "76 \t uniques in test ltable\n",
      "83 \t uniques in test rtable\n",
      "\n",
      "29 \t train/val ltable overlap\n",
      "27 \t train/val rtable overlap\n",
      "27 \t train/test ltable overlap\n",
      "36 \t train/test rtable overlap\n",
      "10 \t test/val ltable overlap\n",
      "18 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "company_exp_data\n",
      "28200 \t lsize\n",
      "28200 \t rsize\n",
      "67596 \t train size\n",
      "22533 \t val size\n",
      "22503 \t test size\n",
      "\n",
      "22457 \t uniques in train ltable\n",
      "19232 \t uniques in train rtable\n",
      "15381 \t uniques in val ltable\n",
      "9892 \t uniques in val rtable\n",
      "5640 \t uniques in test ltable\n",
      "5640 \t uniques in test rtable\n",
      "\n",
      "15278 \t train/val ltable overlap\n",
      "6564 \t train/val rtable overlap\n",
      "0 \t train/test ltable overlap\n",
      "0 \t train/test rtable overlap\n",
      "0 \t test/val ltable overlap\n",
      "0 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "dblp_acm_exp_data\n",
      "2616 \t lsize\n",
      "2294 \t rsize\n",
      "7417 \t train size\n",
      "2473 \t val size\n",
      "2473 \t test size\n",
      "\n",
      "2093 \t uniques in train ltable\n",
      "1927 \t uniques in train rtable\n",
      "1271 \t uniques in val ltable\n",
      "1210 \t uniques in val rtable\n",
      "1271 \t uniques in test ltable\n",
      "1218 \t uniques in test rtable\n",
      "\n",
      "1058 \t train/val ltable overlap\n",
      "1027 \t train/val rtable overlap\n",
      "1049 \t train/test ltable overlap\n",
      "1017 \t train/test rtable overlap\n",
      "754 \t test/val ltable overlap\n",
      "752 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "dblp_scholar_exp_data\n",
      "2616 \t lsize\n",
      "64263 \t rsize\n",
      "17223 \t train size\n",
      "5742 \t val size\n",
      "5742 \t test size\n",
      "\n",
      "2382 \t uniques in train ltable\n",
      "8058 \t uniques in train rtable\n",
      "1728 \t uniques in val ltable\n",
      "3948 \t uniques in val rtable\n",
      "1708 \t uniques in test ltable\n",
      "3938 \t uniques in test rtable\n",
      "\n",
      "1606 \t train/val ltable overlap\n",
      "2512 \t train/val rtable overlap\n",
      "1588 \t train/test ltable overlap\n",
      "2502 \t train/test rtable overlap\n",
      "1284 \t test/val ltable overlap\n",
      "1549 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "dirty_dblp_acm_exp_data\n",
      "2616 \t lsize\n",
      "2294 \t rsize\n",
      "7417 \t train size\n",
      "2473 \t val size\n",
      "2473 \t test size\n",
      "\n",
      "2093 \t uniques in train ltable\n",
      "1927 \t uniques in train rtable\n",
      "1271 \t uniques in val ltable\n",
      "1210 \t uniques in val rtable\n",
      "1271 \t uniques in test ltable\n",
      "1218 \t uniques in test rtable\n",
      "\n",
      "1058 \t train/val ltable overlap\n",
      "1027 \t train/val rtable overlap\n",
      "1049 \t train/test ltable overlap\n",
      "1017 \t train/test rtable overlap\n",
      "754 \t test/val ltable overlap\n",
      "752 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "dirty_dblp_scholar_exp_data\n",
      "2616 \t lsize\n",
      "64263 \t rsize\n",
      "17223 \t train size\n",
      "5742 \t val size\n",
      "5742 \t test size\n",
      "\n",
      "2382 \t uniques in train ltable\n",
      "8058 \t uniques in train rtable\n",
      "1728 \t uniques in val ltable\n",
      "3948 \t uniques in val rtable\n",
      "1708 \t uniques in test ltable\n",
      "3938 \t uniques in test rtable\n",
      "\n",
      "1606 \t train/val ltable overlap\n",
      "2512 \t train/val rtable overlap\n",
      "1588 \t train/test ltable overlap\n",
      "2502 \t train/test rtable overlap\n",
      "1284 \t test/val ltable overlap\n",
      "1549 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "dirty_itunes_amazon_exp_data\n",
      "6907 \t lsize\n",
      "55923 \t rsize\n",
      "321 \t train size\n",
      "109 \t val size\n",
      "109 \t test size\n",
      "\n",
      "288 \t uniques in train ltable\n",
      "297 \t uniques in train rtable\n",
      "104 \t uniques in val ltable\n",
      "107 \t uniques in val rtable\n",
      "104 \t uniques in test ltable\n",
      "106 \t uniques in test rtable\n",
      "\n",
      "21 \t train/val ltable overlap\n",
      "10 \t train/val rtable overlap\n",
      "24 \t train/test ltable overlap\n",
      "15 \t train/test rtable overlap\n",
      "6 \t test/val ltable overlap\n",
      "2 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "dirty_walmart_amazon_exp_data\n",
      "2554 \t lsize\n",
      "22074 \t rsize\n",
      "6144 \t train size\n",
      "2049 \t val size\n",
      "2049 \t test size\n",
      "\n",
      "1424 \t uniques in train ltable\n",
      "3702 \t uniques in train rtable\n",
      "927 \t uniques in val ltable\n",
      "1580 \t uniques in val rtable\n",
      "900 \t uniques in test ltable\n",
      "1584 \t uniques in test rtable\n",
      "\n",
      "772 \t train/val ltable overlap\n",
      "749 \t train/val rtable overlap\n",
      "746 \t train/test ltable overlap\n",
      "763 \t train/test rtable overlap\n",
      "555 \t test/val ltable overlap\n",
      "406 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "fodors_zagat_exp_data\n",
      "533 \t lsize\n",
      "331 \t rsize\n",
      "567 \t train size\n",
      "190 \t val size\n",
      "189 \t test size\n",
      "\n",
      "230 \t uniques in train ltable\n",
      "203 \t uniques in train rtable\n",
      "129 \t uniques in val ltable\n",
      "124 \t uniques in val rtable\n",
      "116 \t uniques in test ltable\n",
      "114 \t uniques in test rtable\n",
      "\n",
      "88 \t train/val ltable overlap\n",
      "104 \t train/val rtable overlap\n",
      "87 \t train/test ltable overlap\n",
      "95 \t train/test rtable overlap\n",
      "50 \t test/val ltable overlap\n",
      "67 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "itunes_amazon_exp_data\n",
      "6907 \t lsize\n",
      "55923 \t rsize\n",
      "321 \t train size\n",
      "109 \t val size\n",
      "109 \t test size\n",
      "\n",
      "288 \t uniques in train ltable\n",
      "297 \t uniques in train rtable\n",
      "104 \t uniques in val ltable\n",
      "107 \t uniques in val rtable\n",
      "104 \t uniques in test ltable\n",
      "106 \t uniques in test rtable\n",
      "\n",
      "21 \t train/val ltable overlap\n",
      "10 \t train/val rtable overlap\n",
      "24 \t train/test ltable overlap\n",
      "15 \t train/test rtable overlap\n",
      "6 \t test/val ltable overlap\n",
      "2 \t test/val rtable overlap\n",
      "\n",
      "\n",
      "walmart_amazon_exp_data\n",
      "2554 \t lsize\n",
      "22074 \t rsize\n",
      "6144 \t train size\n",
      "2049 \t val size\n",
      "2049 \t test size\n",
      "\n",
      "1424 \t uniques in train ltable\n",
      "3702 \t uniques in train rtable\n",
      "927 \t uniques in val ltable\n",
      "1580 \t uniques in val rtable\n",
      "900 \t uniques in test ltable\n",
      "1584 \t uniques in test rtable\n",
      "\n",
      "772 \t train/val ltable overlap\n",
      "749 \t train/val rtable overlap\n",
      "746 \t train/test ltable overlap\n",
      "763 \t train/test rtable overlap\n",
      "555 \t test/val ltable overlap\n",
      "406 \t test/val rtable overlap\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    l_df = pd.read_csv(f\"{path}/{datasets[d]}/tableA.csv\")\n",
    "    r_df = pd.read_csv(f\"{path}/{datasets[d]}/tableB.csv\")\n",
    "    \n",
    "    train = pd.read_csv(f\"{path}/{datasets[d]}/train.csv\")\n",
    "    test = pd.read_csv(f\"{path}/{datasets[d]}/test.csv\")\n",
    "    val = pd.read_csv(f\"{path}/{datasets[d]}/valid.csv\")\n",
    "    print(datasets[d])\n",
    "    print(f\"{len(l_df)} \\t lsize\")\n",
    "    print(f\"{len(r_df)} \\t rsize\")\n",
    "    print(f\"{len(train)} \\t train size\")\n",
    "    print(f\"{len(val)} \\t val size\")\n",
    "    print(f\"{len(test)} \\t test size\")\n",
    "    print()\n",
    "    print(f\"{train['ltable_id'].nunique()} \\t uniques in train ltable\")\n",
    "    print(f\"{train['rtable_id'].nunique()} \\t uniques in train rtable\")\n",
    "\n",
    "    print(f\"{val['ltable_id'].nunique()} \\t uniques in val ltable\")\n",
    "    print(f\"{val['rtable_id'].nunique()} \\t uniques in val rtable\")\n",
    "    \n",
    "    print(f\"{test['ltable_id'].nunique()} \\t uniques in test ltable\")\n",
    "    print(f\"{test['rtable_id'].nunique()} \\t uniques in test rtable\")\n",
    "    print()\n",
    "    train_val_l = pd.merge(train, val, on='ltable_id', suffixes=('_l','_r'), how='inner')['ltable_id'].nunique()\n",
    "    train_val_r = pd.merge(train, val, on='rtable_id', suffixes=('_l','_r'), how='inner')['rtable_id'].nunique()\n",
    "    train_test_l = pd.merge(train, test, on='ltable_id', suffixes=('_l','_r'), how='inner')['ltable_id'].nunique()\n",
    "    train_test_r = pd.merge(train, test, on='rtable_id', suffixes=('_l','_r'), how='inner')['rtable_id'].nunique()\n",
    "    val_test_l = pd.merge(val, test, on='ltable_id', suffixes=('_l','_r'), how='inner')['ltable_id'].nunique()\n",
    "    val_test_r = pd.merge(val, test, on='rtable_id', suffixes=('_l','_r'), how='inner')['rtable_id'].nunique()\n",
    "    \n",
    "    print(f\"{train_val_l} \\t train/val ltable overlap\")\n",
    "    print(f\"{train_val_r} \\t train/val rtable overlap\")\n",
    "    print(f\"{train_test_l} \\t train/test ltable overlap\")\n",
    "    print(f\"{train_test_r} \\t train/test rtable overlap\")\n",
    "    print(f\"{val_test_l} \\t test/val ltable overlap\")\n",
    "    print(f\"{val_test_r} \\t test/val rtable overlap\")\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-contamination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
